#######################PARAMETERS######################## cuda
	cuda: True
# train/test parameters	model_name: SimpleFC
	optimizer: SGD
	epochs: 120
	batch_size: 100
	seed: 75
	lr: 0.1
	weight_decay: 0.0001
# data preparation parameters
	patch_size: 21
	dataset: Indian_pines
	band: 220
	number_classes: 16
# SimpleNet parameters
	conv1: 500
	conv2: 100
	fc1: 200
	fc2: 84
# SimpleFC parameters
	FC_1: 500
	FC_2: 350
	FC_3: 150
	FC_4: 16

#############################  MODEL  ###################################

SimpleFC(
  (FC): Sequential(
    (0): Linear(in_features=97020, out_features=500, bias=True)
    (1): ReLU()
    (2): Linear(in_features=500, out_features=350, bias=True)
    (3): ReLU()
    (4): Linear(in_features=350, out_features=150, bias=True)
    (5): ReLU()
    (6): Linear(in_features=150, out_features=16, bias=True)
    (7): ReLU()
  )
  (Softmax): Softmax()
)
##############################################################################

Epoch 1/120| Time: 3.14s| Loss: 2.1405
Epoch 2/120| Time: 3.23s| Loss: 1.2958
Epoch 3/120| Time: 3.27s| Loss: 0.8687
Epoch 4/120| Time: 3.05s| Loss: 0.6044
Epoch 5/120| Time: 3.11s| Loss: 0.4108
Epoch 6/120| Time: 3.08s| Loss: 0.3122
Epoch 7/120| Time: 3.03s| Loss: 0.3477
Epoch 8/120| Time: 3.10s| Loss: 0.1283
Epoch 9/120| Time: 3.22s| Loss: 0.1616
Epoch 10/120| Time: 3.26s| Loss: 0.0853
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-10_12-27-48/SimpleFC10.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-10_12-27-48/SimpleFC10.model model loaded--<<
	Batch_idx: 0 | Loss: 0.4351 | Accuracy: 93
	Batch_idx: 1 | Loss: 0.4021 | Accuracy: 89
	Batch_idx: 2 | Loss: 0.2904 | Accuracy: 90
	Batch_idx: 3 | Loss: 0.2420 | Accuracy: 91
	Batch_idx: 4 | Loss: 0.1475 | Accuracy: 93
	Batch_idx: 5 | Loss: 0.3260 | Accuracy: 86
	Batch_idx: 6 | Loss: 0.1253 | Accuracy: 95
	Batch_idx: 7 | Loss: 0.2730 | Accuracy: 88
	Batch_idx: 8 | Loss: 0.4341 | Accuracy: 90
	Batch_idx: 9 | Loss: 0.3980 | Accuracy: 94
	Batch_idx: 10 | Loss: 0.2533 | Accuracy: 91
	Batch_idx: 11 | Loss: 0.3967 | Accuracy: 93
	Batch_idx: 12 | Loss: 0.3223 | Accuracy: 85
	Batch_idx: 13 | Loss: 0.1520 | Accuracy: 93
	Batch_idx: 14 | Loss: 0.2217 | Accuracy: 90
	Batch_idx: 15 | Loss: 0.3603 | Accuracy: 86
	Batch_idx: 16 | Loss: 0.3222 | Accuracy: 81
	Batch_idx: 17 | Loss: 0.2839 | Accuracy: 88
	Batch_idx: 18 | Loss: 0.2359 | Accuracy: 92
	Batch_idx: 19 | Loss: 0.2964 | Accuracy: 88
	Batch_idx: 20 | Loss: 1.0834 | Accuracy: 74
	Batch_idx: 21 | Loss: 1.8123 | Accuracy: 67
	Batch_idx: 22 | Loss: 1.5426 | Accuracy: 67
	Batch_idx: 23 | Loss: 1.8551 | Accuracy: 57
	Batch_idx: 24 | Loss: 0.5131 | Accuracy: 89
	Batch_idx: 25 | Loss: 0.1397 | Accuracy: 94
	Batch_idx: 26 | Loss: 0.0752 | Accuracy: 96
	Batch_idx: 27 | Loss: 0.2817 | Accuracy: 96
	Batch_idx: 28 | Loss: 0.1142 | Accuracy: 96
	Batch_idx: 29 | Loss: 0.0729 | Accuracy: 97
	Batch_idx: 30 | Loss: 0.0208 | Accuracy: 100
	Batch_idx: 31 | Loss: 0.0089 | Accuracy: 100
	Batch_idx: 32 | Loss: 0.0102 | Accuracy: 100
	Batch_idx: 33 | Loss: 0.0133 | Accuracy: 100
	Batch_idx: 34 | Loss: 1.2671 | Accuracy: 77
	Batch_idx: 35 | Loss: 0.1893 | Accuracy: 94
	Batch_idx: 36 | Loss: 0.2571 | Accuracy: 95
	Batch_idx: 37 | Loss: 0.1634 | Accuracy: 96
	Batch_idx: 38 | Loss: 0.1274 | Accuracy: 97
	Batch_idx: 39 | Loss: 0.1916 | Accuracy: 95
	Batch_idx: 40 | Loss: 0.1628 | Accuracy: 96
	Batch_idx: 41 | Loss: 0.1578 | Accuracy: 96
	Batch_idx: 42 | Loss: 0.0165 | Accuracy: 100
	Batch_idx: 43 | Loss: 0.0185 | Accuracy: 100
	Batch_idx: 44 | Loss: 0.0384 | Accuracy: 98
	Batch_idx: 45 | Loss: 0.0111 | Accuracy: 100
	Batch_idx: 46 | Loss: 0.0056 | Accuracy: 100
	Batch_idx: 47 | Loss: 0.0142 | Accuracy: 100
	Batch_idx: 48 | Loss: 0.0119 | Accuracy: 100
	Batch_idx: 49 | Loss: 0.0527 | Accuracy: 99
	Batch_idx: 50 | Loss: 0.0110 | Accuracy: 100
	Batch_idx: 51 | Loss: 0.0400 | Accuracy: 99
	Batch_idx: 52 | Loss: 0.0046 | Accuracy: 100
	Batch_idx: 53 | Loss: 0.1322 | Accuracy: 98
	Batch_idx: 54 | Loss: 0.1388 | Accuracy: 98
	Batch_idx: 55 | Loss: 0.0335 | Accuracy: 99
	Batch_idx: 56 | Loss: 0.0064 | Accuracy: 100
	Batch_idx: 57 | Loss: 0.0192 | Accuracy: 99
	Batch_idx: 58 | Loss: 0.0298 | Accuracy: 99
	Batch_idx: 59 | Loss: 0.0099 | Accuracy: 100
	Batch_idx: 60 | Loss: 0.0104 | Accuracy: 100
	Batch_idx: 61 | Loss: 0.2468 | Accuracy: 93
	Batch_idx: 62 | Loss: 0.9315 | Accuracy: 72
	Batch_idx: 63 | Loss: 0.6527 | Accuracy: 82
	Batch_idx: 64 | Loss: 0.5913 | Accuracy: 83
	Batch_idx: 65 | Loss: 0.5884 | Accuracy: 79
	Batch_idx: 66 | Loss: 0.2864 | Accuracy: 91
	Batch_idx: 67 | Loss: 0.3013 | Accuracy: 89
	Batch_idx: 68 | Loss: 0.0485 | Accuracy: 99
	Batch_idx: 69 | Loss: 0.0941 | Accuracy: 96
	Batch_idx: 70 | Loss: 0.0908 | Accuracy: 99
	Batch_idx: 71 | Loss: 0.0009 | Accuracy: 100
	Batch_idx: 72 | Loss: 0.0781 | Accuracy: 98
	Batch_idx: 73 | Loss: 0.0204 | Accuracy: 99
	Batch_idx: 74 | Loss: 0.0550 | Accuracy: 99
	Batch_idx: 75 | Loss: 0.0005 | Accuracy: 100
	Batch_idx: 76 | Loss: 0.0011 | Accuracy: 100
	Batch_idx: 77 | Loss: 0.0662 | Accuracy: 98
	Batch_idx: 78 | Loss: 0.0102 | Accuracy: 100
	Batch_idx: 79 | Loss: 0.0173 | Accuracy: 99
	Batch_idx: 80 | Loss: 0.0327 | Accuracy: 98
	Batch_idx: 81 | Loss: 0.0441 | Accuracy: 97
	Batch_idx: 82 | Loss: 0.0143 | Accuracy: 100
Testing Loss: 0.2530 | OA: 93.1253 | Time: 13.22
	Class 0, accuracy: 100.0000
	Class 1, accuracy: 90.9886
	Class 2, accuracy: 87.5000
	Class 3, accuracy: 87.3684
	Class 4, accuracy: 65.1163
	Class 5, accuracy: 95.7192
	Class 6, accuracy: 100.0000
	Class 7, accuracy: 100.0000
	Class 8, accuracy: 0.0000
	Class 9, accuracy: 95.1157
	Class 10, accuracy: 99.3890
	Class 11, accuracy: 79.5789
	Class 12, accuracy: 91.4634
	Class 13, accuracy: 98.9130
	Class 14, accuracy: 99.0291
	Class 15, accuracy: 96.0000
Epoch 11/120| Time: 3.11s| Loss: 0.1012
Epoch 12/120| Time: 3.08s| Loss: 0.1830
Epoch 13/120| Time: 3.22s| Loss: 0.1437
Epoch 14/120| Time: 3.30s| Loss: 0.1426
Epoch 15/120| Time: 3.13s| Loss: 0.0651
Epoch 16/120| Time: 3.20s| Loss: 0.0533
Epoch 17/120| Time: 3.11s| Loss: 0.0360
Epoch 18/120| Time: 3.27s| Loss: 0.0342
