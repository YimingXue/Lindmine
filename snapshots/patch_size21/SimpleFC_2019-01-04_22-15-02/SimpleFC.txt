#############################  PARAMETERS  ###################################
# cuda
	cuda: True
# train/test parameters	model_name: SimpleFC
	optimizer: SGD
	epochs: 120
	batch_size: 100
	seed: 75
	lr: 0.1
	weight_decay: 0.0001
# data preparation parameters
	patch_size: 21
	indianPines_band: 220
	indianPines_class: 16
# SimpleNet parameters
	conv1: 500
	conv2: 100
	fc1: 200
	fc2: 84
# SimpleFC parameters
	FC_1: 500
	FC_2: 350
	FC_3: 150
	FC_4: 16
##############################################################################

#############################  MODEL  ###################################

SimpleFC(
  (FC): Sequential(
    (0): Linear(in_features=97020, out_features=500, bias=True)
    (1): ReLU()
    (2): Linear(in_features=500, out_features=350, bias=True)
    (3): ReLU()
    (4): Linear(in_features=350, out_features=150, bias=True)
    (5): ReLU()
    (6): Linear(in_features=150, out_features=16, bias=True)
    (7): ReLU()
  )
  (Softmax): Softmax()
)
##############################################################################

Epoch 1/120| Time: 1.87s| Loss: 2.2352
Epoch 2/120| Time: 1.83s| Loss: 1.3662
Epoch 3/120| Time: 1.83s| Loss: 0.8163
Epoch 4/120| Time: 1.83s| Loss: 0.6517
Epoch 5/120| Time: 1.83s| Loss: 0.5385
Epoch 6/120| Time: 1.83s| Loss: 0.5375
Epoch 7/120| Time: 1.84s| Loss: 0.4373
Epoch 8/120| Time: 1.84s| Loss: 0.4165
Epoch 9/120| Time: 1.84s| Loss: 0.4530
Epoch 10/120| Time: 1.83s| Loss: 0.7441
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC10.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC10.model model loaded--<<
	Batch_idx: 0 | Loss: 16.5423 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 16.1444 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 15.9837 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 16.6246 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 2.6257 | AccuracyNumber: 20
	Batch_idx: 5 | Loss: 2.6935 | AccuracyNumber: 23
	Batch_idx: 6 | Loss: 2.8502 | AccuracyNumber: 15
	Batch_idx: 7 | Loss: 2.5580 | AccuracyNumber: 25
	Batch_idx: 8 | Loss: 1.2175 | AccuracyNumber: 86
	Batch_idx: 9 | Loss: 1.0201 | AccuracyNumber: 88
	Batch_idx: 10 | Loss: 1.2778 | AccuracyNumber: 83
	Batch_idx: 11 | Loss: 1.1641 | AccuracyNumber: 85
	Batch_idx: 12 | Loss: 1.4774 | AccuracyNumber: 44
	Batch_idx: 13 | Loss: 0.7693 | AccuracyNumber: 62
	Batch_idx: 14 | Loss: 0.7647 | AccuracyNumber: 62
	Batch_idx: 15 | Loss: 0.7006 | AccuracyNumber: 69
	Batch_idx: 16 | Loss: 1.1936 | AccuracyNumber: 87
	Batch_idx: 17 | Loss: 1.4625 | AccuracyNumber: 81
	Batch_idx: 18 | Loss: 1.0981 | AccuracyNumber: 86
	Batch_idx: 19 | Loss: 1.0010 | AccuracyNumber: 90
	Batch_idx: 20 | Loss: 16.2627 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 16.9690 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 15.8506 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 16.9141 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.5195 | AccuracyNumber: 92
	Batch_idx: 25 | Loss: 0.3519 | AccuracyNumber: 91
	Batch_idx: 26 | Loss: 0.9735 | AccuracyNumber: 65
	Batch_idx: 27 | Loss: 2.8078 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8051 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.9696 | AccuracyNumber: 19
	Batch_idx: 30 | Loss: 1.3297 | AccuracyNumber: 30
	Batch_idx: 31 | Loss: 1.3908 | AccuracyNumber: 30
	Batch_idx: 32 | Loss: 0.6411 | AccuracyNumber: 74
	Batch_idx: 33 | Loss: 0.8428 | AccuracyNumber: 65
	Batch_idx: 34 | Loss: 0.4966 | AccuracyNumber: 76
	Batch_idx: 35 | Loss: 0.1039 | AccuracyNumber: 96
	Batch_idx: 36 | Loss: 0.0327 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.1280 | AccuracyNumber: 97
	Batch_idx: 38 | Loss: 0.7865 | AccuracyNumber: 85
	Batch_idx: 39 | Loss: 0.7615 | AccuracyNumber: 86
	Batch_idx: 40 | Loss: 2.7888 | AccuracyNumber: 16
	Batch_idx: 41 | Loss: 2.6769 | AccuracyNumber: 18
	Batch_idx: 42 | Loss: 2.6028 | AccuracyNumber: 22
	Batch_idx: 43 | Loss: 2.5996 | AccuracyNumber: 21
	Batch_idx: 44 | Loss: 2.7001 | AccuracyNumber: 16
	Batch_idx: 45 | Loss: 2.4387 | AccuracyNumber: 28
	Batch_idx: 46 | Loss: 2.5425 | AccuracyNumber: 20
	Batch_idx: 47 | Loss: 2.8132 | AccuracyNumber: 20
	Batch_idx: 48 | Loss: 1.1799 | AccuracyNumber: 36
	Batch_idx: 49 | Loss: 1.1812 | AccuracyNumber: 75
	Batch_idx: 50 | Loss: 1.0102 | AccuracyNumber: 88
	Batch_idx: 51 | Loss: 0.9677 | AccuracyNumber: 89
	Batch_idx: 52 | Loss: 1.2065 | AccuracyNumber: 89
	Batch_idx: 53 | Loss: 1.0384 | AccuracyNumber: 97
	Batch_idx: 54 | Loss: 1.0515 | AccuracyNumber: 84
	Batch_idx: 55 | Loss: 1.2893 | AccuracyNumber: 84
	Batch_idx: 56 | Loss: 1.2875 | AccuracyNumber: 88
	Batch_idx: 57 | Loss: 1.2522 | AccuracyNumber: 86
	Batch_idx: 58 | Loss: 1.0391 | AccuracyNumber: 91
	Batch_idx: 59 | Loss: 1.1733 | AccuracyNumber: 87
	Batch_idx: 60 | Loss: 0.2587 | AccuracyNumber: 97
	Batch_idx: 61 | Loss: 0.2704 | AccuracyNumber: 94
	Batch_idx: 62 | Loss: 0.2292 | AccuracyNumber: 97
	Batch_idx: 63 | Loss: 5.4560 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 1.0935 | AccuracyNumber: 90
	Batch_idx: 65 | Loss: 1.0700 | AccuracyNumber: 88
	Batch_idx: 66 | Loss: 1.1641 | AccuracyNumber: 85
	Batch_idx: 67 | Loss: 1.2043 | AccuracyNumber: 88
	Batch_idx: 68 | Loss: 1.3333 | AccuracyNumber: 32
	Batch_idx: 69 | Loss: 1.3307 | AccuracyNumber: 29
	Batch_idx: 70 | Loss: 1.2864 | AccuracyNumber: 31
	Batch_idx: 71 | Loss: 1.0631 | AccuracyNumber: 42
Testing Loss: 3.0792 | Testing Accuracy: 55.6389 | Time: 11.85
Epoch 11/120| Time: 2.01s| Loss: 0.9053
Epoch 12/120| Time: 1.91s| Loss: 0.5482
Epoch 13/120| Time: 1.87s| Loss: 0.5326
Epoch 14/120| Time: 1.84s| Loss: 0.4942
Epoch 15/120| Time: 1.84s| Loss: 0.4319
Epoch 16/120| Time: 1.85s| Loss: 0.4090
Epoch 17/120| Time: 1.84s| Loss: 0.3854
Epoch 18/120| Time: 1.83s| Loss: 0.3833
Epoch 19/120| Time: 1.84s| Loss: 0.3951
Epoch 20/120| Time: 1.85s| Loss: 0.3920
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC20.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC20.model model loaded--<<
	Batch_idx: 0 | Loss: 35.8964 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 34.3759 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 36.4239 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 36.8621 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.3746 | AccuracyNumber: 93
	Batch_idx: 5 | Loss: 0.7345 | AccuracyNumber: 86
	Batch_idx: 6 | Loss: 0.4944 | AccuracyNumber: 89
	Batch_idx: 7 | Loss: 0.4275 | AccuracyNumber: 91
	Batch_idx: 8 | Loss: 0.8738 | AccuracyNumber: 72
	Batch_idx: 9 | Loss: 0.5650 | AccuracyNumber: 83
	Batch_idx: 10 | Loss: 0.9171 | AccuracyNumber: 71
	Batch_idx: 11 | Loss: 1.0389 | AccuracyNumber: 73
	Batch_idx: 12 | Loss: 0.1747 | AccuracyNumber: 98
	Batch_idx: 13 | Loss: 0.1016 | AccuracyNumber: 98
	Batch_idx: 14 | Loss: 0.0238 | AccuracyNumber: 100
	Batch_idx: 15 | Loss: 0.1072 | AccuracyNumber: 96
	Batch_idx: 16 | Loss: 0.7843 | AccuracyNumber: 77
	Batch_idx: 17 | Loss: 0.9075 | AccuracyNumber: 73
	Batch_idx: 18 | Loss: 0.7427 | AccuracyNumber: 77
	Batch_idx: 19 | Loss: 0.5329 | AccuracyNumber: 85
	Batch_idx: 20 | Loss: 35.0136 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 35.9961 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 36.4587 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 37.8393 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2275 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.0900 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8042 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7854 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8008 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3845 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0135 | AccuracyNumber: 100
	Batch_idx: 31 | Loss: 0.0212 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0260 | AccuracyNumber: 99
	Batch_idx: 33 | Loss: 0.0767 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0570 | AccuracyNumber: 99
	Batch_idx: 35 | Loss: 0.0239 | AccuracyNumber: 99
	Batch_idx: 36 | Loss: 0.0273 | AccuracyNumber: 99
	Batch_idx: 37 | Loss: 0.0159 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0040 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.2622 | AccuracyNumber: 97
	Batch_idx: 40 | Loss: 0.4346 | AccuracyNumber: 88
	Batch_idx: 41 | Loss: 0.4283 | AccuracyNumber: 92
	Batch_idx: 42 | Loss: 0.4362 | AccuracyNumber: 87
	Batch_idx: 43 | Loss: 0.4988 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.4626 | AccuracyNumber: 88
	Batch_idx: 45 | Loss: 0.4479 | AccuracyNumber: 92
	Batch_idx: 46 | Loss: 0.3482 | AccuracyNumber: 91
	Batch_idx: 47 | Loss: 0.5582 | AccuracyNumber: 88
	Batch_idx: 48 | Loss: 0.0838 | AccuracyNumber: 99
	Batch_idx: 49 | Loss: 0.5383 | AccuracyNumber: 79
	Batch_idx: 50 | Loss: 0.6998 | AccuracyNumber: 81
	Batch_idx: 51 | Loss: 0.7520 | AccuracyNumber: 80
	Batch_idx: 52 | Loss: 0.7350 | AccuracyNumber: 80
	Batch_idx: 53 | Loss: 0.6508 | AccuracyNumber: 79
	Batch_idx: 54 | Loss: 0.7886 | AccuracyNumber: 77
	Batch_idx: 55 | Loss: 0.8402 | AccuracyNumber: 74
	Batch_idx: 56 | Loss: 0.9548 | AccuracyNumber: 76
	Batch_idx: 57 | Loss: 0.7452 | AccuracyNumber: 73
	Batch_idx: 58 | Loss: 0.3191 | AccuracyNumber: 88
	Batch_idx: 59 | Loss: 0.7115 | AccuracyNumber: 78
	Batch_idx: 60 | Loss: 0.2002 | AccuracyNumber: 93
	Batch_idx: 61 | Loss: 0.1118 | AccuracyNumber: 97
	Batch_idx: 62 | Loss: 0.3354 | AccuracyNumber: 92
	Batch_idx: 63 | Loss: 11.5778 | AccuracyNumber: 62
	Batch_idx: 64 | Loss: 0.7755 | AccuracyNumber: 76
	Batch_idx: 65 | Loss: 0.5286 | AccuracyNumber: 84
	Batch_idx: 66 | Loss: 0.7771 | AccuracyNumber: 78
	Batch_idx: 67 | Loss: 0.7837 | AccuracyNumber: 74
	Batch_idx: 68 | Loss: 0.0335 | AccuracyNumber: 99
	Batch_idx: 69 | Loss: 0.1753 | AccuracyNumber: 96
	Batch_idx: 70 | Loss: 0.1082 | AccuracyNumber: 99
	Batch_idx: 71 | Loss: 0.0257 | AccuracyNumber: 99
Testing Loss: 4.6271 | Testing Accuracy: 74.9861 | Time: 11.38
Epoch 21/120| Time: 356.10s| Loss: 0.3633
Epoch 22/120| Time: 2.04s| Loss: 0.3718
Epoch 23/120| Time: 2.02s| Loss: 0.4102
Epoch 24/120| Time: 2.02s| Loss: 0.3667
Epoch 25/120| Time: 2.05s| Loss: 0.3578
Epoch 26/120| Time: 2.05s| Loss: 0.3513
Epoch 27/120| Time: 2.04s| Loss: 0.3523
Epoch 28/120| Time: 2.05s| Loss: 0.3485
Epoch 29/120| Time: 2.04s| Loss: 0.3627
Epoch 30/120| Time: 2.06s| Loss: 0.3662
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC30.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC30.model model loaded--<<
	Batch_idx: 0 | Loss: 40.1229 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 38.6131 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 40.6882 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 40.7696 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1526 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.4273 | AccuracyNumber: 92
	Batch_idx: 6 | Loss: 0.2642 | AccuracyNumber: 94
	Batch_idx: 7 | Loss: 0.2839 | AccuracyNumber: 92
	Batch_idx: 8 | Loss: 0.4048 | AccuracyNumber: 87
	Batch_idx: 9 | Loss: 0.1387 | AccuracyNumber: 93
	Batch_idx: 10 | Loss: 0.2852 | AccuracyNumber: 89
	Batch_idx: 11 | Loss: 0.4634 | AccuracyNumber: 84
	Batch_idx: 12 | Loss: 0.2038 | AccuracyNumber: 94
	Batch_idx: 13 | Loss: 0.2485 | AccuracyNumber: 93
	Batch_idx: 14 | Loss: 0.0913 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.2935 | AccuracyNumber: 93
	Batch_idx: 16 | Loss: 0.3469 | AccuracyNumber: 93
	Batch_idx: 17 | Loss: 0.4145 | AccuracyNumber: 88
	Batch_idx: 18 | Loss: 0.2473 | AccuracyNumber: 95
	Batch_idx: 19 | Loss: 0.2419 | AccuracyNumber: 98
	Batch_idx: 20 | Loss: 39.1641 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 40.4497 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 40.1748 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 42.0327 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2725 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.1049 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8048 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7909 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8187 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.4155 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0706 | AccuracyNumber: 97
	Batch_idx: 31 | Loss: 0.0450 | AccuracyNumber: 98
	Batch_idx: 32 | Loss: 0.1127 | AccuracyNumber: 97
	Batch_idx: 33 | Loss: 0.1728 | AccuracyNumber: 94
	Batch_idx: 34 | Loss: 0.0991 | AccuracyNumber: 97
	Batch_idx: 35 | Loss: 0.0329 | AccuracyNumber: 99
	Batch_idx: 36 | Loss: 0.0005 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0238 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0038 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.3355 | AccuracyNumber: 96
	Batch_idx: 40 | Loss: 0.3679 | AccuracyNumber: 94
	Batch_idx: 41 | Loss: 0.3982 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.2327 | AccuracyNumber: 94
	Batch_idx: 43 | Loss: 0.2367 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1202 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.1881 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1926 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.3897 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0769 | AccuracyNumber: 98
	Batch_idx: 49 | Loss: 0.3166 | AccuracyNumber: 90
	Batch_idx: 50 | Loss: 0.1384 | AccuracyNumber: 95
	Batch_idx: 51 | Loss: 0.3901 | AccuracyNumber: 89
	Batch_idx: 52 | Loss: 0.2997 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2154 | AccuracyNumber: 92
	Batch_idx: 54 | Loss: 0.1995 | AccuracyNumber: 91
	Batch_idx: 55 | Loss: 0.3952 | AccuracyNumber: 92
	Batch_idx: 56 | Loss: 0.4665 | AccuracyNumber: 92
	Batch_idx: 57 | Loss: 0.2354 | AccuracyNumber: 91
	Batch_idx: 58 | Loss: 0.0802 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.2776 | AccuracyNumber: 95
	Batch_idx: 60 | Loss: 0.0448 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0048 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0703 | AccuracyNumber: 98
	Batch_idx: 63 | Loss: 12.5866 | AccuracyNumber: 65
	Batch_idx: 64 | Loss: 0.2594 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1436 | AccuracyNumber: 96
	Batch_idx: 66 | Loss: 0.2179 | AccuracyNumber: 90
	Batch_idx: 67 | Loss: 0.2904 | AccuracyNumber: 92
	Batch_idx: 68 | Loss: 0.0220 | AccuracyNumber: 99
	Batch_idx: 69 | Loss: 0.2509 | AccuracyNumber: 96
	Batch_idx: 70 | Loss: 0.1164 | AccuracyNumber: 99
	Batch_idx: 71 | Loss: 0.1200 | AccuracyNumber: 97
Testing Loss: 4.9302 | Testing Accuracy: 80.1111 | Time: 11.16
Epoch 31/120| Time: 2.21s| Loss: 0.3541
Epoch 32/120| Time: 2.03s| Loss: 0.3483
Epoch 33/120| Time: 2.04s| Loss: 0.3543
Epoch 34/120| Time: 2.04s| Loss: 0.3609
Epoch 35/120| Time: 2.02s| Loss: 0.3642
Epoch 36/120| Time: 2.03s| Loss: 0.3705
Epoch 37/120| Time: 2.04s| Loss: 0.3573
Epoch 38/120| Time: 2.02s| Loss: 0.3473
Epoch 39/120| Time: 2.03s| Loss: 0.3482
Epoch 40/120| Time: 2.01s| Loss: 0.3468
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC40.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC40.model model loaded--<<
	Batch_idx: 0 | Loss: 36.9990 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 35.8233 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 37.6549 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 37.7519 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1483 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.5444 | AccuracyNumber: 90
	Batch_idx: 6 | Loss: 0.2675 | AccuracyNumber: 95
	Batch_idx: 7 | Loss: 0.3195 | AccuracyNumber: 94
	Batch_idx: 8 | Loss: 0.3992 | AccuracyNumber: 89
	Batch_idx: 9 | Loss: 0.2605 | AccuracyNumber: 94
	Batch_idx: 10 | Loss: 0.2848 | AccuracyNumber: 92
	Batch_idx: 11 | Loss: 0.6397 | AccuracyNumber: 87
	Batch_idx: 12 | Loss: 0.1340 | AccuracyNumber: 96
	Batch_idx: 13 | Loss: 0.1410 | AccuracyNumber: 97
	Batch_idx: 14 | Loss: 0.0646 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.1688 | AccuracyNumber: 94
	Batch_idx: 16 | Loss: 0.3842 | AccuracyNumber: 92
	Batch_idx: 17 | Loss: 0.3539 | AccuracyNumber: 90
	Batch_idx: 18 | Loss: 0.3739 | AccuracyNumber: 92
	Batch_idx: 19 | Loss: 0.2077 | AccuracyNumber: 97
	Batch_idx: 20 | Loss: 36.2646 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 37.4523 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 37.2276 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 38.9292 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2589 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.1032 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8045 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7893 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8110 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3821 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0297 | AccuracyNumber: 99
	Batch_idx: 31 | Loss: 0.0135 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0434 | AccuracyNumber: 97
	Batch_idx: 33 | Loss: 0.1414 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0795 | AccuracyNumber: 98
	Batch_idx: 35 | Loss: 0.0652 | AccuracyNumber: 98
	Batch_idx: 36 | Loss: 0.0018 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0245 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0026 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.3154 | AccuracyNumber: 96
	Batch_idx: 40 | Loss: 0.4322 | AccuracyNumber: 95
	Batch_idx: 41 | Loss: 0.4361 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.3170 | AccuracyNumber: 92
	Batch_idx: 43 | Loss: 0.3019 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1722 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.2063 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1862 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.4813 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0011 | AccuracyNumber: 100
	Batch_idx: 49 | Loss: 0.2011 | AccuracyNumber: 92
	Batch_idx: 50 | Loss: 0.3855 | AccuracyNumber: 94
	Batch_idx: 51 | Loss: 0.5626 | AccuracyNumber: 90
	Batch_idx: 52 | Loss: 0.2954 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2715 | AccuracyNumber: 93
	Batch_idx: 54 | Loss: 0.4571 | AccuracyNumber: 91
	Batch_idx: 55 | Loss: 0.2837 | AccuracyNumber: 93
	Batch_idx: 56 | Loss: 0.4112 | AccuracyNumber: 94
	Batch_idx: 57 | Loss: 0.2027 | AccuracyNumber: 93
	Batch_idx: 58 | Loss: 0.0590 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.3575 | AccuracyNumber: 93
	Batch_idx: 60 | Loss: 0.0184 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0053 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0550 | AccuracyNumber: 96
	Batch_idx: 63 | Loss: 11.6665 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 0.3278 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1893 | AccuracyNumber: 97
	Batch_idx: 66 | Loss: 0.5202 | AccuracyNumber: 91
	Batch_idx: 67 | Loss: 0.2775 | AccuracyNumber: 95
	Batch_idx: 68 | Loss: 0.0015 | AccuracyNumber: 100
	Batch_idx: 69 | Loss: 0.0974 | AccuracyNumber: 97
	Batch_idx: 70 | Loss: 0.0221 | AccuracyNumber: 99
	Batch_idx: 71 | Loss: 0.0002 | AccuracyNumber: 100
Testing Loss: 4.5953 | Testing Accuracy: 80.6111 | Time: 11.17
Epoch 41/120| Time: 2.14s| Loss: 0.3470
Epoch 42/120| Time: 2.06s| Loss: 0.3469
Epoch 43/120| Time: 2.05s| Loss: 0.3468
Epoch 44/120| Time: 2.06s| Loss: 0.3468
Epoch 45/120| Time: 2.04s| Loss: 0.3468
Epoch 46/120| Time: 2.06s| Loss: 0.3468
Epoch 47/120| Time: 2.04s| Loss: 0.3468
Epoch 48/120| Time: 2.05s| Loss: 0.3468
Epoch 49/120| Time: 2.05s| Loss: 0.3468
Epoch 50/120| Time: 2.05s| Loss: 0.3468
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC50.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC50.model model loaded--<<
	Batch_idx: 0 | Loss: 37.0073 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 35.8807 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 37.6820 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 37.7708 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1528 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.5503 | AccuracyNumber: 90
	Batch_idx: 6 | Loss: 0.2718 | AccuracyNumber: 95
	Batch_idx: 7 | Loss: 0.3220 | AccuracyNumber: 94
	Batch_idx: 8 | Loss: 0.4137 | AccuracyNumber: 88
	Batch_idx: 9 | Loss: 0.2669 | AccuracyNumber: 94
	Batch_idx: 10 | Loss: 0.2745 | AccuracyNumber: 92
	Batch_idx: 11 | Loss: 0.6426 | AccuracyNumber: 87
	Batch_idx: 12 | Loss: 0.1381 | AccuracyNumber: 96
	Batch_idx: 13 | Loss: 0.1463 | AccuracyNumber: 97
	Batch_idx: 14 | Loss: 0.0657 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.1668 | AccuracyNumber: 94
	Batch_idx: 16 | Loss: 0.3781 | AccuracyNumber: 93
	Batch_idx: 17 | Loss: 0.3484 | AccuracyNumber: 90
	Batch_idx: 18 | Loss: 0.3692 | AccuracyNumber: 92
	Batch_idx: 19 | Loss: 0.2014 | AccuracyNumber: 97
	Batch_idx: 20 | Loss: 36.3173 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 37.4950 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 37.2728 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 38.9638 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2583 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.1030 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8045 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7898 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8114 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3917 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0398 | AccuracyNumber: 98
	Batch_idx: 31 | Loss: 0.0158 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0393 | AccuracyNumber: 97
	Batch_idx: 33 | Loss: 0.1406 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0828 | AccuracyNumber: 98
	Batch_idx: 35 | Loss: 0.0373 | AccuracyNumber: 98
	Batch_idx: 36 | Loss: 0.0006 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0243 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0026 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.3142 | AccuracyNumber: 96
	Batch_idx: 40 | Loss: 0.4388 | AccuracyNumber: 95
	Batch_idx: 41 | Loss: 0.4406 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.3203 | AccuracyNumber: 92
	Batch_idx: 43 | Loss: 0.3056 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1743 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.2059 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1881 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.4859 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0033 | AccuracyNumber: 100
	Batch_idx: 49 | Loss: 0.2062 | AccuracyNumber: 92
	Batch_idx: 50 | Loss: 0.3779 | AccuracyNumber: 93
	Batch_idx: 51 | Loss: 0.5714 | AccuracyNumber: 90
	Batch_idx: 52 | Loss: 0.2976 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2822 | AccuracyNumber: 93
	Batch_idx: 54 | Loss: 0.4386 | AccuracyNumber: 92
	Batch_idx: 55 | Loss: 0.2712 | AccuracyNumber: 94
	Batch_idx: 56 | Loss: 0.4040 | AccuracyNumber: 94
	Batch_idx: 57 | Loss: 0.2010 | AccuracyNumber: 93
	Batch_idx: 58 | Loss: 0.0581 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.3581 | AccuracyNumber: 93
	Batch_idx: 60 | Loss: 0.0209 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0050 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0594 | AccuracyNumber: 96
	Batch_idx: 63 | Loss: 11.6793 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 0.3327 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1851 | AccuracyNumber: 97
	Batch_idx: 66 | Loss: 0.5079 | AccuracyNumber: 91
	Batch_idx: 67 | Loss: 0.2710 | AccuracyNumber: 95
	Batch_idx: 68 | Loss: 0.0016 | AccuracyNumber: 100
	Batch_idx: 69 | Loss: 0.1247 | AccuracyNumber: 97
	Batch_idx: 70 | Loss: 0.0418 | AccuracyNumber: 99
	Batch_idx: 71 | Loss: 0.0006 | AccuracyNumber: 100
Testing Loss: 4.6002 | Testing Accuracy: 80.6111 | Time: 11.12
Epoch 51/120| Time: 2.14s| Loss: 0.3467
Epoch 52/120| Time: 2.04s| Loss: 0.3467
Epoch 53/120| Time: 2.03s| Loss: 0.3467
Epoch 54/120| Time: 2.05s| Loss: 0.3467
Epoch 55/120| Time: 2.04s| Loss: 0.3467
Epoch 56/120| Time: 2.05s| Loss: 0.3467
Epoch 57/120| Time: 2.03s| Loss: 0.3467
Epoch 58/120| Time: 2.04s| Loss: 0.3467
Epoch 59/120| Time: 2.03s| Loss: 0.3467
Epoch 60/120| Time: 2.04s| Loss: 0.3467
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC60.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC60.model model loaded--<<
	Batch_idx: 0 | Loss: 36.8788 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 35.7734 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 37.5559 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 37.6436 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1561 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.5525 | AccuracyNumber: 90
	Batch_idx: 6 | Loss: 0.2736 | AccuracyNumber: 95
	Batch_idx: 7 | Loss: 0.3239 | AccuracyNumber: 94
	Batch_idx: 8 | Loss: 0.4212 | AccuracyNumber: 88
	Batch_idx: 9 | Loss: 0.2712 | AccuracyNumber: 94
	Batch_idx: 10 | Loss: 0.2718 | AccuracyNumber: 92
	Batch_idx: 11 | Loss: 0.6450 | AccuracyNumber: 87
	Batch_idx: 12 | Loss: 0.1382 | AccuracyNumber: 96
	Batch_idx: 13 | Loss: 0.1447 | AccuracyNumber: 97
	Batch_idx: 14 | Loss: 0.0650 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.1655 | AccuracyNumber: 94
	Batch_idx: 16 | Loss: 0.3762 | AccuracyNumber: 93
	Batch_idx: 17 | Loss: 0.3469 | AccuracyNumber: 90
	Batch_idx: 18 | Loss: 0.3692 | AccuracyNumber: 92
	Batch_idx: 19 | Loss: 0.1992 | AccuracyNumber: 97
	Batch_idx: 20 | Loss: 36.2077 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 37.3768 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 37.1573 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 38.8366 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2558 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.1015 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8046 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7903 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8119 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3946 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0432 | AccuracyNumber: 98
	Batch_idx: 31 | Loss: 0.0163 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0361 | AccuracyNumber: 98
	Batch_idx: 33 | Loss: 0.1395 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0833 | AccuracyNumber: 98
	Batch_idx: 35 | Loss: 0.0305 | AccuracyNumber: 98
	Batch_idx: 36 | Loss: 0.0005 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0233 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0025 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.3099 | AccuracyNumber: 96
	Batch_idx: 40 | Loss: 0.4423 | AccuracyNumber: 95
	Batch_idx: 41 | Loss: 0.4429 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.3213 | AccuracyNumber: 92
	Batch_idx: 43 | Loss: 0.3077 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1762 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.2066 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1882 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.4881 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0045 | AccuracyNumber: 100
	Batch_idx: 49 | Loss: 0.2076 | AccuracyNumber: 92
	Batch_idx: 50 | Loss: 0.3758 | AccuracyNumber: 93
	Batch_idx: 51 | Loss: 0.5747 | AccuracyNumber: 90
	Batch_idx: 52 | Loss: 0.2977 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2874 | AccuracyNumber: 93
	Batch_idx: 54 | Loss: 0.4327 | AccuracyNumber: 92
	Batch_idx: 55 | Loss: 0.2664 | AccuracyNumber: 94
	Batch_idx: 56 | Loss: 0.4023 | AccuracyNumber: 94
	Batch_idx: 57 | Loss: 0.2012 | AccuracyNumber: 93
	Batch_idx: 58 | Loss: 0.0573 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.3568 | AccuracyNumber: 93
	Batch_idx: 60 | Loss: 0.0227 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0049 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0609 | AccuracyNumber: 96
	Batch_idx: 63 | Loss: 11.6423 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 0.3347 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1838 | AccuracyNumber: 97
	Batch_idx: 66 | Loss: 0.5056 | AccuracyNumber: 91
	Batch_idx: 67 | Loss: 0.2680 | AccuracyNumber: 95
	Batch_idx: 68 | Loss: 0.0016 | AccuracyNumber: 100
	Batch_idx: 69 | Loss: 0.1345 | AccuracyNumber: 96
	Batch_idx: 70 | Loss: 0.0479 | AccuracyNumber: 99
	Batch_idx: 71 | Loss: 0.0009 | AccuracyNumber: 100
Testing Loss: 4.5867 | Testing Accuracy: 80.6111 | Time: 11.69
Epoch 61/120| Time: 2.04s| Loss: 0.3467
Epoch 62/120| Time: 2.01s| Loss: 0.3467
Epoch 63/120| Time: 2.02s| Loss: 0.3467
Epoch 64/120| Time: 2.03s| Loss: 0.3467
Epoch 65/120| Time: 2.02s| Loss: 0.3467
Epoch 66/120| Time: 2.05s| Loss: 0.3467
Epoch 67/120| Time: 2.01s| Loss: 0.3467
Epoch 68/120| Time: 2.02s| Loss: 0.3467
Epoch 69/120| Time: 2.02s| Loss: 0.3467
Epoch 70/120| Time: 2.02s| Loss: 0.3467
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC70.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC70.model model loaded--<<
	Batch_idx: 0 | Loss: 36.7272 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 35.6391 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 37.4049 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 37.4922 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1579 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.5527 | AccuracyNumber: 90
	Batch_idx: 6 | Loss: 0.2743 | AccuracyNumber: 95
	Batch_idx: 7 | Loss: 0.3246 | AccuracyNumber: 94
	Batch_idx: 8 | Loss: 0.4273 | AccuracyNumber: 88
	Batch_idx: 9 | Loss: 0.2756 | AccuracyNumber: 94
	Batch_idx: 10 | Loss: 0.2715 | AccuracyNumber: 92
	Batch_idx: 11 | Loss: 0.6484 | AccuracyNumber: 87
	Batch_idx: 12 | Loss: 0.1378 | AccuracyNumber: 96
	Batch_idx: 13 | Loss: 0.1434 | AccuracyNumber: 97
	Batch_idx: 14 | Loss: 0.0640 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.1645 | AccuracyNumber: 94
	Batch_idx: 16 | Loss: 0.3756 | AccuracyNumber: 93
	Batch_idx: 17 | Loss: 0.3462 | AccuracyNumber: 90
	Batch_idx: 18 | Loss: 0.3705 | AccuracyNumber: 92
	Batch_idx: 19 | Loss: 0.1976 | AccuracyNumber: 97
	Batch_idx: 20 | Loss: 36.0717 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 37.2318 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 37.0152 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 38.6833 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2531 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.0998 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8046 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7907 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8122 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3967 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0456 | AccuracyNumber: 98
	Batch_idx: 31 | Loss: 0.0167 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0337 | AccuracyNumber: 98
	Batch_idx: 33 | Loss: 0.1389 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0837 | AccuracyNumber: 98
	Batch_idx: 35 | Loss: 0.0263 | AccuracyNumber: 98
	Batch_idx: 36 | Loss: 0.0004 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0221 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0024 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.3052 | AccuracyNumber: 96
	Batch_idx: 40 | Loss: 0.4437 | AccuracyNumber: 95
	Batch_idx: 41 | Loss: 0.4439 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.3211 | AccuracyNumber: 92
	Batch_idx: 43 | Loss: 0.3082 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1772 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.2066 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1879 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.4889 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0056 | AccuracyNumber: 100
	Batch_idx: 49 | Loss: 0.2087 | AccuracyNumber: 92
	Batch_idx: 50 | Loss: 0.3768 | AccuracyNumber: 93
	Batch_idx: 51 | Loss: 0.5777 | AccuracyNumber: 90
	Batch_idx: 52 | Loss: 0.2977 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2919 | AccuracyNumber: 93
	Batch_idx: 54 | Loss: 0.4310 | AccuracyNumber: 92
	Batch_idx: 55 | Loss: 0.2636 | AccuracyNumber: 94
	Batch_idx: 56 | Loss: 0.4013 | AccuracyNumber: 94
	Batch_idx: 57 | Loss: 0.2024 | AccuracyNumber: 93
	Batch_idx: 58 | Loss: 0.0569 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.3564 | AccuracyNumber: 93
	Batch_idx: 60 | Loss: 0.0240 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0049 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0619 | AccuracyNumber: 96
	Batch_idx: 63 | Loss: 11.5971 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 0.3369 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1836 | AccuracyNumber: 97
	Batch_idx: 66 | Loss: 0.5062 | AccuracyNumber: 91
	Batch_idx: 67 | Loss: 0.2666 | AccuracyNumber: 95
	Batch_idx: 68 | Loss: 0.0015 | AccuracyNumber: 100
	Batch_idx: 69 | Loss: 0.1416 | AccuracyNumber: 96
	Batch_idx: 70 | Loss: 0.0520 | AccuracyNumber: 98
	Batch_idx: 71 | Loss: 0.0012 | AccuracyNumber: 100
Testing Loss: 4.5702 | Testing Accuracy: 80.5972 | Time: 11.11
Epoch 71/120| Time: 2.05s| Loss: 0.3467
Epoch 72/120| Time: 2.02s| Loss: 0.3467
Epoch 73/120| Time: 2.02s| Loss: 0.3467
Epoch 74/120| Time: 2.04s| Loss: 0.3467
Epoch 75/120| Time: 2.00s| Loss: 0.3467
Epoch 76/120| Time: 2.07s| Loss: 0.3467
Epoch 77/120| Time: 2.06s| Loss: 0.3467
Epoch 78/120| Time: 2.06s| Loss: 0.3467
Epoch 79/120| Time: 2.05s| Loss: 0.3467
Epoch 80/120| Time: 2.05s| Loss: 0.3467
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC80.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC80.model model loaded--<<
	Batch_idx: 0 | Loss: 36.5571 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 35.4841 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 37.2342 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 37.3218 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1593 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.5525 | AccuracyNumber: 89
	Batch_idx: 6 | Loss: 0.2745 | AccuracyNumber: 95
	Batch_idx: 7 | Loss: 0.3249 | AccuracyNumber: 94
	Batch_idx: 8 | Loss: 0.4311 | AccuracyNumber: 88
	Batch_idx: 9 | Loss: 0.2787 | AccuracyNumber: 94
	Batch_idx: 10 | Loss: 0.2705 | AccuracyNumber: 92
	Batch_idx: 11 | Loss: 0.6498 | AccuracyNumber: 87
	Batch_idx: 12 | Loss: 0.1371 | AccuracyNumber: 96
	Batch_idx: 13 | Loss: 0.1420 | AccuracyNumber: 97
	Batch_idx: 14 | Loss: 0.0633 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.1636 | AccuracyNumber: 94
	Batch_idx: 16 | Loss: 0.3748 | AccuracyNumber: 93
	Batch_idx: 17 | Loss: 0.3453 | AccuracyNumber: 90
	Batch_idx: 18 | Loss: 0.3712 | AccuracyNumber: 92
	Batch_idx: 19 | Loss: 0.1962 | AccuracyNumber: 97
	Batch_idx: 20 | Loss: 35.9154 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 37.0659 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 36.8519 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 38.5090 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2501 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.0979 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8047 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7911 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8126 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3980 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0471 | AccuracyNumber: 98
	Batch_idx: 31 | Loss: 0.0169 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0318 | AccuracyNumber: 98
	Batch_idx: 33 | Loss: 0.1382 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0838 | AccuracyNumber: 98
	Batch_idx: 35 | Loss: 0.0235 | AccuracyNumber: 99
	Batch_idx: 36 | Loss: 0.0003 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0208 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0023 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.3002 | AccuracyNumber: 97
	Batch_idx: 40 | Loss: 0.4444 | AccuracyNumber: 95
	Batch_idx: 41 | Loss: 0.4445 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.3206 | AccuracyNumber: 92
	Batch_idx: 43 | Loss: 0.3083 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1780 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.2065 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1874 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.4892 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0064 | AccuracyNumber: 100
	Batch_idx: 49 | Loss: 0.2091 | AccuracyNumber: 92
	Batch_idx: 50 | Loss: 0.3765 | AccuracyNumber: 93
	Batch_idx: 51 | Loss: 0.5791 | AccuracyNumber: 90
	Batch_idx: 52 | Loss: 0.2972 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2949 | AccuracyNumber: 93
	Batch_idx: 54 | Loss: 0.4286 | AccuracyNumber: 92
	Batch_idx: 55 | Loss: 0.2608 | AccuracyNumber: 94
	Batch_idx: 56 | Loss: 0.4003 | AccuracyNumber: 94
	Batch_idx: 57 | Loss: 0.2030 | AccuracyNumber: 93
	Batch_idx: 58 | Loss: 0.0564 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.3551 | AccuracyNumber: 93
	Batch_idx: 60 | Loss: 0.0251 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0048 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0625 | AccuracyNumber: 96
	Batch_idx: 63 | Loss: 11.5457 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 0.3376 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1832 | AccuracyNumber: 97
	Batch_idx: 66 | Loss: 0.5058 | AccuracyNumber: 91
	Batch_idx: 67 | Loss: 0.2649 | AccuracyNumber: 95
	Batch_idx: 68 | Loss: 0.0015 | AccuracyNumber: 100
	Batch_idx: 69 | Loss: 0.1465 | AccuracyNumber: 96
	Batch_idx: 70 | Loss: 0.0548 | AccuracyNumber: 98
	Batch_idx: 71 | Loss: 0.0014 | AccuracyNumber: 100
Testing Loss: 4.5510 | Testing Accuracy: 80.6111 | Time: 11.31
Epoch 81/120| Time: 2.08s| Loss: 0.3467
Epoch 82/120| Time: 2.04s| Loss: 0.3467
Epoch 83/120| Time: 2.03s| Loss: 0.3467
Epoch 84/120| Time: 2.05s| Loss: 0.3467
Epoch 85/120| Time: 2.06s| Loss: 0.3467
Epoch 86/120| Time: 2.07s| Loss: 0.3467
Epoch 87/120| Time: 2.05s| Loss: 0.3467
Epoch 88/120| Time: 2.04s| Loss: 0.3467
Epoch 89/120| Time: 2.07s| Loss: 0.3467
Epoch 90/120| Time: 2.04s| Loss: 0.3467
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC90.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC90.model model loaded--<<
	Batch_idx: 0 | Loss: 36.5399 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 35.4683 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 37.2169 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 37.3045 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1594 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.5524 | AccuracyNumber: 89
	Batch_idx: 6 | Loss: 0.2745 | AccuracyNumber: 95
	Batch_idx: 7 | Loss: 0.3249 | AccuracyNumber: 94
	Batch_idx: 8 | Loss: 0.4314 | AccuracyNumber: 88
	Batch_idx: 9 | Loss: 0.2791 | AccuracyNumber: 94
	Batch_idx: 10 | Loss: 0.2705 | AccuracyNumber: 92
	Batch_idx: 11 | Loss: 0.6500 | AccuracyNumber: 87
	Batch_idx: 12 | Loss: 0.1370 | AccuracyNumber: 96
	Batch_idx: 13 | Loss: 0.1419 | AccuracyNumber: 97
	Batch_idx: 14 | Loss: 0.0632 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.1635 | AccuracyNumber: 94
	Batch_idx: 16 | Loss: 0.3747 | AccuracyNumber: 93
	Batch_idx: 17 | Loss: 0.3452 | AccuracyNumber: 90
	Batch_idx: 18 | Loss: 0.3713 | AccuracyNumber: 92
	Batch_idx: 19 | Loss: 0.1961 | AccuracyNumber: 97
	Batch_idx: 20 | Loss: 35.8994 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 37.0490 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 36.8353 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 38.4913 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2498 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.0977 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8047 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7911 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8126 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3981 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0472 | AccuracyNumber: 98
	Batch_idx: 31 | Loss: 0.0169 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0316 | AccuracyNumber: 98
	Batch_idx: 33 | Loss: 0.1381 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0838 | AccuracyNumber: 98
	Batch_idx: 35 | Loss: 0.0233 | AccuracyNumber: 99
	Batch_idx: 36 | Loss: 0.0003 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0207 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0023 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.2997 | AccuracyNumber: 97
	Batch_idx: 40 | Loss: 0.4444 | AccuracyNumber: 95
	Batch_idx: 41 | Loss: 0.4445 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.3206 | AccuracyNumber: 92
	Batch_idx: 43 | Loss: 0.3083 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1781 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.2065 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1873 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.4891 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0065 | AccuracyNumber: 100
	Batch_idx: 49 | Loss: 0.2092 | AccuracyNumber: 92
	Batch_idx: 50 | Loss: 0.3766 | AccuracyNumber: 93
	Batch_idx: 51 | Loss: 0.5793 | AccuracyNumber: 90
	Batch_idx: 52 | Loss: 0.2972 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2952 | AccuracyNumber: 93
	Batch_idx: 54 | Loss: 0.4285 | AccuracyNumber: 92
	Batch_idx: 55 | Loss: 0.2605 | AccuracyNumber: 94
	Batch_idx: 56 | Loss: 0.4002 | AccuracyNumber: 94
	Batch_idx: 57 | Loss: 0.2031 | AccuracyNumber: 93
	Batch_idx: 58 | Loss: 0.0564 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.3550 | AccuracyNumber: 93
	Batch_idx: 60 | Loss: 0.0252 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0048 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0626 | AccuracyNumber: 96
	Batch_idx: 63 | Loss: 11.5405 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 0.3377 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1832 | AccuracyNumber: 97
	Batch_idx: 66 | Loss: 0.5058 | AccuracyNumber: 91
	Batch_idx: 67 | Loss: 0.2648 | AccuracyNumber: 95
	Batch_idx: 68 | Loss: 0.0015 | AccuracyNumber: 100
	Batch_idx: 69 | Loss: 0.1469 | AccuracyNumber: 96
	Batch_idx: 70 | Loss: 0.0550 | AccuracyNumber: 98
	Batch_idx: 71 | Loss: 0.0015 | AccuracyNumber: 100
Testing Loss: 4.5491 | Testing Accuracy: 80.6111 | Time: 11.07
Epoch 91/120| Time: 2.05s| Loss: 0.3467
Epoch 92/120| Time: 2.05s| Loss: 0.3467
Epoch 93/120| Time: 2.05s| Loss: 0.3467
Epoch 94/120| Time: 2.04s| Loss: 0.3467
Epoch 95/120| Time: 2.05s| Loss: 0.3467
Epoch 96/120| Time: 2.05s| Loss: 0.3467
Epoch 97/120| Time: 2.05s| Loss: 0.3467
Epoch 98/120| Time: 2.05s| Loss: 0.3467
Epoch 99/120| Time: 2.04s| Loss: 0.3467
Epoch 100/120| Time: 2.05s| Loss: 0.3467
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC100.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC100.model model loaded--<<
	Batch_idx: 0 | Loss: 36.5226 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 35.4525 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 37.1996 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 37.2872 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1595 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.5523 | AccuracyNumber: 89
	Batch_idx: 6 | Loss: 0.2745 | AccuracyNumber: 95
	Batch_idx: 7 | Loss: 0.3249 | AccuracyNumber: 94
	Batch_idx: 8 | Loss: 0.4318 | AccuracyNumber: 88
	Batch_idx: 9 | Loss: 0.2794 | AccuracyNumber: 94
	Batch_idx: 10 | Loss: 0.2705 | AccuracyNumber: 92
	Batch_idx: 11 | Loss: 0.6502 | AccuracyNumber: 87
	Batch_idx: 12 | Loss: 0.1370 | AccuracyNumber: 96
	Batch_idx: 13 | Loss: 0.1418 | AccuracyNumber: 97
	Batch_idx: 14 | Loss: 0.0631 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.1634 | AccuracyNumber: 94
	Batch_idx: 16 | Loss: 0.3747 | AccuracyNumber: 93
	Batch_idx: 17 | Loss: 0.3452 | AccuracyNumber: 90
	Batch_idx: 18 | Loss: 0.3715 | AccuracyNumber: 92
	Batch_idx: 19 | Loss: 0.1960 | AccuracyNumber: 97
	Batch_idx: 20 | Loss: 35.8835 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 37.0322 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 36.8186 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 38.4736 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2495 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.0976 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8047 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7912 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8127 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3983 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0474 | AccuracyNumber: 98
	Batch_idx: 31 | Loss: 0.0169 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0314 | AccuracyNumber: 98
	Batch_idx: 33 | Loss: 0.1381 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0838 | AccuracyNumber: 98
	Batch_idx: 35 | Loss: 0.0231 | AccuracyNumber: 99
	Batch_idx: 36 | Loss: 0.0003 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0206 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0023 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.2992 | AccuracyNumber: 97
	Batch_idx: 40 | Loss: 0.4444 | AccuracyNumber: 95
	Batch_idx: 41 | Loss: 0.4445 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.3205 | AccuracyNumber: 92
	Batch_idx: 43 | Loss: 0.3083 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1782 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.2065 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1873 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.4891 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0066 | AccuracyNumber: 100
	Batch_idx: 49 | Loss: 0.2092 | AccuracyNumber: 92
	Batch_idx: 50 | Loss: 0.3767 | AccuracyNumber: 93
	Batch_idx: 51 | Loss: 0.5794 | AccuracyNumber: 90
	Batch_idx: 52 | Loss: 0.2972 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2955 | AccuracyNumber: 93
	Batch_idx: 54 | Loss: 0.4284 | AccuracyNumber: 92
	Batch_idx: 55 | Loss: 0.2603 | AccuracyNumber: 94
	Batch_idx: 56 | Loss: 0.4001 | AccuracyNumber: 94
	Batch_idx: 57 | Loss: 0.2032 | AccuracyNumber: 93
	Batch_idx: 58 | Loss: 0.0563 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.3550 | AccuracyNumber: 93
	Batch_idx: 60 | Loss: 0.0253 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0049 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0627 | AccuracyNumber: 96
	Batch_idx: 63 | Loss: 11.5353 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 0.3378 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1832 | AccuracyNumber: 97
	Batch_idx: 66 | Loss: 0.5059 | AccuracyNumber: 91
	Batch_idx: 67 | Loss: 0.2647 | AccuracyNumber: 95
	Batch_idx: 68 | Loss: 0.0015 | AccuracyNumber: 100
	Batch_idx: 69 | Loss: 0.1473 | AccuracyNumber: 96
	Batch_idx: 70 | Loss: 0.0553 | AccuracyNumber: 98
	Batch_idx: 71 | Loss: 0.0015 | AccuracyNumber: 100
Testing Loss: 4.5471 | Testing Accuracy: 80.6111 | Time: 10.98
Epoch 101/120| Time: 2.08s| Loss: 0.3467
Epoch 102/120| Time: 2.04s| Loss: 0.3467
Epoch 103/120| Time: 2.04s| Loss: 0.3467
Epoch 104/120| Time: 2.05s| Loss: 0.3467
Epoch 105/120| Time: 2.04s| Loss: 0.3467
Epoch 106/120| Time: 2.06s| Loss: 0.3467
Epoch 107/120| Time: 2.04s| Loss: 0.3467
Epoch 108/120| Time: 2.03s| Loss: 0.3467
Epoch 109/120| Time: 2.01s| Loss: 0.3467
Epoch 110/120| Time: 2.01s| Loss: 0.3467
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC110.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC110.model model loaded--<<
	Batch_idx: 0 | Loss: 36.5053 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 35.4365 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 37.1821 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 37.2698 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1596 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.5522 | AccuracyNumber: 89
	Batch_idx: 6 | Loss: 0.2745 | AccuracyNumber: 95
	Batch_idx: 7 | Loss: 0.3249 | AccuracyNumber: 94
	Batch_idx: 8 | Loss: 0.4321 | AccuracyNumber: 88
	Batch_idx: 9 | Loss: 0.2797 | AccuracyNumber: 94
	Batch_idx: 10 | Loss: 0.2704 | AccuracyNumber: 92
	Batch_idx: 11 | Loss: 0.6503 | AccuracyNumber: 87
	Batch_idx: 12 | Loss: 0.1369 | AccuracyNumber: 96
	Batch_idx: 13 | Loss: 0.1416 | AccuracyNumber: 97
	Batch_idx: 14 | Loss: 0.0631 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.1634 | AccuracyNumber: 94
	Batch_idx: 16 | Loss: 0.3747 | AccuracyNumber: 93
	Batch_idx: 17 | Loss: 0.3451 | AccuracyNumber: 90
	Batch_idx: 18 | Loss: 0.3716 | AccuracyNumber: 92
	Batch_idx: 19 | Loss: 0.1958 | AccuracyNumber: 97
	Batch_idx: 20 | Loss: 35.8674 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 37.0151 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 36.8018 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 38.4557 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2492 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.0974 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8047 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7912 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8127 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3984 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0475 | AccuracyNumber: 98
	Batch_idx: 31 | Loss: 0.0169 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0313 | AccuracyNumber: 98
	Batch_idx: 33 | Loss: 0.1380 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0838 | AccuracyNumber: 98
	Batch_idx: 35 | Loss: 0.0228 | AccuracyNumber: 99
	Batch_idx: 36 | Loss: 0.0003 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0205 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0023 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.2987 | AccuracyNumber: 97
	Batch_idx: 40 | Loss: 0.4444 | AccuracyNumber: 95
	Batch_idx: 41 | Loss: 0.4445 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.3204 | AccuracyNumber: 92
	Batch_idx: 43 | Loss: 0.3082 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1782 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.2064 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1872 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.4891 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0067 | AccuracyNumber: 100
	Batch_idx: 49 | Loss: 0.2093 | AccuracyNumber: 92
	Batch_idx: 50 | Loss: 0.3767 | AccuracyNumber: 93
	Batch_idx: 51 | Loss: 0.5796 | AccuracyNumber: 90
	Batch_idx: 52 | Loss: 0.2971 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2958 | AccuracyNumber: 93
	Batch_idx: 54 | Loss: 0.4283 | AccuracyNumber: 92
	Batch_idx: 55 | Loss: 0.2601 | AccuracyNumber: 94
	Batch_idx: 56 | Loss: 0.4000 | AccuracyNumber: 94
	Batch_idx: 57 | Loss: 0.2032 | AccuracyNumber: 93
	Batch_idx: 58 | Loss: 0.0563 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.3549 | AccuracyNumber: 93
	Batch_idx: 60 | Loss: 0.0254 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0049 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0628 | AccuracyNumber: 96
	Batch_idx: 63 | Loss: 11.5300 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 0.3378 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1831 | AccuracyNumber: 97
	Batch_idx: 66 | Loss: 0.5059 | AccuracyNumber: 91
	Batch_idx: 67 | Loss: 0.2645 | AccuracyNumber: 95
	Batch_idx: 68 | Loss: 0.0015 | AccuracyNumber: 100
	Batch_idx: 69 | Loss: 0.1477 | AccuracyNumber: 96
	Batch_idx: 70 | Loss: 0.0555 | AccuracyNumber: 98
	Batch_idx: 71 | Loss: 0.0015 | AccuracyNumber: 100
Testing Loss: 4.5452 | Testing Accuracy: 80.6111 | Time: 11.25
Epoch 111/120| Time: 2.07s| Loss: 0.3467
Epoch 112/120| Time: 2.05s| Loss: 0.3467
Epoch 113/120| Time: 2.04s| Loss: 0.3467
Epoch 114/120| Time: 2.05s| Loss: 0.3467
Epoch 115/120| Time: 2.04s| Loss: 0.3467
Epoch 116/120| Time: 2.05s| Loss: 0.3467
Epoch 117/120| Time: 2.04s| Loss: 0.3467
Epoch 118/120| Time: 2.04s| Loss: 0.3467
Epoch 119/120| Time: 2.06s| Loss: 0.3467
Epoch 120/120| Time: 2.04s| Loss: 0.3467
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC120.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size21/SimpleFC_2019-01-04_22-15-02/SimpleFC120.model model loaded--<<
	Batch_idx: 0 | Loss: 36.4877 | AccuracyNumber: 0
	Batch_idx: 1 | Loss: 35.4203 | AccuracyNumber: 0
	Batch_idx: 2 | Loss: 37.1645 | AccuracyNumber: 0
	Batch_idx: 3 | Loss: 37.2522 | AccuracyNumber: 0
	Batch_idx: 4 | Loss: 0.1597 | AccuracyNumber: 94
	Batch_idx: 5 | Loss: 0.5521 | AccuracyNumber: 89
	Batch_idx: 6 | Loss: 0.2745 | AccuracyNumber: 95
	Batch_idx: 7 | Loss: 0.3249 | AccuracyNumber: 94
	Batch_idx: 8 | Loss: 0.4324 | AccuracyNumber: 88
	Batch_idx: 9 | Loss: 0.2800 | AccuracyNumber: 94
	Batch_idx: 10 | Loss: 0.2705 | AccuracyNumber: 92
	Batch_idx: 11 | Loss: 0.6506 | AccuracyNumber: 87
	Batch_idx: 12 | Loss: 0.1368 | AccuracyNumber: 96
	Batch_idx: 13 | Loss: 0.1415 | AccuracyNumber: 97
	Batch_idx: 14 | Loss: 0.0629 | AccuracyNumber: 98
	Batch_idx: 15 | Loss: 0.1633 | AccuracyNumber: 94
	Batch_idx: 16 | Loss: 0.3746 | AccuracyNumber: 93
	Batch_idx: 17 | Loss: 0.3450 | AccuracyNumber: 90
	Batch_idx: 18 | Loss: 0.3717 | AccuracyNumber: 92
	Batch_idx: 19 | Loss: 0.1957 | AccuracyNumber: 97
	Batch_idx: 20 | Loss: 35.8511 | AccuracyNumber: 0
	Batch_idx: 21 | Loss: 36.9979 | AccuracyNumber: 0
	Batch_idx: 22 | Loss: 36.7848 | AccuracyNumber: 0
	Batch_idx: 23 | Loss: 38.4377 | AccuracyNumber: 0
	Batch_idx: 24 | Loss: 0.2489 | AccuracyNumber: 98
	Batch_idx: 25 | Loss: 0.0972 | AccuracyNumber: 99
	Batch_idx: 26 | Loss: 0.8047 | AccuracyNumber: 71
	Batch_idx: 27 | Loss: 2.7912 | AccuracyNumber: 0
	Batch_idx: 28 | Loss: 2.8128 | AccuracyNumber: 0
	Batch_idx: 29 | Loss: 1.3985 | AccuracyNumber: 50
	Batch_idx: 30 | Loss: 0.0476 | AccuracyNumber: 98
	Batch_idx: 31 | Loss: 0.0169 | AccuracyNumber: 99
	Batch_idx: 32 | Loss: 0.0311 | AccuracyNumber: 98
	Batch_idx: 33 | Loss: 0.1379 | AccuracyNumber: 97
	Batch_idx: 34 | Loss: 0.0838 | AccuracyNumber: 98
	Batch_idx: 35 | Loss: 0.0226 | AccuracyNumber: 99
	Batch_idx: 36 | Loss: 0.0003 | AccuracyNumber: 100
	Batch_idx: 37 | Loss: 0.0204 | AccuracyNumber: 99
	Batch_idx: 38 | Loss: 0.0023 | AccuracyNumber: 100
	Batch_idx: 39 | Loss: 0.2982 | AccuracyNumber: 97
	Batch_idx: 40 | Loss: 0.4444 | AccuracyNumber: 95
	Batch_idx: 41 | Loss: 0.4446 | AccuracyNumber: 94
	Batch_idx: 42 | Loss: 0.3203 | AccuracyNumber: 92
	Batch_idx: 43 | Loss: 0.3082 | AccuracyNumber: 92
	Batch_idx: 44 | Loss: 0.1783 | AccuracyNumber: 96
	Batch_idx: 45 | Loss: 0.2064 | AccuracyNumber: 96
	Batch_idx: 46 | Loss: 0.1872 | AccuracyNumber: 96
	Batch_idx: 47 | Loss: 0.4891 | AccuracyNumber: 92
	Batch_idx: 48 | Loss: 0.0067 | AccuracyNumber: 100
	Batch_idx: 49 | Loss: 0.2093 | AccuracyNumber: 92
	Batch_idx: 50 | Loss: 0.3769 | AccuracyNumber: 93
	Batch_idx: 51 | Loss: 0.5798 | AccuracyNumber: 90
	Batch_idx: 52 | Loss: 0.2971 | AccuracyNumber: 94
	Batch_idx: 53 | Loss: 0.2960 | AccuracyNumber: 93
	Batch_idx: 54 | Loss: 0.4283 | AccuracyNumber: 92
	Batch_idx: 55 | Loss: 0.2599 | AccuracyNumber: 94
	Batch_idx: 56 | Loss: 0.3999 | AccuracyNumber: 94
	Batch_idx: 57 | Loss: 0.2033 | AccuracyNumber: 93
	Batch_idx: 58 | Loss: 0.0563 | AccuracyNumber: 98
	Batch_idx: 59 | Loss: 0.3548 | AccuracyNumber: 93
	Batch_idx: 60 | Loss: 0.0254 | AccuracyNumber: 99
	Batch_idx: 61 | Loss: 0.0049 | AccuracyNumber: 100
	Batch_idx: 62 | Loss: 0.0628 | AccuracyNumber: 96
	Batch_idx: 63 | Loss: 11.5247 | AccuracyNumber: 66
	Batch_idx: 64 | Loss: 0.3379 | AccuracyNumber: 94
	Batch_idx: 65 | Loss: 0.1832 | AccuracyNumber: 97
	Batch_idx: 66 | Loss: 0.5060 | AccuracyNumber: 91
	Batch_idx: 67 | Loss: 0.2644 | AccuracyNumber: 95
	Batch_idx: 68 | Loss: 0.0015 | AccuracyNumber: 100
	Batch_idx: 69 | Loss: 0.1481 | AccuracyNumber: 96
	Batch_idx: 70 | Loss: 0.0557 | AccuracyNumber: 98
	Batch_idx: 71 | Loss: 0.0015 | AccuracyNumber: 100
Testing Loss: 4.5432 | Testing Accuracy: 80.6111 | Time: 10.90
