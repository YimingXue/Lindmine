#######################PARAMETERS######################## Dataset selection
	maxTrain: True
	max_trainData: 200
# train/test parameters	model_name: ResNetv2
	optimizer: SGD
	epochs: 80
	batch_size: 100
	seed: 80
	lr: 0.01
	weight_decay: 0.0001
# data preparation parameters
	dataset: crop_43
	patch_size: 29
	band: 63
	num_classes: 15
	train_percent: 0.01
	val_percent: 0.0
	test_percent: 0.25

#############################  MODEL  ###################################

ResNetv2(
  (conv): Sequential(
    (0): Conv2d(63, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)
  )
  (relu): ReLU()
  (block1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (downsample1): Sequential(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (downsample2): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=32768, out_features=2048, bias=True)
    (1): Dropout(p=0.2)
    (2): ReLU(inplace)
    (3): Linear(in_features=2048, out_features=1024, bias=True)
    (4): Dropout(p=0.2)
    (5): ReLU(inplace)
    (6): Linear(in_features=1024, out_features=15, bias=True)
  )
  (Softmax): Softmax()
)
##############################################################################

Epoch 1/80| Time: 3.69s| Loss: 3.0754
Epoch 2/80| Time: 3.59s| Loss: 2.1186
Epoch 3/80| Time: 3.52s| Loss: 1.6769
Epoch 4/80| Time: 3.54s| Loss: 1.3698
Epoch 5/80| Time: 3.71s| Loss: 0.9814
Epoch 6/80| Time: 3.64s| Loss: 0.6922
Epoch 7/80| Time: 3.67s| Loss: 0.5196
Epoch 8/80| Time: 3.60s| Loss: 0.4345
Epoch 9/80| Time: 3.60s| Loss: 0.3400
Epoch 10/80| Time: 4.02s| Loss: 0.2782
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv210.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv210.model model loaded--<<
	Batch_idx: 0 | Loss: 4.2289 | Accuracy: 10
	Batch_idx: 50 | Loss: 4.8375 | Accuracy: 10
	Batch_idx: 100 | Loss: 4.2525 | Accuracy: 17
	Batch_idx: 150 | Loss: 4.7288 | Accuracy: 15
	Batch_idx: 200 | Loss: 4.2678 | Accuracy: 19
	Batch_idx: 250 | Loss: 4.3695 | Accuracy: 14
	Batch_idx: 300 | Loss: 3.9042 | Accuracy: 19
	Batch_idx: 350 | Loss: 4.8763 | Accuracy: 15
	Batch_idx: 400 | Loss: 4.2639 | Accuracy: 16
	Batch_idx: 450 | Loss: 2.1664 | Accuracy: 42
	Batch_idx: 500 | Loss: 0.8563 | Accuracy: 72
	Batch_idx: 550 | Loss: 0.8215 | Accuracy: 80
	Batch_idx: 600 | Loss: 0.8805 | Accuracy: 76
	Batch_idx: 650 | Loss: 1.9040 | Accuracy: 33
	Batch_idx: 700 | Loss: 1.9590 | Accuracy: 36
	Batch_idx: 750 | Loss: 1.9868 | Accuracy: 28
	Batch_idx: 800 | Loss: 1.9997 | Accuracy: 39
	Batch_idx: 850 | Loss: 2.1249 | Accuracy: 33
	Batch_idx: 900 | Loss: 1.7442 | Accuracy: 39
	Batch_idx: 950 | Loss: 0.8676 | Accuracy: 69
	Batch_idx: 1000 | Loss: 1.1110 | Accuracy: 75
	Batch_idx: 1050 | Loss: 0.7615 | Accuracy: 73
	Batch_idx: 1100 | Loss: 0.7399 | Accuracy: 76
	Batch_idx: 1150 | Loss: 1.0220 | Accuracy: 62
	Batch_idx: 1200 | Loss: 0.9086 | Accuracy: 68
	Batch_idx: 1250 | Loss: 0.8998 | Accuracy: 75
	Batch_idx: 1300 | Loss: 3.5499 | Accuracy: 34
	Batch_idx: 1350 | Loss: 0.5409 | Accuracy: 89
	Batch_idx: 1400 | Loss: 0.4875 | Accuracy: 90
	Batch_idx: 1450 | Loss: 2.6514 | Accuracy: 34
	Batch_idx: 1500 | Loss: 2.1296 | Accuracy: 49
	Batch_idx: 1550 | Loss: 2.5305 | Accuracy: 39
	Batch_idx: 1600 | Loss: 2.7871 | Accuracy: 34
	Batch_idx: 1650 | Loss: 2.7376 | Accuracy: 38
	Batch_idx: 1700 | Loss: 2.6040 | Accuracy: 37
	Batch_idx: 1750 | Loss: 4.1686 | Accuracy: 17
	Batch_idx: 1800 | Loss: 3.7963 | Accuracy: 20
	Batch_idx: 1850 | Loss: 3.5260 | Accuracy: 21
	Batch_idx: 1900 | Loss: 3.8220 | Accuracy: 21
	Batch_idx: 1950 | Loss: 3.7920 | Accuracy: 22
	Batch_idx: 2000 | Loss: 3.4075 | Accuracy: 28
	Batch_idx: 2050 | Loss: 3.7290 | Accuracy: 23
	Batch_idx: 2100 | Loss: 1.1094 | Accuracy: 66
	Batch_idx: 2150 | Loss: 1.0249 | Accuracy: 63
	Batch_idx: 2200 | Loss: 1.3919 | Accuracy: 59
	Batch_idx: 2250 | Loss: 1.4105 | Accuracy: 69
	Batch_idx: 2300 | Loss: 2.3789 | Accuracy: 34
	Batch_idx: 2350 | Loss: 2.2634 | Accuracy: 37
	Batch_idx: 2400 | Loss: 2.4459 | Accuracy: 36
	Batch_idx: 2450 | Loss: 3.6401 | Accuracy: 31
	Batch_idx: 2500 | Loss: 2.9906 | Accuracy: 41
	Batch_idx: 2550 | Loss: 3.6217 | Accuracy: 37
	Batch_idx: 2600 | Loss: 3.9267 | Accuracy: 31
	Batch_idx: 2650 | Loss: 3.3367 | Accuracy: 34
	Batch_idx: 2700 | Loss: 2.5192 | Accuracy: 33
	Batch_idx: 2750 | Loss: 2.3084 | Accuracy: 33
	Batch_idx: 2800 | Loss: 2.6042 | Accuracy: 42
	Batch_idx: 2850 | Loss: 2.6825 | Accuracy: 28
	Batch_idx: 2900 | Loss: 3.2142 | Accuracy: 27
	Batch_idx: 2950 | Loss: 2.3916 | Accuracy: 39
	Batch_idx: 3000 | Loss: 3.3208 | Accuracy: 27
	Batch_idx: 3050 | Loss: 2.8351 | Accuracy: 30
	Batch_idx: 3100 | Loss: 2.4706 | Accuracy: 30
	Batch_idx: 3150 | Loss: 1.9663 | Accuracy: 42
	Batch_idx: 3200 | Loss: 2.7018 | Accuracy: 33
	Batch_idx: 3250 | Loss: 3.0501 | Accuracy: 26
	Batch_idx: 3300 | Loss: 2.4107 | Accuracy: 28
	Batch_idx: 3350 | Loss: 2.7659 | Accuracy: 35
	Batch_idx: 3400 | Loss: 2.7593 | Accuracy: 35
	Batch_idx: 3450 | Loss: 1.9467 | Accuracy: 39
	Batch_idx: 3500 | Loss: 2.8940 | Accuracy: 31
	Batch_idx: 3550 | Loss: 2.2585 | Accuracy: 46
	Batch_idx: 3600 | Loss: 2.5576 | Accuracy: 34
	Batch_idx: 3650 | Loss: 2.4687 | Accuracy: 41
	Batch_idx: 3700 | Loss: 2.8119 | Accuracy: 33
	Batch_idx: 3750 | Loss: 2.3005 | Accuracy: 38
	Batch_idx: 3800 | Loss: 2.5479 | Accuracy: 38
	Batch_idx: 3850 | Loss: 2.7368 | Accuracy: 34
	Batch_idx: 3900 | Loss: 2.0756 | Accuracy: 42
	Batch_idx: 3950 | Loss: 2.2149 | Accuracy: 32
	Batch_idx: 4000 | Loss: 2.3082 | Accuracy: 39
	Batch_idx: 4050 | Loss: 2.8009 | Accuracy: 28
	Batch_idx: 4100 | Loss: 2.3727 | Accuracy: 30
	Batch_idx: 4150 | Loss: 2.3528 | Accuracy: 39
	Batch_idx: 4200 | Loss: 4.3484 | Accuracy: 14
	Batch_idx: 4250 | Loss: 4.7364 | Accuracy: 8
	Batch_idx: 4300 | Loss: 4.0723 | Accuracy: 13
	Batch_idx: 4350 | Loss: 4.7839 | Accuracy: 9
	Batch_idx: 4400 | Loss: 4.5377 | Accuracy: 12
	Batch_idx: 4450 | Loss: 4.7657 | Accuracy: 13
	Batch_idx: 4500 | Loss: 5.0898 | Accuracy: 4
	Batch_idx: 4550 | Loss: 4.7226 | Accuracy: 8
	Batch_idx: 4600 | Loss: 4.4428 | Accuracy: 14
	Batch_idx: 4650 | Loss: 4.8937 | Accuracy: 9
	Batch_idx: 4700 | Loss: 4.2864 | Accuracy: 8
	Batch_idx: 4750 | Loss: 4.6872 | Accuracy: 9
	Batch_idx: 4800 | Loss: 0.5428 | Accuracy: 84
	Batch_idx: 4850 | Loss: 0.7600 | Accuracy: 73
  Class 0, accuracy: 16.70
  Class 1, accuracy: 40.68
  Class 2, accuracy: 76.75
  Class 3, accuracy: 34.06
  Class 4, accuracy: 70.75
  Class 5, accuracy: 39.53
  Class 6, accuracy: 86.27
  Class 7, accuracy: 40.26
  Class 8, accuracy: 20.78
  Class 9, accuracy: 66.09
  Class 10, accuracy: 39.28
  Class 11, accuracy: 31.63
  Class 12, accuracy: 35.68
  Class 13, accuracy: 12.35
  Class 14, accuracy: 76.25
Testing Loss: 2.7152 | OA: 37.30 | AA: 45.80 | Kappa: 34.00 | Time: 723.75
Epoch 11/80| Time: 3.58s| Loss: 0.2394
Epoch 12/80| Time: 3.55s| Loss: 0.1960
Epoch 13/80| Time: 3.54s| Loss: 0.1181
Epoch 14/80| Time: 3.61s| Loss: 0.1006
Epoch 15/80| Time: 3.53s| Loss: 0.0924
Epoch 16/80| Time: 3.45s| Loss: 0.0693
Epoch 17/80| Time: 3.46s| Loss: 0.0606
Epoch 18/80| Time: 3.52s| Loss: 0.0694
Epoch 19/80| Time: 3.53s| Loss: 0.0704
Epoch 20/80| Time: 3.56s| Loss: 0.0724
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv220.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv220.model model loaded--<<
	Batch_idx: 0 | Loss: 4.6555 | Accuracy: 21
	Batch_idx: 50 | Loss: 5.9890 | Accuracy: 17
	Batch_idx: 100 | Loss: 4.5157 | Accuracy: 21
	Batch_idx: 150 | Loss: 6.0144 | Accuracy: 21
	Batch_idx: 200 | Loss: 5.0901 | Accuracy: 21
	Batch_idx: 250 | Loss: 5.1229 | Accuracy: 14
	Batch_idx: 300 | Loss: 4.8914 | Accuracy: 26
	Batch_idx: 350 | Loss: 5.4943 | Accuracy: 20
	Batch_idx: 400 | Loss: 4.3972 | Accuracy: 24
	Batch_idx: 450 | Loss: 3.9615 | Accuracy: 28
	Batch_idx: 500 | Loss: 1.7118 | Accuracy: 66
	Batch_idx: 550 | Loss: 1.2344 | Accuracy: 66
	Batch_idx: 600 | Loss: 1.3674 | Accuracy: 73
	Batch_idx: 650 | Loss: 4.3368 | Accuracy: 31
	Batch_idx: 700 | Loss: 3.5429 | Accuracy: 33
	Batch_idx: 750 | Loss: 3.6148 | Accuracy: 35
	Batch_idx: 800 | Loss: 4.1889 | Accuracy: 26
	Batch_idx: 850 | Loss: 4.0655 | Accuracy: 23
	Batch_idx: 900 | Loss: 4.2937 | Accuracy: 27
	Batch_idx: 950 | Loss: 2.3557 | Accuracy: 56
	Batch_idx: 1000 | Loss: 2.8424 | Accuracy: 49
	Batch_idx: 1050 | Loss: 1.3116 | Accuracy: 67
	Batch_idx: 1100 | Loss: 1.9498 | Accuracy: 56
	Batch_idx: 1150 | Loss: 2.9126 | Accuracy: 41
	Batch_idx: 1200 | Loss: 2.4592 | Accuracy: 47
	Batch_idx: 1250 | Loss: 2.3985 | Accuracy: 44
	Batch_idx: 1300 | Loss: 1.2011 | Accuracy: 72
	Batch_idx: 1350 | Loss: 1.1390 | Accuracy: 81
	Batch_idx: 1400 | Loss: 0.6783 | Accuracy: 86
	Batch_idx: 1450 | Loss: 2.6845 | Accuracy: 48
	Batch_idx: 1500 | Loss: 2.2750 | Accuracy: 56
	Batch_idx: 1550 | Loss: 2.4965 | Accuracy: 52
	Batch_idx: 1600 | Loss: 2.6278 | Accuracy: 42
	Batch_idx: 1650 | Loss: 2.7630 | Accuracy: 48
	Batch_idx: 1700 | Loss: 2.3176 | Accuracy: 47
	Batch_idx: 1750 | Loss: 2.5538 | Accuracy: 46
	Batch_idx: 1800 | Loss: 1.7809 | Accuracy: 62
	Batch_idx: 1850 | Loss: 1.3688 | Accuracy: 66
	Batch_idx: 1900 | Loss: 2.1802 | Accuracy: 55
	Batch_idx: 1950 | Loss: 2.4089 | Accuracy: 55
	Batch_idx: 2000 | Loss: 2.0065 | Accuracy: 54
	Batch_idx: 2050 | Loss: 1.6894 | Accuracy: 56
	Batch_idx: 2100 | Loss: 2.4124 | Accuracy: 60
	Batch_idx: 2150 | Loss: 2.2574 | Accuracy: 63
	Batch_idx: 2200 | Loss: 2.1271 | Accuracy: 63
	Batch_idx: 2250 | Loss: 2.4510 | Accuracy: 56
	Batch_idx: 2300 | Loss: 0.6245 | Accuracy: 83
	Batch_idx: 2350 | Loss: 0.7233 | Accuracy: 74
	Batch_idx: 2400 | Loss: 0.6797 | Accuracy: 81
	Batch_idx: 2450 | Loss: 2.9990 | Accuracy: 48
	Batch_idx: 2500 | Loss: 2.3290 | Accuracy: 50
	Batch_idx: 2550 | Loss: 3.1212 | Accuracy: 49
	Batch_idx: 2600 | Loss: 3.0950 | Accuracy: 49
	Batch_idx: 2650 | Loss: 2.9804 | Accuracy: 49
	Batch_idx: 2700 | Loss: 4.4528 | Accuracy: 23
	Batch_idx: 2750 | Loss: 3.8856 | Accuracy: 34
	Batch_idx: 2800 | Loss: 4.2106 | Accuracy: 30
	Batch_idx: 2850 | Loss: 4.4649 | Accuracy: 27
	Batch_idx: 2900 | Loss: 4.9829 | Accuracy: 20
	Batch_idx: 2950 | Loss: 4.3399 | Accuracy: 28
	Batch_idx: 3000 | Loss: 4.5658 | Accuracy: 25
	Batch_idx: 3050 | Loss: 3.9711 | Accuracy: 32
	Batch_idx: 3100 | Loss: 3.9686 | Accuracy: 30
	Batch_idx: 3150 | Loss: 3.3687 | Accuracy: 36
	Batch_idx: 3200 | Loss: 4.8416 | Accuracy: 21
	Batch_idx: 3250 | Loss: 4.1848 | Accuracy: 23
	Batch_idx: 3300 | Loss: 4.4991 | Accuracy: 27
	Batch_idx: 3350 | Loss: 4.0175 | Accuracy: 33
	Batch_idx: 3400 | Loss: 4.8710 | Accuracy: 20
	Batch_idx: 3450 | Loss: 3.3194 | Accuracy: 33
	Batch_idx: 3500 | Loss: 4.5070 | Accuracy: 28
	Batch_idx: 3550 | Loss: 3.3645 | Accuracy: 34
	Batch_idx: 3600 | Loss: 4.3846 | Accuracy: 23
	Batch_idx: 3650 | Loss: 4.3991 | Accuracy: 30
	Batch_idx: 3700 | Loss: 4.3466 | Accuracy: 30
	Batch_idx: 3750 | Loss: 3.7575 | Accuracy: 28
	Batch_idx: 3800 | Loss: 4.0668 | Accuracy: 28
	Batch_idx: 3850 | Loss: 4.5231 | Accuracy: 22
	Batch_idx: 3900 | Loss: 3.7989 | Accuracy: 32
	Batch_idx: 3950 | Loss: 3.9459 | Accuracy: 30
	Batch_idx: 4000 | Loss: 3.8222 | Accuracy: 33
	Batch_idx: 4050 | Loss: 4.4037 | Accuracy: 31
	Batch_idx: 4100 | Loss: 4.2850 | Accuracy: 25
	Batch_idx: 4150 | Loss: 3.6461 | Accuracy: 31
	Batch_idx: 4200 | Loss: 5.0497 | Accuracy: 22
	Batch_idx: 4250 | Loss: 5.5802 | Accuracy: 18
	Batch_idx: 4300 | Loss: 5.1295 | Accuracy: 16
	Batch_idx: 4350 | Loss: 5.2491 | Accuracy: 15
	Batch_idx: 4400 | Loss: 5.3365 | Accuracy: 21
	Batch_idx: 4450 | Loss: 4.9454 | Accuracy: 23
	Batch_idx: 4500 | Loss: 5.5009 | Accuracy: 16
	Batch_idx: 4550 | Loss: 5.2541 | Accuracy: 17
	Batch_idx: 4600 | Loss: 5.3077 | Accuracy: 18
	Batch_idx: 4650 | Loss: 6.0487 | Accuracy: 17
	Batch_idx: 4700 | Loss: 5.2619 | Accuracy: 18
	Batch_idx: 4750 | Loss: 5.5383 | Accuracy: 22
	Batch_idx: 4800 | Loss: 0.1443 | Accuracy: 94
	Batch_idx: 4850 | Loss: 0.0366 | Accuracy: 98
  Class 0, accuracy: 21.91
  Class 1, accuracy: 31.90
  Class 2, accuracy: 69.54
  Class 3, accuracy: 30.28
  Class 4, accuracy: 53.18
  Class 5, accuracy: 74.50
  Class 6, accuracy: 78.29
  Class 7, accuracy: 51.17
  Class 8, accuracy: 56.65
  Class 9, accuracy: 59.68
  Class 10, accuracy: 77.88
  Class 11, accuracy: 46.62
  Class 12, accuracy: 29.25
  Class 13, accuracy: 18.65
  Class 14, accuracy: 94.88
Testing Loss: 3.4327 | OA: 39.95 | AA: 52.96 | Kappa: 37.01 | Time: 695.58
Epoch 21/80| Time: 3.42s| Loss: 0.0281
Epoch 22/80| Time: 3.45s| Loss: 0.0133
Epoch 23/80| Time: 3.44s| Loss: 0.0079
Epoch 24/80| Time: 3.45s| Loss: 0.0069
Epoch 25/80| Time: 3.43s| Loss: 0.0072
Epoch 26/80| Time: 3.43s| Loss: 0.0040
Epoch 27/80| Time: 3.46s| Loss: 0.0046
Epoch 28/80| Time: 3.46s| Loss: 0.0045
Epoch 29/80| Time: 3.45s| Loss: 0.0040
Epoch 30/80| Time: 3.48s| Loss: 0.0037
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv230.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv230.model model loaded--<<
	Batch_idx: 0 | Loss: 5.5429 | Accuracy: 17
	Batch_idx: 50 | Loss: 6.6560 | Accuracy: 13
	Batch_idx: 100 | Loss: 5.4349 | Accuracy: 21
	Batch_idx: 150 | Loss: 6.8785 | Accuracy: 17
	Batch_idx: 200 | Loss: 6.0563 | Accuracy: 19
	Batch_idx: 250 | Loss: 5.9085 | Accuracy: 14
	Batch_idx: 300 | Loss: 5.6553 | Accuracy: 19
	Batch_idx: 350 | Loss: 6.4425 | Accuracy: 16
	Batch_idx: 400 | Loss: 5.0648 | Accuracy: 22
	Batch_idx: 450 | Loss: 3.6185 | Accuracy: 42
	Batch_idx: 500 | Loss: 2.0584 | Accuracy: 66
	Batch_idx: 550 | Loss: 1.5686 | Accuracy: 64
	Batch_idx: 600 | Loss: 1.4128 | Accuracy: 78
	Batch_idx: 650 | Loss: 3.6067 | Accuracy: 42
	Batch_idx: 700 | Loss: 2.6031 | Accuracy: 52
	Batch_idx: 750 | Loss: 2.6921 | Accuracy: 50
	Batch_idx: 800 | Loss: 3.2824 | Accuracy: 43
	Batch_idx: 850 | Loss: 3.3751 | Accuracy: 42
	Batch_idx: 900 | Loss: 3.2868 | Accuracy: 42
	Batch_idx: 950 | Loss: 2.9370 | Accuracy: 53
	Batch_idx: 1000 | Loss: 2.8557 | Accuracy: 51
	Batch_idx: 1050 | Loss: 1.4862 | Accuracy: 57
	Batch_idx: 1100 | Loss: 1.9782 | Accuracy: 55
	Batch_idx: 1150 | Loss: 3.2421 | Accuracy: 43
	Batch_idx: 1200 | Loss: 2.5497 | Accuracy: 50
	Batch_idx: 1250 | Loss: 2.5159 | Accuracy: 48
	Batch_idx: 1300 | Loss: 1.4680 | Accuracy: 70
	Batch_idx: 1350 | Loss: 0.8972 | Accuracy: 87
	Batch_idx: 1400 | Loss: 0.5256 | Accuracy: 88
	Batch_idx: 1450 | Loss: 1.6433 | Accuracy: 60
	Batch_idx: 1500 | Loss: 1.4591 | Accuracy: 67
	Batch_idx: 1550 | Loss: 1.6320 | Accuracy: 64
	Batch_idx: 1600 | Loss: 1.8953 | Accuracy: 61
	Batch_idx: 1650 | Loss: 1.8668 | Accuracy: 62
	Batch_idx: 1700 | Loss: 1.3667 | Accuracy: 65
	Batch_idx: 1750 | Loss: 3.0050 | Accuracy: 46
	Batch_idx: 1800 | Loss: 2.2752 | Accuracy: 53
	Batch_idx: 1850 | Loss: 1.9526 | Accuracy: 59
	Batch_idx: 1900 | Loss: 2.6189 | Accuracy: 51
	Batch_idx: 1950 | Loss: 2.8390 | Accuracy: 51
	Batch_idx: 2000 | Loss: 2.4019 | Accuracy: 56
	Batch_idx: 2050 | Loss: 2.2208 | Accuracy: 52
	Batch_idx: 2100 | Loss: 1.1221 | Accuracy: 80
	Batch_idx: 2150 | Loss: 1.1264 | Accuracy: 81
	Batch_idx: 2200 | Loss: 1.1210 | Accuracy: 79
	Batch_idx: 2250 | Loss: 1.3807 | Accuracy: 77
	Batch_idx: 2300 | Loss: 0.7411 | Accuracy: 82
	Batch_idx: 2350 | Loss: 0.8939 | Accuracy: 73
	Batch_idx: 2400 | Loss: 0.8138 | Accuracy: 78
	Batch_idx: 2450 | Loss: 2.5966 | Accuracy: 54
	Batch_idx: 2500 | Loss: 2.0081 | Accuracy: 63
	Batch_idx: 2550 | Loss: 2.7859 | Accuracy: 51
	Batch_idx: 2600 | Loss: 2.6003 | Accuracy: 59
	Batch_idx: 2650 | Loss: 2.5661 | Accuracy: 56
	Batch_idx: 2700 | Loss: 5.3313 | Accuracy: 19
	Batch_idx: 2750 | Loss: 4.7034 | Accuracy: 22
	Batch_idx: 2800 | Loss: 5.0256 | Accuracy: 24
	Batch_idx: 2850 | Loss: 5.5202 | Accuracy: 22
	Batch_idx: 2900 | Loss: 6.2209 | Accuracy: 9
	Batch_idx: 2950 | Loss: 5.4481 | Accuracy: 21
	Batch_idx: 3000 | Loss: 5.8368 | Accuracy: 26
	Batch_idx: 3050 | Loss: 4.9857 | Accuracy: 24
	Batch_idx: 3100 | Loss: 4.8624 | Accuracy: 22
	Batch_idx: 3150 | Loss: 4.1474 | Accuracy: 31
	Batch_idx: 3200 | Loss: 5.7817 | Accuracy: 19
	Batch_idx: 3250 | Loss: 5.3475 | Accuracy: 20
	Batch_idx: 3300 | Loss: 5.3275 | Accuracy: 23
	Batch_idx: 3350 | Loss: 5.0569 | Accuracy: 24
	Batch_idx: 3400 | Loss: 5.9305 | Accuracy: 20
	Batch_idx: 3450 | Loss: 4.2224 | Accuracy: 30
	Batch_idx: 3500 | Loss: 5.6053 | Accuracy: 23
	Batch_idx: 3550 | Loss: 4.2146 | Accuracy: 30
	Batch_idx: 3600 | Loss: 5.3577 | Accuracy: 23
	Batch_idx: 3650 | Loss: 5.3744 | Accuracy: 24
	Batch_idx: 3700 | Loss: 5.3691 | Accuracy: 27
	Batch_idx: 3750 | Loss: 4.8078 | Accuracy: 23
	Batch_idx: 3800 | Loss: 5.1489 | Accuracy: 20
	Batch_idx: 3850 | Loss: 5.5172 | Accuracy: 19
	Batch_idx: 3900 | Loss: 4.5389 | Accuracy: 30
	Batch_idx: 3950 | Loss: 4.6328 | Accuracy: 27
	Batch_idx: 4000 | Loss: 4.7956 | Accuracy: 28
	Batch_idx: 4050 | Loss: 5.4688 | Accuracy: 20
	Batch_idx: 4100 | Loss: 4.9970 | Accuracy: 20
	Batch_idx: 4150 | Loss: 4.5980 | Accuracy: 32
	Batch_idx: 4200 | Loss: 5.7501 | Accuracy: 22
	Batch_idx: 4250 | Loss: 6.3293 | Accuracy: 16
	Batch_idx: 4300 | Loss: 5.5096 | Accuracy: 21
	Batch_idx: 4350 | Loss: 5.7240 | Accuracy: 14
	Batch_idx: 4400 | Loss: 5.8410 | Accuracy: 22
	Batch_idx: 4450 | Loss: 5.5165 | Accuracy: 23
	Batch_idx: 4500 | Loss: 6.0731 | Accuracy: 17
	Batch_idx: 4550 | Loss: 5.8878 | Accuracy: 15
	Batch_idx: 4600 | Loss: 5.7310 | Accuracy: 21
	Batch_idx: 4650 | Loss: 6.5001 | Accuracy: 17
	Batch_idx: 4700 | Loss: 5.7961 | Accuracy: 19
	Batch_idx: 4750 | Loss: 6.3051 | Accuracy: 22
	Batch_idx: 4800 | Loss: 0.1155 | Accuracy: 94
	Batch_idx: 4850 | Loss: 0.0897 | Accuracy: 97
  Class 0, accuracy: 18.18
  Class 1, accuracy: 37.96
  Class 2, accuracy: 68.67
  Class 3, accuracy: 45.73
  Class 4, accuracy: 54.41
  Class 5, accuracy: 72.36
  Class 6, accuracy: 83.22
  Class 7, accuracy: 66.20
  Class 8, accuracy: 51.98
  Class 9, accuracy: 77.27
  Class 10, accuracy: 75.65
  Class 11, accuracy: 54.03
  Class 12, accuracy: 23.63
  Class 13, accuracy: 19.60
  Class 14, accuracy: 95.05
Testing Loss: 3.7620 | OA: 40.56 | AA: 56.26 | Kappa: 37.94 | Time: 726.15
Epoch 31/80| Time: 5.36s| Loss: 0.0038
Epoch 32/80| Time: 5.55s| Loss: 0.0030
Epoch 33/80| Time: 4.04s| Loss: 0.0030
Epoch 34/80| Time: 3.47s| Loss: 0.0031
Epoch 35/80| Time: 3.50s| Loss: 0.0028
Epoch 36/80| Time: 4.69s| Loss: 0.0027
Epoch 37/80| Time: 5.05s| Loss: 0.0024
Epoch 38/80| Time: 4.93s| Loss: 0.0023
Epoch 39/80| Time: 4.80s| Loss: 0.0017
Epoch 40/80| Time: 4.68s| Loss: 0.0029
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv240.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv240.model model loaded--<<
	Batch_idx: 0 | Loss: 5.7254 | Accuracy: 16
	Batch_idx: 50 | Loss: 6.8220 | Accuracy: 13
	Batch_idx: 100 | Loss: 5.5497 | Accuracy: 21
	Batch_idx: 150 | Loss: 7.0597 | Accuracy: 17
	Batch_idx: 200 | Loss: 6.2064 | Accuracy: 17
	Batch_idx: 250 | Loss: 6.1648 | Accuracy: 13
	Batch_idx: 300 | Loss: 5.8193 | Accuracy: 17
	Batch_idx: 350 | Loss: 6.6314 | Accuracy: 17
	Batch_idx: 400 | Loss: 5.1785 | Accuracy: 24
	Batch_idx: 450 | Loss: 3.6232 | Accuracy: 42
	Batch_idx: 500 | Loss: 2.0754 | Accuracy: 66
	Batch_idx: 550 | Loss: 1.6249 | Accuracy: 63
	Batch_idx: 600 | Loss: 1.4510 | Accuracy: 79
	Batch_idx: 650 | Loss: 3.7010 | Accuracy: 42
	Batch_idx: 700 | Loss: 2.6040 | Accuracy: 55
	Batch_idx: 750 | Loss: 2.6850 | Accuracy: 50
	Batch_idx: 800 | Loss: 3.3483 | Accuracy: 46
	Batch_idx: 850 | Loss: 3.4573 | Accuracy: 42
	Batch_idx: 900 | Loss: 3.3462 | Accuracy: 43
	Batch_idx: 950 | Loss: 3.0577 | Accuracy: 52
	Batch_idx: 1000 | Loss: 2.9169 | Accuracy: 51
	Batch_idx: 1050 | Loss: 1.6014 | Accuracy: 59
	Batch_idx: 1100 | Loss: 2.0673 | Accuracy: 56
	Batch_idx: 1150 | Loss: 3.3525 | Accuracy: 43
	Batch_idx: 1200 | Loss: 2.6418 | Accuracy: 49
	Batch_idx: 1250 | Loss: 2.6239 | Accuracy: 48
	Batch_idx: 1300 | Loss: 1.3789 | Accuracy: 73
	Batch_idx: 1350 | Loss: 0.9679 | Accuracy: 87
	Batch_idx: 1400 | Loss: 0.5342 | Accuracy: 88
	Batch_idx: 1450 | Loss: 1.8707 | Accuracy: 56
	Batch_idx: 1500 | Loss: 1.6255 | Accuracy: 62
	Batch_idx: 1550 | Loss: 1.8227 | Accuracy: 62
	Batch_idx: 1600 | Loss: 2.0983 | Accuracy: 56
	Batch_idx: 1650 | Loss: 2.0589 | Accuracy: 60
	Batch_idx: 1700 | Loss: 1.5554 | Accuracy: 62
	Batch_idx: 1750 | Loss: 3.1532 | Accuracy: 46
	Batch_idx: 1800 | Loss: 2.3784 | Accuracy: 52
	Batch_idx: 1850 | Loss: 2.0419 | Accuracy: 57
	Batch_idx: 1900 | Loss: 2.7480 | Accuracy: 50
	Batch_idx: 1950 | Loss: 2.9630 | Accuracy: 50
	Batch_idx: 2000 | Loss: 2.5255 | Accuracy: 55
	Batch_idx: 2050 | Loss: 2.2840 | Accuracy: 52
	Batch_idx: 2100 | Loss: 1.2160 | Accuracy: 79
	Batch_idx: 2150 | Loss: 1.2152 | Accuracy: 80
	Batch_idx: 2200 | Loss: 1.2290 | Accuracy: 79
	Batch_idx: 2250 | Loss: 1.4781 | Accuracy: 76
	Batch_idx: 2300 | Loss: 0.6826 | Accuracy: 83
	Batch_idx: 2350 | Loss: 0.8748 | Accuracy: 76
	Batch_idx: 2400 | Loss: 0.7717 | Accuracy: 78
	Batch_idx: 2450 | Loss: 2.8423 | Accuracy: 49
	Batch_idx: 2500 | Loss: 2.1400 | Accuracy: 57
	Batch_idx: 2550 | Loss: 3.0439 | Accuracy: 50
	Batch_idx: 2600 | Loss: 2.8307 | Accuracy: 55
	Batch_idx: 2650 | Loss: 2.7804 | Accuracy: 53
	Batch_idx: 2700 | Loss: 5.0840 | Accuracy: 21
	Batch_idx: 2750 | Loss: 4.4904 | Accuracy: 27
	Batch_idx: 2800 | Loss: 4.8248 | Accuracy: 24
	Batch_idx: 2850 | Loss: 5.2825 | Accuracy: 23
	Batch_idx: 2900 | Loss: 6.0355 | Accuracy: 10
	Batch_idx: 2950 | Loss: 5.3044 | Accuracy: 27
	Batch_idx: 3000 | Loss: 5.7263 | Accuracy: 25
	Batch_idx: 3050 | Loss: 4.8595 | Accuracy: 25
	Batch_idx: 3100 | Loss: 4.6637 | Accuracy: 22
	Batch_idx: 3150 | Loss: 4.0090 | Accuracy: 31
	Batch_idx: 3200 | Loss: 5.6078 | Accuracy: 21
	Batch_idx: 3250 | Loss: 5.2900 | Accuracy: 21
	Batch_idx: 3300 | Loss: 5.1369 | Accuracy: 26
	Batch_idx: 3350 | Loss: 4.9645 | Accuracy: 28
	Batch_idx: 3400 | Loss: 5.7237 | Accuracy: 22
	Batch_idx: 3450 | Loss: 4.0926 | Accuracy: 28
	Batch_idx: 3500 | Loss: 5.4193 | Accuracy: 26
	Batch_idx: 3550 | Loss: 4.1332 | Accuracy: 31
	Batch_idx: 3600 | Loss: 5.2900 | Accuracy: 23
	Batch_idx: 3650 | Loss: 5.2738 | Accuracy: 25
	Batch_idx: 3700 | Loss: 5.2888 | Accuracy: 28
	Batch_idx: 3750 | Loss: 4.7156 | Accuracy: 24
	Batch_idx: 3800 | Loss: 5.0264 | Accuracy: 22
	Batch_idx: 3850 | Loss: 5.3726 | Accuracy: 22
	Batch_idx: 3900 | Loss: 4.3274 | Accuracy: 33
	Batch_idx: 3950 | Loss: 4.4313 | Accuracy: 28
	Batch_idx: 4000 | Loss: 4.6387 | Accuracy: 30
	Batch_idx: 4050 | Loss: 5.2713 | Accuracy: 23
	Batch_idx: 4100 | Loss: 4.8708 | Accuracy: 24
	Batch_idx: 4150 | Loss: 4.4456 | Accuracy: 36
	Batch_idx: 4200 | Loss: 6.0568 | Accuracy: 22
	Batch_idx: 4250 | Loss: 6.5483 | Accuracy: 14
	Batch_idx: 4300 | Loss: 5.8397 | Accuracy: 18
	Batch_idx: 4350 | Loss: 6.0915 | Accuracy: 15
	Batch_idx: 4400 | Loss: 6.1366 | Accuracy: 23
	Batch_idx: 4450 | Loss: 5.8865 | Accuracy: 23
	Batch_idx: 4500 | Loss: 6.4602 | Accuracy: 17
	Batch_idx: 4550 | Loss: 6.2207 | Accuracy: 14
	Batch_idx: 4600 | Loss: 6.0701 | Accuracy: 21
	Batch_idx: 4650 | Loss: 6.8582 | Accuracy: 16
	Batch_idx: 4700 | Loss: 6.1984 | Accuracy: 19
	Batch_idx: 4750 | Loss: 6.6267 | Accuracy: 21
	Batch_idx: 4800 | Loss: 0.2278 | Accuracy: 92
	Batch_idx: 4850 | Loss: 0.1874 | Accuracy: 95
  Class 0, accuracy: 18.47
  Class 1, accuracy: 39.08
  Class 2, accuracy: 69.45
  Class 3, accuracy: 46.84
  Class 4, accuracy: 54.06
  Class 5, accuracy: 74.40
  Class 6, accuracy: 82.87
  Class 7, accuracy: 64.07
  Class 8, accuracy: 51.69
  Class 9, accuracy: 76.15
  Class 10, accuracy: 77.28
  Class 11, accuracy: 52.01
  Class 12, accuracy: 25.91
  Class 13, accuracy: 19.16
  Class 14, accuracy: 92.09
Testing Loss: 3.8072 | OA: 41.07 | AA: 56.24 | Kappa: 38.33 | Time: 747.87
Epoch 41/80| Time: 3.47s| Loss: 0.0021
Epoch 42/80| Time: 3.45s| Loss: 0.0021
Epoch 43/80| Time: 3.50s| Loss: 0.0018
Epoch 44/80| Time: 3.53s| Loss: 0.0019
Epoch 45/80| Time: 3.48s| Loss: 0.0019
Epoch 46/80| Time: 3.51s| Loss: 0.0022
Epoch 47/80| Time: 3.53s| Loss: 0.0018
Epoch 48/80| Time: 3.52s| Loss: 0.0019
Epoch 49/80| Time: 3.51s| Loss: 0.0022
Epoch 50/80| Time: 3.54s| Loss: 0.0028
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv250.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-01-18_12-57-09/ResNetv250.model model loaded--<<
	Batch_idx: 0 | Loss: 5.8282 | Accuracy: 16
	Batch_idx: 50 | Loss: 6.9054 | Accuracy: 13
	Batch_idx: 100 | Loss: 5.6555 | Accuracy: 21
	Batch_idx: 150 | Loss: 7.1580 | Accuracy: 16
	Batch_idx: 200 | Loss: 6.3240 | Accuracy: 17
	Batch_idx: 250 | Loss: 6.2539 | Accuracy: 13
	Batch_idx: 300 | Loss: 5.9062 | Accuracy: 17
	Batch_idx: 350 | Loss: 6.7534 | Accuracy: 17
	Batch_idx: 400 | Loss: 5.2822 | Accuracy: 23
	Batch_idx: 450 | Loss: 3.6577 | Accuracy: 43
	Batch_idx: 500 | Loss: 2.1699 | Accuracy: 65
	Batch_idx: 550 | Loss: 1.7152 | Accuracy: 60
	Batch_idx: 600 | Loss: 1.5086 | Accuracy: 77
	Batch_idx: 650 | Loss: 3.6550 | Accuracy: 43
	Batch_idx: 700 | Loss: 2.5633 | Accuracy: 55
	Batch_idx: 750 | Loss: 2.6518 | Accuracy: 53
	Batch_idx: 800 | Loss: 3.2993 | Accuracy: 46
	Batch_idx: 850 | Loss: 3.4095 | Accuracy: 43
	Batch_idx: 900 | Loss: 3.2815 | Accuracy: 45
	Batch_idx: 950 | Loss: 3.1109 | Accuracy: 52
	Batch_idx: 1000 | Loss: 2.9389 | Accuracy: 51
	Batch_idx: 1050 | Loss: 1.6331 | Accuracy: 56
	Batch_idx: 1100 | Loss: 2.0808 | Accuracy: 56
	Batch_idx: 1150 | Loss: 3.4028 | Accuracy: 42
	Batch_idx: 1200 | Loss: 2.6693 | Accuracy: 49
	Batch_idx: 1250 | Loss: 2.6504 | Accuracy: 48
	Batch_idx: 1300 | Loss: 1.3811 | Accuracy: 72
	Batch_idx: 1350 | Loss: 0.8931 | Accuracy: 87
	Batch_idx: 1400 | Loss: 0.4961 | Accuracy: 88
	Batch_idx: 1450 | Loss: 1.7786 | Accuracy: 60
	Batch_idx: 1500 | Loss: 1.5404 | Accuracy: 63
	Batch_idx: 1550 | Loss: 1.7511 | Accuracy: 63
	Batch_idx: 1600 | Loss: 2.0099 | Accuracy: 57
	Batch_idx: 1650 | Loss: 1.9712 | Accuracy: 61
	Batch_idx: 1700 | Loss: 1.4659 | Accuracy: 65
	Batch_idx: 1750 | Loss: 3.0731 | Accuracy: 47
	Batch_idx: 1800 | Loss: 2.3264 | Accuracy: 55
	Batch_idx: 1850 | Loss: 1.9980 | Accuracy: 59
