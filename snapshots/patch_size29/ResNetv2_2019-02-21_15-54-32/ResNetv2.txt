#######################PARAMETERS######################## Dataset selection
	maxTrain: True
	max_trainData: 200
# train/test parameters	model_name: ResNetv2
	optimizer: SGD
	epochs: 50
	batch_size: 100
	seed: 80
	lr: 0.01
	weight_decay: 0.0001
# data preparation parameters
	dataset: crop_59
	patch_size: 29
	band: 63
	num_classes: 19
	train_percent: 0.75
	val_percent: 0.0
	test_percent: 0.25

#############################  MODEL  ###################################

ResNetv2(
  (conv): Sequential(
    (0): Conv2d(63, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)
  )
  (relu): ReLU()
  (block1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (downsample1): Sequential(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (block2): Sequential(
    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (downsample2): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=32768, out_features=2048, bias=True)
    (1): Dropout(p=0.2)
    (2): ReLU(inplace)
    (3): Linear(in_features=2048, out_features=1024, bias=True)
    (4): Dropout(p=0.2)
    (5): ReLU(inplace)
    (6): Linear(in_features=1024, out_features=19, bias=True)
  )
  (Softmax): Softmax()
)
##############################################################################

Epoch 1/50| Time: 1.65s| Loss: 2.4923
Epoch 2/50| Time: 1.65s| Loss: 0.4909
Epoch 3/50| Time: 1.61s| Loss: 0.3234
Epoch 4/50| Time: 1.62s| Loss: 0.2265
Epoch 5/50| Time: 1.61s| Loss: 0.1878
Epoch 6/50| Time: 1.62s| Loss: 0.1701
Epoch 7/50| Time: 1.63s| Loss: 0.1469
Epoch 8/50| Time: 1.64s| Loss: 0.1323
Epoch 9/50| Time: 1.62s| Loss: 0.1417
Epoch 10/50| Time: 1.65s| Loss: 0.1506
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv210.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv210.model model loaded--<<
	Batch_idx: 0 | Loss: 0.7700 | Accuracy: 63
	Batch_idx: 50 | Loss: 0.9302 | Accuracy: 67
	Batch_idx: 100 | Loss: 0.6718 | Accuracy: 61
	Batch_idx: 150 | Loss: 0.7812 | Accuracy: 67
	Batch_idx: 200 | Loss: 0.6453 | Accuracy: 68
	Batch_idx: 250 | Loss: 0.6753 | Accuracy: 69
	Batch_idx: 300 | Loss: 0.5174 | Accuracy: 77
	Batch_idx: 350 | Loss: 0.6598 | Accuracy: 72
	Batch_idx: 400 | Loss: 0.6208 | Accuracy: 71
	Batch_idx: 450 | Loss: 0.5959 | Accuracy: 71
	Batch_idx: 500 | Loss: 0.5929 | Accuracy: 75
	Batch_idx: 550 | Loss: 0.6044 | Accuracy: 69
	Batch_idx: 600 | Loss: 0.6691 | Accuracy: 63
	Batch_idx: 650 | Loss: 0.6589 | Accuracy: 70
	Batch_idx: 700 | Loss: 0.4268 | Accuracy: 82
	Batch_idx: 750 | Loss: 0.3824 | Accuracy: 86
	Batch_idx: 800 | Loss: 0.4584 | Accuracy: 72
	Batch_idx: 850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1100 | Loss: 0.0001 | Accuracy: 100
	Batch_idx: 1150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1200 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1250 | Loss: 0.0160 | Accuracy: 99
	Batch_idx: 1300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1350 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1450 | Loss: 0.0001 | Accuracy: 100
	Batch_idx: 1500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1550 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1600 | Loss: 0.0175 | Accuracy: 99
	Batch_idx: 1650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1700 | Loss: 0.0387 | Accuracy: 99
	Batch_idx: 1750 | Loss: 0.0343 | Accuracy: 99
	Batch_idx: 1800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1850 | Loss: 0.0008 | Accuracy: 100
	Batch_idx: 1900 | Loss: 0.0781 | Accuracy: 99
	Batch_idx: 1950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2100 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2150 | Loss: 0.0011 | Accuracy: 100
	Batch_idx: 2200 | Loss: 0.0148 | Accuracy: 99
	Batch_idx: 2250 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2350 | Loss: 0.0229 | Accuracy: 99
	Batch_idx: 2400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2450 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2550 | Loss: 0.0744 | Accuracy: 99
	Batch_idx: 2600 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2700 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2750 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3050 | Loss: 0.0013 | Accuracy: 100
	Batch_idx: 3100 | Loss: 0.0208 | Accuracy: 99
	Batch_idx: 3150 | Loss: 0.0002 | Accuracy: 100
	Batch_idx: 3200 | Loss: 0.0068 | Accuracy: 100
	Batch_idx: 3250 | Loss: 0.0221 | Accuracy: 99
	Batch_idx: 3300 | Loss: 0.0173 | Accuracy: 99
	Batch_idx: 3350 | Loss: 0.0095 | Accuracy: 100
	Batch_idx: 3400 | Loss: 0.0019 | Accuracy: 100
	Batch_idx: 3450 | Loss: 0.0031 | Accuracy: 100
  Class 0, accuracy: 68.14
  Class 1, accuracy: 78.86
  Class 11, accuracy: 99.94
  Class 15, accuracy: 99.53
  Class 16, accuracy: 99.85
  Class 17, accuracy: 99.93
  Class 18, accuracy: 99.60
Testing Loss: 0.1544 | OA: 92.88 | AA: 92.27 | Kappa: 91.25 | Time: 578.75
Epoch 11/50| Time: 1.77s| Loss: 0.1024
Epoch 12/50| Time: 1.79s| Loss: 0.0936
Epoch 13/50| Time: 1.77s| Loss: 0.0890
Epoch 14/50| Time: 1.74s| Loss: 0.0792
Epoch 15/50| Time: 1.73s| Loss: 0.1008
Epoch 16/50| Time: 1.76s| Loss: 0.0706
Epoch 17/50| Time: 1.79s| Loss: 0.0748
Epoch 18/50| Time: 1.78s| Loss: 0.0688
Epoch 19/50| Time: 1.77s| Loss: 0.0461
Epoch 20/50| Time: 1.78s| Loss: 0.0329
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv220.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv220.model model loaded--<<
	Batch_idx: 0 | Loss: 1.3698 | Accuracy: 59
	Batch_idx: 50 | Loss: 1.6353 | Accuracy: 65
	Batch_idx: 100 | Loss: 1.1159 | Accuracy: 63
	Batch_idx: 150 | Loss: 1.4791 | Accuracy: 63
	Batch_idx: 200 | Loss: 0.9698 | Accuracy: 61
	Batch_idx: 250 | Loss: 1.0623 | Accuracy: 65
	Batch_idx: 300 | Loss: 0.8131 | Accuracy: 77
	Batch_idx: 350 | Loss: 0.8726 | Accuracy: 71
	Batch_idx: 400 | Loss: 0.9511 | Accuracy: 68
	Batch_idx: 450 | Loss: 0.7962 | Accuracy: 69
	Batch_idx: 500 | Loss: 0.8219 | Accuracy: 72
	Batch_idx: 550 | Loss: 0.9597 | Accuracy: 70
	Batch_idx: 600 | Loss: 0.7728 | Accuracy: 71
	Batch_idx: 650 | Loss: 1.1544 | Accuracy: 60
	Batch_idx: 700 | Loss: 0.2505 | Accuracy: 91
	Batch_idx: 750 | Loss: 0.1166 | Accuracy: 95
	Batch_idx: 800 | Loss: 0.2056 | Accuracy: 93
	Batch_idx: 850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1100 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1200 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1250 | Loss: 0.0009 | Accuracy: 100
	Batch_idx: 1300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1350 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1450 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1550 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1600 | Loss: 0.0021 | Accuracy: 100
	Batch_idx: 1650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1700 | Loss: 0.0340 | Accuracy: 99
	Batch_idx: 1750 | Loss: 0.0172 | Accuracy: 99
	Batch_idx: 1800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1900 | Loss: 0.0721 | Accuracy: 99
	Batch_idx: 1950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2100 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2200 | Loss: 0.0046 | Accuracy: 100
	Batch_idx: 2250 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2350 | Loss: 0.0093 | Accuracy: 99
	Batch_idx: 2400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2450 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2550 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2600 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2700 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2750 | Loss: 0.0001 | Accuracy: 100
	Batch_idx: 2800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3050 | Loss: 0.0010 | Accuracy: 100
	Batch_idx: 3100 | Loss: 0.0214 | Accuracy: 99
	Batch_idx: 3150 | Loss: 0.0237 | Accuracy: 99
	Batch_idx: 3200 | Loss: 0.0035 | Accuracy: 100
	Batch_idx: 3250 | Loss: 0.0220 | Accuracy: 99
	Batch_idx: 3300 | Loss: 0.0006 | Accuracy: 100
	Batch_idx: 3350 | Loss: 0.0004 | Accuracy: 100
	Batch_idx: 3400 | Loss: 0.0001 | Accuracy: 100
	Batch_idx: 3450 | Loss: 0.0003 | Accuracy: 100
  Class 0, accuracy: 66.14
  Class 1, accuracy: 91.36
  Class 11, accuracy: 99.97
  Class 15, accuracy: 99.70
  Class 16, accuracy: 99.87
  Class 17, accuracy: 99.64
  Class 18, accuracy: 99.91
Testing Loss: 0.2232 | OA: 93.06 | AA: 93.80 | Kappa: 91.48 | Time: 599.25
Epoch 21/50| Time: 1.76s| Loss: 0.0284
Epoch 22/50| Time: 1.79s| Loss: 0.0175
Epoch 23/50| Time: 1.76s| Loss: 0.0186
Epoch 24/50| Time: 1.74s| Loss: 0.0176
Epoch 25/50| Time: 1.80s| Loss: 0.0153
Epoch 26/50| Time: 1.75s| Loss: 0.0181
Epoch 27/50| Time: 1.80s| Loss: 0.0158
Epoch 28/50| Time: 1.83s| Loss: 0.0159
Epoch 29/50| Time: 1.73s| Loss: 0.0112
Epoch 30/50| Time: 1.73s| Loss: 0.0094
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv230.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv230.model model loaded--<<
	Batch_idx: 0 | Loss: 0.7965 | Accuracy: 75
	Batch_idx: 50 | Loss: 1.0249 | Accuracy: 85
	Batch_idx: 100 | Loss: 0.4910 | Accuracy: 84
	Batch_idx: 150 | Loss: 0.7912 | Accuracy: 78
	Batch_idx: 200 | Loss: 0.3574 | Accuracy: 88
	Batch_idx: 250 | Loss: 0.5294 | Accuracy: 85
	Batch_idx: 300 | Loss: 0.3608 | Accuracy: 90
	Batch_idx: 350 | Loss: 0.3674 | Accuracy: 87
	Batch_idx: 400 | Loss: 0.4708 | Accuracy: 83
	Batch_idx: 450 | Loss: 0.2899 | Accuracy: 88
	Batch_idx: 500 | Loss: 0.3500 | Accuracy: 85
	Batch_idx: 550 | Loss: 0.3979 | Accuracy: 90
	Batch_idx: 600 | Loss: 0.3252 | Accuracy: 88
	Batch_idx: 650 | Loss: 0.5927 | Accuracy: 85
	Batch_idx: 700 | Loss: 0.5322 | Accuracy: 83
	Batch_idx: 750 | Loss: 0.3180 | Accuracy: 84
	Batch_idx: 800 | Loss: 0.4455 | Accuracy: 84
	Batch_idx: 850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1100 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1200 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1250 | Loss: 0.0065 | Accuracy: 100
	Batch_idx: 1300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1350 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1450 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1550 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1600 | Loss: 0.0003 | Accuracy: 100
	Batch_idx: 1650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1700 | Loss: 0.0172 | Accuracy: 99
	Batch_idx: 1750 | Loss: 0.0056 | Accuracy: 100
	Batch_idx: 1800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1900 | Loss: 0.0716 | Accuracy: 99
	Batch_idx: 1950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2100 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2200 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2250 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2350 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2450 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2550 | Loss: 0.0001 | Accuracy: 100
	Batch_idx: 2600 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2700 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2750 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3050 | Loss: 0.0003 | Accuracy: 100
	Batch_idx: 3100 | Loss: 0.0189 | Accuracy: 99
	Batch_idx: 3150 | Loss: 0.0001 | Accuracy: 100
	Batch_idx: 3200 | Loss: 0.0035 | Accuracy: 100
	Batch_idx: 3250 | Loss: 0.0161 | Accuracy: 99
	Batch_idx: 3300 | Loss: 0.0010 | Accuracy: 100
	Batch_idx: 3350 | Loss: 0.0004 | Accuracy: 100
	Batch_idx: 3400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3450 | Loss: 0.0002 | Accuracy: 100
  Class 0, accuracy: 84.40
  Class 1, accuracy: 83.48
  Class 11, accuracy: 99.94
  Class 15, accuracy: 99.75
  Class 16, accuracy: 99.95
  Class 17, accuracy: 99.90
  Class 18, accuracy: 99.89
Testing Loss: 0.1177 | OA: 96.24 | AA: 95.33 | Kappa: 95.35 | Time: 584.01
Epoch 31/50| Time: 1.74s| Loss: 0.0100
Epoch 32/50| Time: 1.70s| Loss: 0.0125
Epoch 33/50| Time: 1.71s| Loss: 0.0117
Epoch 34/50| Time: 1.70s| Loss: 0.0132
Epoch 35/50| Time: 1.70s| Loss: 0.0120
Epoch 36/50| Time: 1.76s| Loss: 0.0084
Epoch 37/50| Time: 1.68s| Loss: 0.0088
Epoch 38/50| Time: 1.69s| Loss: 0.0140
Epoch 39/50| Time: 1.71s| Loss: 0.0077
Epoch 40/50| Time: 1.71s| Loss: 0.0088
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv240.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv240.model model loaded--<<
	Batch_idx: 0 | Loss: 0.9446 | Accuracy: 74
	Batch_idx: 50 | Loss: 1.1648 | Accuracy: 85
	Batch_idx: 100 | Loss: 0.6096 | Accuracy: 78
	Batch_idx: 150 | Loss: 0.9442 | Accuracy: 73
	Batch_idx: 200 | Loss: 0.4401 | Accuracy: 84
	Batch_idx: 250 | Loss: 0.6406 | Accuracy: 82
	Batch_idx: 300 | Loss: 0.4378 | Accuracy: 90
	Batch_idx: 350 | Loss: 0.4511 | Accuracy: 86
	Batch_idx: 400 | Loss: 0.5885 | Accuracy: 81
	Batch_idx: 450 | Loss: 0.3673 | Accuracy: 88
	Batch_idx: 500 | Loss: 0.4311 | Accuracy: 83
	Batch_idx: 550 | Loss: 0.4634 | Accuracy: 89
	Batch_idx: 600 | Loss: 0.4208 | Accuracy: 86
	Batch_idx: 650 | Loss: 0.6970 | Accuracy: 82
	Batch_idx: 700 | Loss: 0.4790 | Accuracy: 84
	Batch_idx: 750 | Loss: 0.2585 | Accuracy: 88
	Batch_idx: 800 | Loss: 0.3700 | Accuracy: 86
	Batch_idx: 850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1100 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1200 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1250 | Loss: 0.0075 | Accuracy: 100
	Batch_idx: 1300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1350 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1450 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1550 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1600 | Loss: 0.0003 | Accuracy: 100
	Batch_idx: 1650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1700 | Loss: 0.0167 | Accuracy: 99
	Batch_idx: 1750 | Loss: 0.0044 | Accuracy: 100
	Batch_idx: 1800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1900 | Loss: 0.0679 | Accuracy: 99
	Batch_idx: 1950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2100 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2200 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2250 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2350 | Loss: 0.0001 | Accuracy: 100
	Batch_idx: 2400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2450 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2550 | Loss: 0.0008 | Accuracy: 100
	Batch_idx: 2600 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2700 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2750 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3050 | Loss: 0.0003 | Accuracy: 100
	Batch_idx: 3100 | Loss: 0.0211 | Accuracy: 99
	Batch_idx: 3150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3200 | Loss: 0.0055 | Accuracy: 100
	Batch_idx: 3250 | Loss: 0.0180 | Accuracy: 99
	Batch_idx: 3300 | Loss: 0.0010 | Accuracy: 100
	Batch_idx: 3350 | Loss: 0.0004 | Accuracy: 100
	Batch_idx: 3400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3450 | Loss: 0.0001 | Accuracy: 100
  Class 0, accuracy: 82.04
  Class 1, accuracy: 86.05
  Class 11, accuracy: 99.94
  Class 15, accuracy: 99.76
  Class 16, accuracy: 99.95
  Class 17, accuracy: 99.92
  Class 18, accuracy: 99.88
Testing Loss: 0.1363 | OA: 95.91 | AA: 95.36 | Kappa: 94.94 | Time: 562.69
Epoch 41/50| Time: 1.65s| Loss: 0.0068
Epoch 42/50| Time: 1.64s| Loss: 0.0081
Epoch 43/50| Time: 1.64s| Loss: 0.0076
Epoch 44/50| Time: 1.64s| Loss: 0.0090
Epoch 45/50| Time: 1.63s| Loss: 0.0110
Epoch 46/50| Time: 1.64s| Loss: 0.0129
Epoch 47/50| Time: 1.63s| Loss: 0.0087
Epoch 48/50| Time: 1.65s| Loss: 0.0111
Epoch 49/50| Time: 1.64s| Loss: 0.0078
Epoch 50/50| Time: 1.63s| Loss: 0.0077
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv250.model model saved--<<
>>--/home/xueyiming/TEST/snapshots/patch_size29/ResNetv2_2019-02-21_15-54-32/ResNetv250.model model loaded--<<
	Batch_idx: 0 | Loss: 0.9100 | Accuracy: 75
	Batch_idx: 50 | Loss: 1.1504 | Accuracy: 85
	Batch_idx: 100 | Loss: 0.5770 | Accuracy: 79
	Batch_idx: 150 | Loss: 0.9398 | Accuracy: 75
	Batch_idx: 200 | Loss: 0.4080 | Accuracy: 86
	Batch_idx: 250 | Loss: 0.6151 | Accuracy: 83
	Batch_idx: 300 | Loss: 0.4296 | Accuracy: 90
	Batch_idx: 350 | Loss: 0.4746 | Accuracy: 85
	Batch_idx: 400 | Loss: 0.5565 | Accuracy: 84
	Batch_idx: 450 | Loss: 0.3336 | Accuracy: 88
	Batch_idx: 500 | Loss: 0.4137 | Accuracy: 84
	Batch_idx: 550 | Loss: 0.4559 | Accuracy: 90
	Batch_idx: 600 | Loss: 0.3925 | Accuracy: 86
	Batch_idx: 650 | Loss: 0.6704 | Accuracy: 84
	Batch_idx: 700 | Loss: 0.4901 | Accuracy: 84
	Batch_idx: 750 | Loss: 0.2637 | Accuracy: 89
	Batch_idx: 800 | Loss: 0.3959 | Accuracy: 85
	Batch_idx: 850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1100 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1200 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1250 | Loss: 0.0042 | Accuracy: 100
	Batch_idx: 1300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1350 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1450 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1550 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1600 | Loss: 0.0001 | Accuracy: 100
	Batch_idx: 1650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1700 | Loss: 0.0115 | Accuracy: 99
	Batch_idx: 1750 | Loss: 0.0025 | Accuracy: 100
	Batch_idx: 1800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 1900 | Loss: 0.0667 | Accuracy: 99
	Batch_idx: 1950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2050 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2100 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2200 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2250 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2300 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2350 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2450 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2500 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2550 | Loss: 0.0002 | Accuracy: 100
	Batch_idx: 2600 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2650 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2700 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2750 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2800 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2850 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2900 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 2950 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3000 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3050 | Loss: 0.0003 | Accuracy: 100
	Batch_idx: 3100 | Loss: 0.0190 | Accuracy: 99
	Batch_idx: 3150 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3200 | Loss: 0.0044 | Accuracy: 100
	Batch_idx: 3250 | Loss: 0.0149 | Accuracy: 99
	Batch_idx: 3300 | Loss: 0.0011 | Accuracy: 100
	Batch_idx: 3350 | Loss: 0.0005 | Accuracy: 100
	Batch_idx: 3400 | Loss: 0.0000 | Accuracy: 100
	Batch_idx: 3450 | Loss: 0.0002 | Accuracy: 100
  Class 0, accuracy: 82.75
  Class 1, accuracy: 85.65
  Class 11, accuracy: 99.94
  Class 15, accuracy: 99.79
  Class 16, accuracy: 99.95
  Class 17, accuracy: 99.92
  Class 18, accuracy: 99.87
Testing Loss: 0.1320 | OA: 96.03 | AA: 95.41 | Kappa: 95.09 | Time: 536.55
