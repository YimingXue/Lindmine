#######################PARAMETERS######################## cuda
	cuda: True
# train/test parameters	model_name: Pyramidal_ResNet
	optimizer: SGD
	epochs: 150
	batch_size: 100
	seed: 75
	lr: 0.001
	weight_decay: 0.0001
# data preparation parameters
	dataset: Indian_pines
	patch_size: 11
	band: 220
	num_classes: 16
# SimpleFC parameters
	FC_1: 500
	FC_2: 350
	FC_3: 150
	FC_4: 16

#############################  MODEL  ###################################

Pyramidal_ResNet(
  (Input_module): Sequential(
    (0): Conv2d(220, 220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (Pyramidal_module_P1): Sequential(
    (0): BatchNorm2d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(220, 64, kernel_size=(1, 1), stride=(1, 1))
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): Conv2d(64, 220, kernel_size=(1, 1), stride=(1, 1))
    (6): BatchNorm2d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): ReLU()
    (8): BatchNorm2d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): Conv2d(220, 64, kernel_size=(1, 1), stride=(1, 1))
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): Conv2d(64, 225, kernel_size=(1, 1), stride=(1, 1))
    (14): BatchNorm2d(225, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): ReLU()
    (16): BatchNorm2d(225, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): Conv2d(225, 64, kernel_size=(1, 1), stride=(1, 1))
    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (21): Conv2d(64, 230, kernel_size=(1, 1), stride=(1, 1))
    (22): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU()
  )
  (P1_ShortCut): Sequential(
    (0): BatchNorm2d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(220, 230, kernel_size=(1, 1), stride=(1, 1))
  )
  (Pyramidal_module_P2): Sequential(
    (0): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(230, 64, kernel_size=(1, 1), stride=(1, 1))
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): Conv2d(64, 235, kernel_size=(1, 1), stride=(1, 1))
    (6): BatchNorm2d(235, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): ReLU()
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (9): BatchNorm2d(235, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(235, 64, kernel_size=(1, 1), stride=(1, 1))
    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))
    (15): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU()
    (17): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))
    (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(64, 245, kernel_size=(1, 1), stride=(1, 1))
    (23): BatchNorm2d(245, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): ReLU()
  )
  (P2_ShortCut): Sequential(
    (0): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(230, 245, kernel_size=(3, 3), stride=(2, 2))
    (2): BatchNorm2d(245, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(245, 245, kernel_size=(3, 3), stride=(1, 1))
  )
  (Pyramidal_module_P3): Sequential(
    (0): BatchNorm2d(245, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(245, 64, kernel_size=(1, 1), stride=(1, 1))
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): Conv2d(64, 250, kernel_size=(1, 1), stride=(1, 1))
    (6): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): ReLU()
    (8): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): Conv2d(250, 64, kernel_size=(1, 1), stride=(1, 1))
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): Conv2d(64, 255, kernel_size=(1, 1), stride=(1, 1))
    (14): BatchNorm2d(255, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): ReLU()
    (16): BatchNorm2d(255, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): Conv2d(255, 64, kernel_size=(1, 1), stride=(1, 1))
    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (21): Conv2d(64, 260, kernel_size=(1, 1), stride=(1, 1))
    (22): BatchNorm2d(260, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU()
  )
  (P3_ShortCut): Sequential(
    (0): BatchNorm2d(245, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(245, 260, kernel_size=(3, 3), stride=(1, 1))
  )
  (classifier): Sequential(
    (0): Linear(in_features=260, out_features=16, bias=True)
  )
  (Softmax): Softmax()
)
##############################################################################

Epoch 1/150| Time: 1.68s| Loss: 1.8190
Epoch 2/150| Time: 1.64s| Loss: 0.8843
Epoch 3/150| Time: 1.65s| Loss: 0.5429
Epoch 4/150| Time: 1.67s| Loss: 0.3444
Epoch 5/150| Time: 1.65s| Loss: 0.2193
Epoch 6/150| Time: 1.65s| Loss: 0.1463
Epoch 7/150| Time: 1.64s| Loss: 0.1040
Epoch 8/150| Time: 1.67s| Loss: 0.0904
Epoch 9/150| Time: 1.64s| Loss: 0.0637
Epoch 10/150| Time: 1.66s| Loss: 0.0471
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet10.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet10.model model loaded--<<
	Batch_idx: 0 | Loss: 0.5021 | Accuracy: 26
	Batch_idx: 1 | Loss: 0.0895 | Accuracy: 13
	Batch_idx: 2 | Loss: 0.1276 | Accuracy: 8
	Batch_idx: 3 | Loss: 0.1490 | Accuracy: 8
	Batch_idx: 4 | Loss: 0.1651 | Accuracy: 9
	Batch_idx: 5 | Loss: 0.1861 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1315 | Accuracy: 6
	Batch_idx: 7 | Loss: 0.1947 | Accuracy: 5
	Batch_idx: 8 | Loss: 0.1662 | Accuracy: 10
	Batch_idx: 9 | Loss: 0.1635 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.2208 | Accuracy: 7
	Batch_idx: 11 | Loss: 0.2337 | Accuracy: 9
	Batch_idx: 12 | Loss: 0.2744 | Accuracy: 1
	Batch_idx: 13 | Loss: 0.3477 | Accuracy: 1
	Batch_idx: 14 | Loss: 0.1582 | Accuracy: 6
	Batch_idx: 15 | Loss: 0.1702 | Accuracy: 9
	Batch_idx: 16 | Loss: 0.2942 | Accuracy: 8
	Batch_idx: 17 | Loss: 0.3525 | Accuracy: 12
	Batch_idx: 18 | Loss: 0.3205 | Accuracy: 11
	Batch_idx: 19 | Loss: 0.3744 | Accuracy: 3
	Batch_idx: 20 | Loss: 0.1829 | Accuracy: 11
	Batch_idx: 21 | Loss: 0.0986 | Accuracy: 12
	Batch_idx: 22 | Loss: 0.1007 | Accuracy: 11
	Batch_idx: 23 | Loss: 0.0638 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0466 | Accuracy: 20
	Batch_idx: 25 | Loss: 0.0662 | Accuracy: 13
	Batch_idx: 26 | Loss: 0.0504 | Accuracy: 17
	Batch_idx: 27 | Loss: 0.0398 | Accuracy: 16
	Batch_idx: 28 | Loss: 0.0362 | Accuracy: 13
	Batch_idx: 29 | Loss: 0.0375 | Accuracy: 12
	Batch_idx: 30 | Loss: 0.2800 | Accuracy: 28
	Batch_idx: 31 | Loss: 0.0309 | Accuracy: 12
	Batch_idx: 32 | Loss: 0.0311 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0399 | Accuracy: 14
	Batch_idx: 34 | Loss: 0.4803 | Accuracy: 19
	Batch_idx: 35 | Loss: 0.4216 | Accuracy: 13
	Batch_idx: 36 | Loss: 0.4539 | Accuracy: 8
	Batch_idx: 37 | Loss: 0.3337 | Accuracy: 9
	Batch_idx: 38 | Loss: 0.4517 | Accuracy: 13
	Batch_idx: 39 | Loss: 0.2469 | Accuracy: 8
	Batch_idx: 40 | Loss: 0.2571 | Accuracy: 13
	Batch_idx: 41 | Loss: 0.2340 | Accuracy: 11
	Batch_idx: 42 | Loss: 0.0780 | Accuracy: 15
	Batch_idx: 43 | Loss: 0.0679 | Accuracy: 10
	Batch_idx: 44 | Loss: 0.0924 | Accuracy: 11
	Batch_idx: 45 | Loss: 0.0663 | Accuracy: 9
	Batch_idx: 46 | Loss: 0.1501 | Accuracy: 12
	Batch_idx: 47 | Loss: 0.0741 | Accuracy: 13
	Batch_idx: 48 | Loss: 0.1525 | Accuracy: 11
	Batch_idx: 49 | Loss: 0.0850 | Accuracy: 11
	Batch_idx: 50 | Loss: 0.0737 | Accuracy: 12
	Batch_idx: 51 | Loss: 0.0725 | Accuracy: 13
	Batch_idx: 52 | Loss: 0.0991 | Accuracy: 13
	Batch_idx: 53 | Loss: 0.1235 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.1486 | Accuracy: 15
	Batch_idx: 55 | Loss: 0.1277 | Accuracy: 11
	Batch_idx: 56 | Loss: 0.1371 | Accuracy: 8
	Batch_idx: 57 | Loss: 0.0954 | Accuracy: 8
	Batch_idx: 58 | Loss: 0.0986 | Accuracy: 8
	Batch_idx: 59 | Loss: 0.1245 | Accuracy: 9
	Batch_idx: 60 | Loss: 0.1359 | Accuracy: 12
	Batch_idx: 61 | Loss: 0.2056 | Accuracy: 16
	Batch_idx: 62 | Loss: 0.5046 | Accuracy: 7
	Batch_idx: 63 | Loss: 0.5325 | Accuracy: 13
	Batch_idx: 64 | Loss: 0.4903 | Accuracy: 11
	Batch_idx: 65 | Loss: 0.4395 | Accuracy: 6
	Batch_idx: 66 | Loss: 0.2286 | Accuracy: 14
	Batch_idx: 67 | Loss: 0.0609 | Accuracy: 5
	Batch_idx: 68 | Loss: 0.2651 | Accuracy: 19
	Batch_idx: 69 | Loss: 0.1632 | Accuracy: 14
	Batch_idx: 70 | Loss: 0.2167 | Accuracy: 14
	Batch_idx: 71 | Loss: 0.2441 | Accuracy: 11
	Batch_idx: 72 | Loss: 0.2468 | Accuracy: 15
	Batch_idx: 73 | Loss: 0.2107 | Accuracy: 13
	Batch_idx: 74 | Loss: 0.1880 | Accuracy: 10
	Batch_idx: 75 | Loss: 0.2023 | Accuracy: 12
	Batch_idx: 76 | Loss: 0.2219 | Accuracy: 19
	Batch_idx: 77 | Loss: 0.3345 | Accuracy: 16
	Batch_idx: 78 | Loss: 0.2073 | Accuracy: 16
	Batch_idx: 79 | Loss: 0.1731 | Accuracy: 2
	Batch_idx: 80 | Loss: 0.2241 | Accuracy: 5
	Batch_idx: 81 | Loss: 0.0912 | Accuracy: 16
	Batch_idx: 82 | Loss: 0.0008 | Accuracy: 0
  Class 0, accuracy: 37.8378
  Class 1, accuracy: 8.9239
  Class 2, accuracy: 7.2289
  Class 3, accuracy: 5.7895
  Class 4, accuracy: 12.6615
  Class 5, accuracy: 15.0685
  Class 6, accuracy: 26.0870
  Class 7, accuracy: 15.9269
  Class 8, accuracy: 25.0000
  Class 9, accuracy: 11.3111
  Class 10, accuracy: 11.2016
  Class 11, accuracy: 10.3158
  Class 12, accuracy: 10.9756
  Class 13, accuracy: 14.6245
  Class 14, accuracy: 5.1780
  Class 15, accuracy: 17.3333
Testing Loss: 0.1958 | OA: 11.3969 | AA: 14.7165 | Time: 7.22
Epoch 11/150| Time: 1.63s| Loss: 0.0426
Epoch 12/150| Time: 1.62s| Loss: 0.0347
Epoch 13/150| Time: 1.62s| Loss: 0.0265
Epoch 14/150| Time: 1.63s| Loss: 0.0251
Epoch 15/150| Time: 1.62s| Loss: 0.0227
Epoch 16/150| Time: 1.73s| Loss: 0.0189
Epoch 17/150| Time: 1.62s| Loss: 0.0182
Epoch 18/150| Time: 1.62s| Loss: 0.0155
Epoch 19/150| Time: 1.61s| Loss: 0.0115
Epoch 20/150| Time: 1.62s| Loss: 0.0125
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet20.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet20.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3799 | Accuracy: 23
	Batch_idx: 1 | Loss: 0.0700 | Accuracy: 15
	Batch_idx: 2 | Loss: 0.1428 | Accuracy: 9
	Batch_idx: 3 | Loss: 0.1403 | Accuracy: 6
	Batch_idx: 4 | Loss: 0.1549 | Accuracy: 10
	Batch_idx: 5 | Loss: 0.1656 | Accuracy: 6
	Batch_idx: 6 | Loss: 0.1327 | Accuracy: 6
	Batch_idx: 7 | Loss: 0.2022 | Accuracy: 4
	Batch_idx: 8 | Loss: 0.1915 | Accuracy: 9
	Batch_idx: 9 | Loss: 0.2057 | Accuracy: 12
	Batch_idx: 10 | Loss: 0.2388 | Accuracy: 5
	Batch_idx: 11 | Loss: 0.2142 | Accuracy: 9
	Batch_idx: 12 | Loss: 0.1295 | Accuracy: 3
	Batch_idx: 13 | Loss: 0.2008 | Accuracy: 5
	Batch_idx: 14 | Loss: 0.0769 | Accuracy: 8
	Batch_idx: 15 | Loss: 0.0750 | Accuracy: 8
	Batch_idx: 16 | Loss: 0.1407 | Accuracy: 8
	Batch_idx: 17 | Loss: 0.1734 | Accuracy: 9
	Batch_idx: 18 | Loss: 0.1782 | Accuracy: 13
	Batch_idx: 19 | Loss: 0.2071 | Accuracy: 4
	Batch_idx: 20 | Loss: 0.1068 | Accuracy: 13
	Batch_idx: 21 | Loss: 0.0803 | Accuracy: 11
	Batch_idx: 22 | Loss: 0.1013 | Accuracy: 15
	Batch_idx: 23 | Loss: 0.0396 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0243 | Accuracy: 18
	Batch_idx: 25 | Loss: 0.0406 | Accuracy: 9
	Batch_idx: 26 | Loss: 0.0276 | Accuracy: 16
	Batch_idx: 27 | Loss: 0.0240 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0199 | Accuracy: 10
	Batch_idx: 29 | Loss: 0.0181 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1856 | Accuracy: 28
	Batch_idx: 31 | Loss: 0.0121 | Accuracy: 12
	Batch_idx: 32 | Loss: 0.0100 | Accuracy: 11
	Batch_idx: 33 | Loss: 0.0146 | Accuracy: 14
	Batch_idx: 34 | Loss: 0.2931 | Accuracy: 23
	Batch_idx: 35 | Loss: 0.2545 | Accuracy: 15
	Batch_idx: 36 | Loss: 0.2568 | Accuracy: 10
	Batch_idx: 37 | Loss: 0.1645 | Accuracy: 8
	Batch_idx: 38 | Loss: 0.2773 | Accuracy: 17
	Batch_idx: 39 | Loss: 0.0902 | Accuracy: 8
	Batch_idx: 40 | Loss: 0.0972 | Accuracy: 16
	Batch_idx: 41 | Loss: 0.1257 | Accuracy: 10
	Batch_idx: 42 | Loss: 0.0538 | Accuracy: 13
	Batch_idx: 43 | Loss: 0.0235 | Accuracy: 11
	Batch_idx: 44 | Loss: 0.0392 | Accuracy: 11
	Batch_idx: 45 | Loss: 0.0439 | Accuracy: 9
	Batch_idx: 46 | Loss: 0.1150 | Accuracy: 13
	Batch_idx: 47 | Loss: 0.0667 | Accuracy: 13
	Batch_idx: 48 | Loss: 0.0692 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0474 | Accuracy: 12
	Batch_idx: 50 | Loss: 0.0376 | Accuracy: 13
	Batch_idx: 51 | Loss: 0.0295 | Accuracy: 11
	Batch_idx: 52 | Loss: 0.0622 | Accuracy: 10
	Batch_idx: 53 | Loss: 0.0856 | Accuracy: 11
	Batch_idx: 54 | Loss: 0.0851 | Accuracy: 14
	Batch_idx: 55 | Loss: 0.0931 | Accuracy: 10
	Batch_idx: 56 | Loss: 0.1030 | Accuracy: 8
	Batch_idx: 57 | Loss: 0.0642 | Accuracy: 6
	Batch_idx: 58 | Loss: 0.0470 | Accuracy: 7
	Batch_idx: 59 | Loss: 0.0773 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0955 | Accuracy: 12
	Batch_idx: 61 | Loss: 0.0965 | Accuracy: 12
	Batch_idx: 62 | Loss: 0.2629 | Accuracy: 5
	Batch_idx: 63 | Loss: 0.2185 | Accuracy: 10
	Batch_idx: 64 | Loss: 0.2024 | Accuracy: 7
	Batch_idx: 65 | Loss: 0.1411 | Accuracy: 7
	Batch_idx: 66 | Loss: 0.1142 | Accuracy: 11
	Batch_idx: 67 | Loss: 0.0290 | Accuracy: 6
	Batch_idx: 68 | Loss: 0.1297 | Accuracy: 18
	Batch_idx: 69 | Loss: 0.0081 | Accuracy: 15
	Batch_idx: 70 | Loss: 0.0437 | Accuracy: 14
	Batch_idx: 71 | Loss: 0.0353 | Accuracy: 12
	Batch_idx: 72 | Loss: 0.0235 | Accuracy: 15
	Batch_idx: 73 | Loss: 0.0158 | Accuracy: 11
	Batch_idx: 74 | Loss: 0.0159 | Accuracy: 12
	Batch_idx: 75 | Loss: 0.0413 | Accuracy: 13
	Batch_idx: 76 | Loss: 0.0896 | Accuracy: 16
	Batch_idx: 77 | Loss: 0.0748 | Accuracy: 14
	Batch_idx: 78 | Loss: 0.1214 | Accuracy: 14
	Batch_idx: 79 | Loss: 0.0996 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.1489 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0934 | Accuracy: 14
	Batch_idx: 82 | Loss: 0.0039 | Accuracy: 0
  Class 0, accuracy: 29.7297
  Class 1, accuracy: 8.8364
  Class 2, accuracy: 7.6807
  Class 3, accuracy: 7.8947
  Class 4, accuracy: 13.6951
  Class 5, accuracy: 12.6712
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 16.1880
  Class 8, accuracy: 31.2500
  Class 9, accuracy: 12.7249
  Class 10, accuracy: 10.8961
  Class 11, accuracy: 8.0000
  Class 12, accuracy: 9.7561
  Class 13, accuracy: 14.4269
  Class 14, accuracy: 5.8252
  Class 15, accuracy: 14.6667
Testing Loss: 0.1089 | OA: 11.2262 | AA: 14.6673 | Time: 7.42
Epoch 21/150| Time: 1.63s| Loss: 0.0096
Epoch 22/150| Time: 1.62s| Loss: 0.0101
Epoch 23/150| Time: 1.62s| Loss: 0.0091
Epoch 24/150| Time: 1.63s| Loss: 0.0107
Epoch 25/150| Time: 1.62s| Loss: 0.0085
Epoch 26/150| Time: 1.63s| Loss: 0.0071
Epoch 27/150| Time: 1.64s| Loss: 0.0064
Epoch 28/150| Time: 1.62s| Loss: 0.0069
Epoch 29/150| Time: 1.63s| Loss: 0.0071
Epoch 30/150| Time: 1.62s| Loss: 0.0084
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet30.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet30.model model loaded--<<
	Batch_idx: 0 | Loss: 0.2930 | Accuracy: 22
	Batch_idx: 1 | Loss: 0.0331 | Accuracy: 13
	Batch_idx: 2 | Loss: 0.0963 | Accuracy: 7
	Batch_idx: 3 | Loss: 0.1265 | Accuracy: 10
	Batch_idx: 4 | Loss: 0.1259 | Accuracy: 10
	Batch_idx: 5 | Loss: 0.1091 | Accuracy: 5
	Batch_idx: 6 | Loss: 0.1085 | Accuracy: 6
	Batch_idx: 7 | Loss: 0.1622 | Accuracy: 5
	Batch_idx: 8 | Loss: 0.1464 | Accuracy: 11
	Batch_idx: 9 | Loss: 0.1888 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.2433 | Accuracy: 4
	Batch_idx: 11 | Loss: 0.1473 | Accuracy: 6
	Batch_idx: 12 | Loss: 0.0719 | Accuracy: 1
	Batch_idx: 13 | Loss: 0.1386 | Accuracy: 2
	Batch_idx: 14 | Loss: 0.0458 | Accuracy: 3
	Batch_idx: 15 | Loss: 0.0510 | Accuracy: 3
	Batch_idx: 16 | Loss: 0.0832 | Accuracy: 5
	Batch_idx: 17 | Loss: 0.1610 | Accuracy: 7
	Batch_idx: 18 | Loss: 0.1504 | Accuracy: 10
	Batch_idx: 19 | Loss: 0.2062 | Accuracy: 5
	Batch_idx: 20 | Loss: 0.1082 | Accuracy: 11
	Batch_idx: 21 | Loss: 0.0678 | Accuracy: 11
	Batch_idx: 22 | Loss: 0.1001 | Accuracy: 16
	Batch_idx: 23 | Loss: 0.0267 | Accuracy: 17
	Batch_idx: 24 | Loss: 0.0224 | Accuracy: 18
	Batch_idx: 25 | Loss: 0.0314 | Accuracy: 13
	Batch_idx: 26 | Loss: 0.0177 | Accuracy: 13
	Batch_idx: 27 | Loss: 0.0200 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0159 | Accuracy: 10
	Batch_idx: 29 | Loss: 0.0109 | Accuracy: 12
	Batch_idx: 30 | Loss: 0.1661 | Accuracy: 23
	Batch_idx: 31 | Loss: 0.0119 | Accuracy: 11
	Batch_idx: 32 | Loss: 0.0102 | Accuracy: 10
	Batch_idx: 33 | Loss: 0.0138 | Accuracy: 16
	Batch_idx: 34 | Loss: 0.2529 | Accuracy: 25
	Batch_idx: 35 | Loss: 0.2443 | Accuracy: 14
	Batch_idx: 36 | Loss: 0.2890 | Accuracy: 14
	Batch_idx: 37 | Loss: 0.1547 | Accuracy: 15
	Batch_idx: 38 | Loss: 0.2818 | Accuracy: 13
	Batch_idx: 39 | Loss: 0.0728 | Accuracy: 14
	Batch_idx: 40 | Loss: 0.0754 | Accuracy: 14
	Batch_idx: 41 | Loss: 0.1327 | Accuracy: 11
	Batch_idx: 42 | Loss: 0.0743 | Accuracy: 13
	Batch_idx: 43 | Loss: 0.0511 | Accuracy: 15
	Batch_idx: 44 | Loss: 0.0691 | Accuracy: 11
	Batch_idx: 45 | Loss: 0.0907 | Accuracy: 10
	Batch_idx: 46 | Loss: 0.1488 | Accuracy: 11
	Batch_idx: 47 | Loss: 0.1208 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.1145 | Accuracy: 15
	Batch_idx: 49 | Loss: 0.0992 | Accuracy: 17
	Batch_idx: 50 | Loss: 0.1079 | Accuracy: 13
	Batch_idx: 51 | Loss: 0.0862 | Accuracy: 10
	Batch_idx: 52 | Loss: 0.1250 | Accuracy: 13
	Batch_idx: 53 | Loss: 0.1508 | Accuracy: 11
	Batch_idx: 54 | Loss: 0.1569 | Accuracy: 13
	Batch_idx: 55 | Loss: 0.1260 | Accuracy: 11
	Batch_idx: 56 | Loss: 0.1614 | Accuracy: 9
	Batch_idx: 57 | Loss: 0.1083 | Accuracy: 8
	Batch_idx: 58 | Loss: 0.0644 | Accuracy: 10
	Batch_idx: 59 | Loss: 0.1350 | Accuracy: 10
	Batch_idx: 60 | Loss: 0.1309 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.1212 | Accuracy: 14
	Batch_idx: 62 | Loss: 0.2629 | Accuracy: 8
	Batch_idx: 63 | Loss: 0.2534 | Accuracy: 7
	Batch_idx: 64 | Loss: 0.2242 | Accuracy: 9
	Batch_idx: 65 | Loss: 0.1641 | Accuracy: 7
	Batch_idx: 66 | Loss: 0.1269 | Accuracy: 15
	Batch_idx: 67 | Loss: 0.0287 | Accuracy: 8
	Batch_idx: 68 | Loss: 0.1283 | Accuracy: 22
	Batch_idx: 69 | Loss: 0.0053 | Accuracy: 15
	Batch_idx: 70 | Loss: 0.0452 | Accuracy: 15
	Batch_idx: 71 | Loss: 0.0301 | Accuracy: 13
	Batch_idx: 72 | Loss: 0.0177 | Accuracy: 14
	Batch_idx: 73 | Loss: 0.0108 | Accuracy: 12
	Batch_idx: 74 | Loss: 0.0099 | Accuracy: 10
	Batch_idx: 75 | Loss: 0.0308 | Accuracy: 12
	Batch_idx: 76 | Loss: 0.0866 | Accuracy: 17
	Batch_idx: 77 | Loss: 0.0718 | Accuracy: 15
	Batch_idx: 78 | Loss: 0.1132 | Accuracy: 15
	Batch_idx: 79 | Loss: 0.0948 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.1488 | Accuracy: 8
	Batch_idx: 81 | Loss: 0.0763 | Accuracy: 12
	Batch_idx: 82 | Loss: 0.0016 | Accuracy: 25
  Class 0, accuracy: 24.3243
  Class 1, accuracy: 8.7489
  Class 2, accuracy: 4.0663
  Class 3, accuracy: 8.4211
  Class 4, accuracy: 13.4367
  Class 5, accuracy: 13.5274
  Class 6, accuracy: 34.7826
  Class 7, accuracy: 14.6214
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 14.1388
  Class 10, accuracy: 11.9145
  Class 11, accuracy: 8.6316
  Class 12, accuracy: 12.8049
  Class 13, accuracy: 15.0198
  Class 14, accuracy: 6.1489
  Class 15, accuracy: 13.3333
Testing Loss: 0.1096 | OA: 11.4578 | AA: 15.0888 | Time: 7.14
Epoch 31/150| Time: 1.63s| Loss: 0.0079
Epoch 32/150| Time: 1.62s| Loss: 0.0066
Epoch 33/150| Time: 1.63s| Loss: 0.0065
Epoch 34/150| Time: 1.63s| Loss: 0.0054
Epoch 35/150| Time: 1.63s| Loss: 0.0069
Epoch 36/150| Time: 1.62s| Loss: 0.0059
Epoch 37/150| Time: 1.63s| Loss: 0.0054
Epoch 38/150| Time: 1.62s| Loss: 0.0047
Epoch 39/150| Time: 1.63s| Loss: 0.0046
Epoch 40/150| Time: 1.63s| Loss: 0.0060
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet40.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet40.model model loaded--<<
	Batch_idx: 0 | Loss: 0.4450 | Accuracy: 23
	Batch_idx: 1 | Loss: 0.1274 | Accuracy: 11
	Batch_idx: 2 | Loss: 0.2779 | Accuracy: 13
	Batch_idx: 3 | Loss: 0.2735 | Accuracy: 6
	Batch_idx: 4 | Loss: 0.2870 | Accuracy: 12
	Batch_idx: 5 | Loss: 0.2815 | Accuracy: 8
	Batch_idx: 6 | Loss: 0.2657 | Accuracy: 9
	Batch_idx: 7 | Loss: 0.3039 | Accuracy: 7
	Batch_idx: 8 | Loss: 0.3088 | Accuracy: 11
	Batch_idx: 9 | Loss: 0.3262 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.3460 | Accuracy: 7
	Batch_idx: 11 | Loss: 0.3932 | Accuracy: 9
	Batch_idx: 12 | Loss: 0.0796 | Accuracy: 4
	Batch_idx: 13 | Loss: 0.1093 | Accuracy: 3
	Batch_idx: 14 | Loss: 0.0457 | Accuracy: 3
	Batch_idx: 15 | Loss: 0.0420 | Accuracy: 5
	Batch_idx: 16 | Loss: 0.0840 | Accuracy: 6
	Batch_idx: 17 | Loss: 0.1378 | Accuracy: 11
	Batch_idx: 18 | Loss: 0.1075 | Accuracy: 11
	Batch_idx: 19 | Loss: 0.1418 | Accuracy: 5
	Batch_idx: 20 | Loss: 0.0959 | Accuracy: 14
	Batch_idx: 21 | Loss: 0.0819 | Accuracy: 10
	Batch_idx: 22 | Loss: 0.1052 | Accuracy: 13
	Batch_idx: 23 | Loss: 0.0313 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0204 | Accuracy: 17
	Batch_idx: 25 | Loss: 0.0297 | Accuracy: 10
	Batch_idx: 26 | Loss: 0.0180 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0176 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0134 | Accuracy: 12
	Batch_idx: 29 | Loss: 0.0112 | Accuracy: 11
	Batch_idx: 30 | Loss: 0.1584 | Accuracy: 21
	Batch_idx: 31 | Loss: 0.0079 | Accuracy: 11
	Batch_idx: 32 | Loss: 0.0059 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0085 | Accuracy: 17
	Batch_idx: 34 | Loss: 0.3095 | Accuracy: 22
	Batch_idx: 35 | Loss: 0.2506 | Accuracy: 10
	Batch_idx: 36 | Loss: 0.2630 | Accuracy: 9
	Batch_idx: 37 | Loss: 0.1776 | Accuracy: 9
	Batch_idx: 38 | Loss: 0.3216 | Accuracy: 10
	Batch_idx: 39 | Loss: 0.1835 | Accuracy: 8
	Batch_idx: 40 | Loss: 0.1931 | Accuracy: 11
	Batch_idx: 41 | Loss: 0.2033 | Accuracy: 12
	Batch_idx: 42 | Loss: 0.0589 | Accuracy: 15
	Batch_idx: 43 | Loss: 0.0119 | Accuracy: 15
	Batch_idx: 44 | Loss: 0.0153 | Accuracy: 15
	Batch_idx: 45 | Loss: 0.0156 | Accuracy: 13
	Batch_idx: 46 | Loss: 0.0798 | Accuracy: 13
	Batch_idx: 47 | Loss: 0.0618 | Accuracy: 15
	Batch_idx: 48 | Loss: 0.0250 | Accuracy: 14
	Batch_idx: 49 | Loss: 0.0301 | Accuracy: 13
	Batch_idx: 50 | Loss: 0.0098 | Accuracy: 18
	Batch_idx: 51 | Loss: 0.0112 | Accuracy: 14
	Batch_idx: 52 | Loss: 0.0252 | Accuracy: 12
	Batch_idx: 53 | Loss: 0.0592 | Accuracy: 15
	Batch_idx: 54 | Loss: 0.0307 | Accuracy: 15
	Batch_idx: 55 | Loss: 0.0664 | Accuracy: 16
	Batch_idx: 56 | Loss: 0.0701 | Accuracy: 12
	Batch_idx: 57 | Loss: 0.0656 | Accuracy: 9
	Batch_idx: 58 | Loss: 0.0208 | Accuracy: 10
	Batch_idx: 59 | Loss: 0.0456 | Accuracy: 12
	Batch_idx: 60 | Loss: 0.0488 | Accuracy: 12
	Batch_idx: 61 | Loss: 0.0777 | Accuracy: 17
	Batch_idx: 62 | Loss: 0.3067 | Accuracy: 9
	Batch_idx: 63 | Loss: 0.2506 | Accuracy: 12
	Batch_idx: 64 | Loss: 0.2260 | Accuracy: 10
	Batch_idx: 65 | Loss: 0.1352 | Accuracy: 6
	Batch_idx: 66 | Loss: 0.1374 | Accuracy: 16
	Batch_idx: 67 | Loss: 0.0207 | Accuracy: 7
	Batch_idx: 68 | Loss: 0.1397 | Accuracy: 18
	Batch_idx: 69 | Loss: 0.0047 | Accuracy: 15
	Batch_idx: 70 | Loss: 0.0472 | Accuracy: 13
	Batch_idx: 71 | Loss: 0.0306 | Accuracy: 11
	Batch_idx: 72 | Loss: 0.0134 | Accuracy: 14
	Batch_idx: 73 | Loss: 0.0070 | Accuracy: 11
	Batch_idx: 74 | Loss: 0.0090 | Accuracy: 12
	Batch_idx: 75 | Loss: 0.0330 | Accuracy: 12
	Batch_idx: 76 | Loss: 0.0907 | Accuracy: 14
	Batch_idx: 77 | Loss: 0.0732 | Accuracy: 14
	Batch_idx: 78 | Loss: 0.0944 | Accuracy: 14
	Batch_idx: 79 | Loss: 0.0622 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.1152 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0546 | Accuracy: 14
	Batch_idx: 82 | Loss: 0.0011 | Accuracy: 25
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 10.0612
  Class 2, accuracy: 6.0241
  Class 3, accuracy: 8.4211
  Class 4, accuracy: 12.6615
  Class 5, accuracy: 13.3562
  Class 6, accuracy: 26.0870
  Class 7, accuracy: 14.3603
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 10.6684
  Class 10, accuracy: 13.6456
  Class 11, accuracy: 10.3158
  Class 12, accuracy: 12.1951
  Class 13, accuracy: 13.6364
  Class 14, accuracy: 6.1489
  Class 15, accuracy: 16.0000
Testing Loss: 0.1167 | OA: 11.7504 | AA: 14.8818 | Time: 7.22
Epoch 41/150| Time: 1.64s| Loss: 0.0056
Epoch 42/150| Time: 1.63s| Loss: 0.0046
Epoch 43/150| Time: 1.62s| Loss: 0.0043
Epoch 44/150| Time: 1.63s| Loss: 0.0041
Epoch 45/150| Time: 1.62s| Loss: 0.0060
Epoch 46/150| Time: 1.63s| Loss: 0.0039
Epoch 47/150| Time: 1.62s| Loss: 0.0042
Epoch 48/150| Time: 1.63s| Loss: 0.0043
Epoch 49/150| Time: 1.62s| Loss: 0.0040
Epoch 50/150| Time: 1.63s| Loss: 0.0045
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet50.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet50.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3356 | Accuracy: 24
	Batch_idx: 1 | Loss: 0.0549 | Accuracy: 13
	Batch_idx: 2 | Loss: 0.1438 | Accuracy: 7
	Batch_idx: 3 | Loss: 0.1268 | Accuracy: 9
	Batch_idx: 4 | Loss: 0.1350 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1327 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1307 | Accuracy: 9
	Batch_idx: 7 | Loss: 0.1859 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1794 | Accuracy: 10
	Batch_idx: 9 | Loss: 0.2061 | Accuracy: 12
	Batch_idx: 10 | Loss: 0.2605 | Accuracy: 7
	Batch_idx: 11 | Loss: 0.1718 | Accuracy: 12
	Batch_idx: 12 | Loss: 0.0750 | Accuracy: 3
	Batch_idx: 13 | Loss: 0.1336 | Accuracy: 4
	Batch_idx: 14 | Loss: 0.0380 | Accuracy: 9
	Batch_idx: 15 | Loss: 0.0315 | Accuracy: 4
	Batch_idx: 16 | Loss: 0.0782 | Accuracy: 7
	Batch_idx: 17 | Loss: 0.1583 | Accuracy: 10
	Batch_idx: 18 | Loss: 0.1178 | Accuracy: 14
	Batch_idx: 19 | Loss: 0.1590 | Accuracy: 4
	Batch_idx: 20 | Loss: 0.0941 | Accuracy: 15
	Batch_idx: 21 | Loss: 0.0822 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.1073 | Accuracy: 12
	Batch_idx: 23 | Loss: 0.0295 | Accuracy: 18
	Batch_idx: 24 | Loss: 0.0183 | Accuracy: 15
	Batch_idx: 25 | Loss: 0.0278 | Accuracy: 10
	Batch_idx: 26 | Loss: 0.0154 | Accuracy: 15
	Batch_idx: 27 | Loss: 0.0177 | Accuracy: 14
	Batch_idx: 28 | Loss: 0.0112 | Accuracy: 9
	Batch_idx: 29 | Loss: 0.0091 | Accuracy: 10
	Batch_idx: 30 | Loss: 0.1506 | Accuracy: 25
	Batch_idx: 31 | Loss: 0.0071 | Accuracy: 10
	Batch_idx: 32 | Loss: 0.0059 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0084 | Accuracy: 14
	Batch_idx: 34 | Loss: 0.2291 | Accuracy: 26
	Batch_idx: 35 | Loss: 0.1847 | Accuracy: 15
	Batch_idx: 36 | Loss: 0.1671 | Accuracy: 10
	Batch_idx: 37 | Loss: 0.1139 | Accuracy: 10
	Batch_idx: 38 | Loss: 0.1974 | Accuracy: 18
	Batch_idx: 39 | Loss: 0.0559 | Accuracy: 10
	Batch_idx: 40 | Loss: 0.0472 | Accuracy: 13
	Batch_idx: 41 | Loss: 0.0922 | Accuracy: 12
	Batch_idx: 42 | Loss: 0.0456 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0151 | Accuracy: 13
	Batch_idx: 44 | Loss: 0.0266 | Accuracy: 13
	Batch_idx: 45 | Loss: 0.0359 | Accuracy: 13
	Batch_idx: 46 | Loss: 0.0958 | Accuracy: 12
	Batch_idx: 47 | Loss: 0.0753 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0496 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0355 | Accuracy: 15
	Batch_idx: 50 | Loss: 0.0254 | Accuracy: 15
	Batch_idx: 51 | Loss: 0.0267 | Accuracy: 13
	Batch_idx: 52 | Loss: 0.0495 | Accuracy: 12
	Batch_idx: 53 | Loss: 0.0652 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.0593 | Accuracy: 14
	Batch_idx: 55 | Loss: 0.0802 | Accuracy: 14
	Batch_idx: 56 | Loss: 0.0977 | Accuracy: 14
	Batch_idx: 57 | Loss: 0.0546 | Accuracy: 7
	Batch_idx: 58 | Loss: 0.0351 | Accuracy: 8
	Batch_idx: 59 | Loss: 0.0613 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0828 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.0647 | Accuracy: 14
	Batch_idx: 62 | Loss: 0.1819 | Accuracy: 7
	Batch_idx: 63 | Loss: 0.1430 | Accuracy: 8
	Batch_idx: 64 | Loss: 0.1595 | Accuracy: 6
	Batch_idx: 65 | Loss: 0.0777 | Accuracy: 5
	Batch_idx: 66 | Loss: 0.0811 | Accuracy: 12
	Batch_idx: 67 | Loss: 0.0207 | Accuracy: 6
	Batch_idx: 68 | Loss: 0.1497 | Accuracy: 19
	Batch_idx: 69 | Loss: 0.0058 | Accuracy: 12
	Batch_idx: 70 | Loss: 0.0531 | Accuracy: 13
	Batch_idx: 71 | Loss: 0.0362 | Accuracy: 8
	Batch_idx: 72 | Loss: 0.0222 | Accuracy: 15
	Batch_idx: 73 | Loss: 0.0095 | Accuracy: 12
	Batch_idx: 74 | Loss: 0.0126 | Accuracy: 13
	Batch_idx: 75 | Loss: 0.0363 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.1015 | Accuracy: 14
	Batch_idx: 77 | Loss: 0.0852 | Accuracy: 14
	Batch_idx: 78 | Loss: 0.0952 | Accuracy: 12
	Batch_idx: 79 | Loss: 0.0576 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.0988 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0507 | Accuracy: 13
	Batch_idx: 82 | Loss: 0.0011 | Accuracy: 0
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 9.8863
  Class 2, accuracy: 7.3795
  Class 3, accuracy: 8.9474
  Class 4, accuracy: 12.6615
  Class 5, accuracy: 12.3288
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 14.3603
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 13.2391
  Class 10, accuracy: 12.6782
  Class 11, accuracy: 6.9474
  Class 12, accuracy: 10.3659
  Class 13, accuracy: 13.3399
  Class 14, accuracy: 5.8252
  Class 15, accuracy: 13.3333
Testing Loss: 0.0864 | OA: 11.4944 | AA: 14.7659 | Time: 7.17
Epoch 51/150| Time: 1.63s| Loss: 0.0041
Epoch 52/150| Time: 1.63s| Loss: 0.0036
Epoch 53/150| Time: 1.63s| Loss: 0.0039
Epoch 54/150| Time: 1.63s| Loss: 0.0041
Epoch 55/150| Time: 1.63s| Loss: 0.0039
Epoch 56/150| Time: 1.62s| Loss: 0.0040
Epoch 57/150| Time: 1.62s| Loss: 0.0038
Epoch 58/150| Time: 1.63s| Loss: 0.0041
Epoch 59/150| Time: 1.62s| Loss: 0.0042
Epoch 60/150| Time: 1.63s| Loss: 0.0035
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet60.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet60.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3296 | Accuracy: 24
	Batch_idx: 1 | Loss: 0.0664 | Accuracy: 13
	Batch_idx: 2 | Loss: 0.1644 | Accuracy: 8
	Batch_idx: 3 | Loss: 0.1521 | Accuracy: 7
	Batch_idx: 4 | Loss: 0.1589 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1572 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1561 | Accuracy: 8
	Batch_idx: 7 | Loss: 0.2126 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.2059 | Accuracy: 10
	Batch_idx: 9 | Loss: 0.2372 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.2772 | Accuracy: 6
	Batch_idx: 11 | Loss: 0.2174 | Accuracy: 11
	Batch_idx: 12 | Loss: 0.0621 | Accuracy: 3
	Batch_idx: 13 | Loss: 0.1219 | Accuracy: 3
	Batch_idx: 14 | Loss: 0.0328 | Accuracy: 6
	Batch_idx: 15 | Loss: 0.0260 | Accuracy: 5
	Batch_idx: 16 | Loss: 0.0620 | Accuracy: 5
	Batch_idx: 17 | Loss: 0.1432 | Accuracy: 10
	Batch_idx: 18 | Loss: 0.1166 | Accuracy: 13
	Batch_idx: 19 | Loss: 0.1571 | Accuracy: 5
	Batch_idx: 20 | Loss: 0.0970 | Accuracy: 15
	Batch_idx: 21 | Loss: 0.0757 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.1029 | Accuracy: 11
	Batch_idx: 23 | Loss: 0.0286 | Accuracy: 15
	Batch_idx: 24 | Loss: 0.0184 | Accuracy: 16
	Batch_idx: 25 | Loss: 0.0281 | Accuracy: 11
	Batch_idx: 26 | Loss: 0.0154 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0170 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0114 | Accuracy: 10
	Batch_idx: 29 | Loss: 0.0093 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1485 | Accuracy: 24
	Batch_idx: 31 | Loss: 0.0070 | Accuracy: 11
	Batch_idx: 32 | Loss: 0.0060 | Accuracy: 9
	Batch_idx: 33 | Loss: 0.0082 | Accuracy: 13
	Batch_idx: 34 | Loss: 0.2329 | Accuracy: 25
	Batch_idx: 35 | Loss: 0.2049 | Accuracy: 14
	Batch_idx: 36 | Loss: 0.1908 | Accuracy: 10
	Batch_idx: 37 | Loss: 0.1266 | Accuracy: 10
	Batch_idx: 38 | Loss: 0.2196 | Accuracy: 16
	Batch_idx: 39 | Loss: 0.0625 | Accuracy: 10
	Batch_idx: 40 | Loss: 0.0584 | Accuracy: 13
	Batch_idx: 41 | Loss: 0.1069 | Accuracy: 12
	Batch_idx: 42 | Loss: 0.0461 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0125 | Accuracy: 13
	Batch_idx: 44 | Loss: 0.0196 | Accuracy: 14
	Batch_idx: 45 | Loss: 0.0290 | Accuracy: 14
	Batch_idx: 46 | Loss: 0.0911 | Accuracy: 11
	Batch_idx: 47 | Loss: 0.0662 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0379 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0258 | Accuracy: 16
	Batch_idx: 50 | Loss: 0.0199 | Accuracy: 14
	Batch_idx: 51 | Loss: 0.0177 | Accuracy: 13
	Batch_idx: 52 | Loss: 0.0388 | Accuracy: 11
	Batch_idx: 53 | Loss: 0.0594 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.0431 | Accuracy: 12
	Batch_idx: 55 | Loss: 0.0700 | Accuracy: 13
	Batch_idx: 56 | Loss: 0.0798 | Accuracy: 14
	Batch_idx: 57 | Loss: 0.0480 | Accuracy: 8
	Batch_idx: 58 | Loss: 0.0287 | Accuracy: 9
	Batch_idx: 59 | Loss: 0.0533 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0701 | Accuracy: 12
	Batch_idx: 61 | Loss: 0.0585 | Accuracy: 14
	Batch_idx: 62 | Loss: 0.1894 | Accuracy: 7
	Batch_idx: 63 | Loss: 0.1449 | Accuracy: 8
	Batch_idx: 64 | Loss: 0.1635 | Accuracy: 6
	Batch_idx: 65 | Loss: 0.0826 | Accuracy: 5
	Batch_idx: 66 | Loss: 0.0896 | Accuracy: 9
	Batch_idx: 67 | Loss: 0.0189 | Accuracy: 6
	Batch_idx: 68 | Loss: 0.1420 | Accuracy: 22
	Batch_idx: 69 | Loss: 0.0039 | Accuracy: 16
	Batch_idx: 70 | Loss: 0.0482 | Accuracy: 14
	Batch_idx: 71 | Loss: 0.0284 | Accuracy: 11
	Batch_idx: 72 | Loss: 0.0161 | Accuracy: 15
	Batch_idx: 73 | Loss: 0.0064 | Accuracy: 11
	Batch_idx: 74 | Loss: 0.0080 | Accuracy: 12
	Batch_idx: 75 | Loss: 0.0317 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.0940 | Accuracy: 15
	Batch_idx: 77 | Loss: 0.0746 | Accuracy: 17
	Batch_idx: 78 | Loss: 0.0924 | Accuracy: 13
	Batch_idx: 79 | Loss: 0.0666 | Accuracy: 5
	Batch_idx: 80 | Loss: 0.1158 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0546 | Accuracy: 13
	Batch_idx: 82 | Loss: 0.0009 | Accuracy: 25
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 9.5363
  Class 2, accuracy: 6.3253
  Class 3, accuracy: 8.9474
  Class 4, accuracy: 12.1447
  Class 5, accuracy: 12.5000
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 14.3603
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 12.7249
  Class 10, accuracy: 12.5764
  Class 11, accuracy: 6.7368
  Class 12, accuracy: 9.7561
  Class 13, accuracy: 14.6245
  Class 14, accuracy: 6.1489
  Class 15, accuracy: 14.6667
Testing Loss: 0.0880 | OA: 11.4334 | AA: 14.7506 | Time: 7.20
Epoch 61/150| Time: 1.65s| Loss: 0.0040
Epoch 62/150| Time: 1.64s| Loss: 0.0037
Epoch 63/150| Time: 1.71s| Loss: 0.0036
Epoch 64/150| Time: 1.65s| Loss: 0.0034
Epoch 65/150| Time: 1.63s| Loss: 0.0044
Epoch 66/150| Time: 1.64s| Loss: 0.0035
Epoch 67/150| Time: 1.71s| Loss: 0.0044
Epoch 68/150| Time: 1.63s| Loss: 0.0044
Epoch 69/150| Time: 1.63s| Loss: 0.0039
Epoch 70/150| Time: 1.64s| Loss: 0.0034
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet70.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet70.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3190 | Accuracy: 24
	Batch_idx: 1 | Loss: 0.0519 | Accuracy: 13
	Batch_idx: 2 | Loss: 0.1296 | Accuracy: 8
	Batch_idx: 3 | Loss: 0.1188 | Accuracy: 7
	Batch_idx: 4 | Loss: 0.1278 | Accuracy: 10
	Batch_idx: 5 | Loss: 0.1216 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1195 | Accuracy: 10
	Batch_idx: 7 | Loss: 0.1795 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1732 | Accuracy: 10
	Batch_idx: 9 | Loss: 0.1947 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.2447 | Accuracy: 5
	Batch_idx: 11 | Loss: 0.1640 | Accuracy: 10
	Batch_idx: 12 | Loss: 0.0726 | Accuracy: 3
	Batch_idx: 13 | Loss: 0.1293 | Accuracy: 3
	Batch_idx: 14 | Loss: 0.0415 | Accuracy: 5
	Batch_idx: 15 | Loss: 0.0365 | Accuracy: 4
	Batch_idx: 16 | Loss: 0.0751 | Accuracy: 5
	Batch_idx: 17 | Loss: 0.1507 | Accuracy: 10
	Batch_idx: 18 | Loss: 0.1118 | Accuracy: 11
	Batch_idx: 19 | Loss: 0.1422 | Accuracy: 2
	Batch_idx: 20 | Loss: 0.0823 | Accuracy: 15
	Batch_idx: 21 | Loss: 0.0702 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.0969 | Accuracy: 12
	Batch_idx: 23 | Loss: 0.0256 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0158 | Accuracy: 17
	Batch_idx: 25 | Loss: 0.0232 | Accuracy: 11
	Batch_idx: 26 | Loss: 0.0129 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0148 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0085 | Accuracy: 11
	Batch_idx: 29 | Loss: 0.0075 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1486 | Accuracy: 25
	Batch_idx: 31 | Loss: 0.0059 | Accuracy: 11
	Batch_idx: 32 | Loss: 0.0053 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0075 | Accuracy: 14
	Batch_idx: 34 | Loss: 0.2493 | Accuracy: 23
	Batch_idx: 35 | Loss: 0.1987 | Accuracy: 15
	Batch_idx: 36 | Loss: 0.1673 | Accuracy: 12
	Batch_idx: 37 | Loss: 0.1199 | Accuracy: 10
	Batch_idx: 38 | Loss: 0.2135 | Accuracy: 16
	Batch_idx: 39 | Loss: 0.0660 | Accuracy: 11
	Batch_idx: 40 | Loss: 0.0606 | Accuracy: 12
	Batch_idx: 41 | Loss: 0.0989 | Accuracy: 11
	Batch_idx: 42 | Loss: 0.0452 | Accuracy: 13
	Batch_idx: 43 | Loss: 0.0157 | Accuracy: 13
	Batch_idx: 44 | Loss: 0.0242 | Accuracy: 11
	Batch_idx: 45 | Loss: 0.0338 | Accuracy: 11
	Batch_idx: 46 | Loss: 0.1026 | Accuracy: 11
	Batch_idx: 47 | Loss: 0.0662 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0459 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0356 | Accuracy: 15
	Batch_idx: 50 | Loss: 0.0245 | Accuracy: 16
	Batch_idx: 51 | Loss: 0.0230 | Accuracy: 12
	Batch_idx: 52 | Loss: 0.0429 | Accuracy: 9
	Batch_idx: 53 | Loss: 0.0648 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.0533 | Accuracy: 14
	Batch_idx: 55 | Loss: 0.0730 | Accuracy: 14
	Batch_idx: 56 | Loss: 0.0979 | Accuracy: 12
	Batch_idx: 57 | Loss: 0.0529 | Accuracy: 8
	Batch_idx: 58 | Loss: 0.0355 | Accuracy: 6
	Batch_idx: 59 | Loss: 0.0608 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0809 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.0573 | Accuracy: 12
	Batch_idx: 62 | Loss: 0.1846 | Accuracy: 8
	Batch_idx: 63 | Loss: 0.1353 | Accuracy: 7
	Batch_idx: 64 | Loss: 0.1453 | Accuracy: 6
	Batch_idx: 65 | Loss: 0.0737 | Accuracy: 5
	Batch_idx: 66 | Loss: 0.0735 | Accuracy: 11
	Batch_idx: 67 | Loss: 0.0179 | Accuracy: 5
	Batch_idx: 68 | Loss: 0.1448 | Accuracy: 21
	Batch_idx: 69 | Loss: 0.0046 | Accuracy: 13
	Batch_idx: 70 | Loss: 0.0503 | Accuracy: 14
	Batch_idx: 71 | Loss: 0.0318 | Accuracy: 10
	Batch_idx: 72 | Loss: 0.0205 | Accuracy: 15
	Batch_idx: 73 | Loss: 0.0078 | Accuracy: 12
	Batch_idx: 74 | Loss: 0.0093 | Accuracy: 12
	Batch_idx: 75 | Loss: 0.0355 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.0978 | Accuracy: 15
	Batch_idx: 77 | Loss: 0.0807 | Accuracy: 16
	Batch_idx: 78 | Loss: 0.0890 | Accuracy: 14
	Batch_idx: 79 | Loss: 0.0596 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.1022 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0492 | Accuracy: 13
	Batch_idx: 82 | Loss: 0.0008 | Accuracy: 0
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 9.4488
  Class 2, accuracy: 5.8735
  Class 3, accuracy: 6.8421
  Class 4, accuracy: 12.6615
  Class 5, accuracy: 12.8425
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 14.6214
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 12.7249
  Class 10, accuracy: 11.9654
  Class 11, accuracy: 6.9474
  Class 12, accuracy: 9.7561
  Class 13, accuracy: 14.2292
  Class 14, accuracy: 5.8252
  Class 15, accuracy: 13.3333
Testing Loss: 0.0835 | OA: 11.1897 | AA: 14.5021 | Time: 7.23
Epoch 71/150| Time: 1.64s| Loss: 0.0042
Epoch 72/150| Time: 1.63s| Loss: 0.0049
Epoch 73/150| Time: 1.63s| Loss: 0.0050
Epoch 74/150| Time: 1.67s| Loss: 0.0037
Epoch 75/150| Time: 1.64s| Loss: 0.0035
Epoch 76/150| Time: 1.63s| Loss: 0.0038
Epoch 77/150| Time: 1.67s| Loss: 0.0035
Epoch 78/150| Time: 1.63s| Loss: 0.0037
Epoch 79/150| Time: 1.63s| Loss: 0.0039
Epoch 80/150| Time: 1.64s| Loss: 0.0038
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet80.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet80.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3042 | Accuracy: 24
	Batch_idx: 1 | Loss: 0.0474 | Accuracy: 13
	Batch_idx: 2 | Loss: 0.1327 | Accuracy: 7
	Batch_idx: 3 | Loss: 0.1183 | Accuracy: 7
	Batch_idx: 4 | Loss: 0.1238 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1222 | Accuracy: 8
	Batch_idx: 6 | Loss: 0.1130 | Accuracy: 11
	Batch_idx: 7 | Loss: 0.1802 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1731 | Accuracy: 10
	Batch_idx: 9 | Loss: 0.1960 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.2376 | Accuracy: 6
	Batch_idx: 11 | Loss: 0.1662 | Accuracy: 10
	Batch_idx: 12 | Loss: 0.0717 | Accuracy: 2
	Batch_idx: 13 | Loss: 0.1412 | Accuracy: 4
	Batch_idx: 14 | Loss: 0.0393 | Accuracy: 7
	Batch_idx: 15 | Loss: 0.0329 | Accuracy: 4
	Batch_idx: 16 | Loss: 0.0708 | Accuracy: 6
	Batch_idx: 17 | Loss: 0.1522 | Accuracy: 9
	Batch_idx: 18 | Loss: 0.1127 | Accuracy: 14
	Batch_idx: 19 | Loss: 0.1495 | Accuracy: 4
	Batch_idx: 20 | Loss: 0.0894 | Accuracy: 15
	Batch_idx: 21 | Loss: 0.0766 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.1044 | Accuracy: 12
	Batch_idx: 23 | Loss: 0.0279 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0167 | Accuracy: 17
	Batch_idx: 25 | Loss: 0.0239 | Accuracy: 10
	Batch_idx: 26 | Loss: 0.0128 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0152 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0096 | Accuracy: 11
	Batch_idx: 29 | Loss: 0.0073 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1474 | Accuracy: 24
	Batch_idx: 31 | Loss: 0.0060 | Accuracy: 9
	Batch_idx: 32 | Loss: 0.0051 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0071 | Accuracy: 14
	Batch_idx: 34 | Loss: 0.2308 | Accuracy: 24
	Batch_idx: 35 | Loss: 0.2018 | Accuracy: 14
	Batch_idx: 36 | Loss: 0.1841 | Accuracy: 12
	Batch_idx: 37 | Loss: 0.1262 | Accuracy: 11
	Batch_idx: 38 | Loss: 0.2128 | Accuracy: 17
	Batch_idx: 39 | Loss: 0.0587 | Accuracy: 11
	Batch_idx: 40 | Loss: 0.0547 | Accuracy: 12
	Batch_idx: 41 | Loss: 0.1034 | Accuracy: 11
	Batch_idx: 42 | Loss: 0.0391 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0127 | Accuracy: 13
	Batch_idx: 44 | Loss: 0.0200 | Accuracy: 13
	Batch_idx: 45 | Loss: 0.0306 | Accuracy: 13
	Batch_idx: 46 | Loss: 0.0874 | Accuracy: 12
	Batch_idx: 47 | Loss: 0.0606 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0379 | Accuracy: 14
	Batch_idx: 49 | Loss: 0.0249 | Accuracy: 18
	Batch_idx: 50 | Loss: 0.0234 | Accuracy: 14
	Batch_idx: 51 | Loss: 0.0214 | Accuracy: 13
	Batch_idx: 52 | Loss: 0.0468 | Accuracy: 10
	Batch_idx: 53 | Loss: 0.0601 | Accuracy: 13
	Batch_idx: 54 | Loss: 0.0458 | Accuracy: 13
	Batch_idx: 55 | Loss: 0.0635 | Accuracy: 13
	Batch_idx: 56 | Loss: 0.0832 | Accuracy: 13
	Batch_idx: 57 | Loss: 0.0442 | Accuracy: 7
	Batch_idx: 58 | Loss: 0.0282 | Accuracy: 8
	Batch_idx: 59 | Loss: 0.0537 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0694 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.0638 | Accuracy: 13
	Batch_idx: 62 | Loss: 0.2027 | Accuracy: 8
	Batch_idx: 63 | Loss: 0.1564 | Accuracy: 7
	Batch_idx: 64 | Loss: 0.1742 | Accuracy: 7
	Batch_idx: 65 | Loss: 0.0820 | Accuracy: 4
	Batch_idx: 66 | Loss: 0.0892 | Accuracy: 11
	Batch_idx: 67 | Loss: 0.0191 | Accuracy: 4
	Batch_idx: 68 | Loss: 0.1466 | Accuracy: 20
	Batch_idx: 69 | Loss: 0.0050 | Accuracy: 14
	Batch_idx: 70 | Loss: 0.0542 | Accuracy: 11
	Batch_idx: 71 | Loss: 0.0322 | Accuracy: 10
	Batch_idx: 72 | Loss: 0.0213 | Accuracy: 13
	Batch_idx: 73 | Loss: 0.0077 | Accuracy: 11
	Batch_idx: 74 | Loss: 0.0101 | Accuracy: 12
	Batch_idx: 75 | Loss: 0.0369 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.1015 | Accuracy: 15
	Batch_idx: 77 | Loss: 0.0855 | Accuracy: 16
	Batch_idx: 78 | Loss: 0.0905 | Accuracy: 14
	Batch_idx: 79 | Loss: 0.0627 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.1035 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0572 | Accuracy: 15
	Batch_idx: 82 | Loss: 0.0012 | Accuracy: 25
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 9.7113
  Class 2, accuracy: 6.4759
  Class 3, accuracy: 8.9474
  Class 4, accuracy: 12.6615
  Class 5, accuracy: 12.5000
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 13.8381
  Class 8, accuracy: 31.2500
  Class 9, accuracy: 13.1105
  Class 10, accuracy: 12.5764
  Class 11, accuracy: 7.1579
  Class 12, accuracy: 8.5366
  Class 13, accuracy: 13.6364
  Class 14, accuracy: 5.8252
  Class 15, accuracy: 17.3333
Testing Loss: 0.0837 | OA: 11.3847 | AA: 14.4389 | Time: 7.25
Epoch 81/150| Time: 1.64s| Loss: 0.0034
Epoch 82/150| Time: 1.64s| Loss: 0.0037
Epoch 83/150| Time: 1.65s| Loss: 0.0037
Epoch 84/150| Time: 1.64s| Loss: 0.0050
Epoch 85/150| Time: 1.64s| Loss: 0.0033
Epoch 86/150| Time: 1.64s| Loss: 0.0033
Epoch 87/150| Time: 1.64s| Loss: 0.0036
Epoch 88/150| Time: 1.63s| Loss: 0.0034
Epoch 89/150| Time: 1.63s| Loss: 0.0042
Epoch 90/150| Time: 1.63s| Loss: 0.0033
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet90.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet90.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3259 | Accuracy: 24
	Batch_idx: 1 | Loss: 0.0531 | Accuracy: 14
	Batch_idx: 2 | Loss: 0.1401 | Accuracy: 7
	Batch_idx: 3 | Loss: 0.1270 | Accuracy: 8
	Batch_idx: 4 | Loss: 0.1353 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1260 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1256 | Accuracy: 10
	Batch_idx: 7 | Loss: 0.1928 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1853 | Accuracy: 11
	Batch_idx: 9 | Loss: 0.2085 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.2533 | Accuracy: 7
	Batch_idx: 11 | Loss: 0.1764 | Accuracy: 10
	Batch_idx: 12 | Loss: 0.0681 | Accuracy: 2
	Batch_idx: 13 | Loss: 0.1314 | Accuracy: 3
	Batch_idx: 14 | Loss: 0.0350 | Accuracy: 5
	Batch_idx: 15 | Loss: 0.0315 | Accuracy: 4
	Batch_idx: 16 | Loss: 0.0687 | Accuracy: 6
	Batch_idx: 17 | Loss: 0.1516 | Accuracy: 10
	Batch_idx: 18 | Loss: 0.1231 | Accuracy: 13
	Batch_idx: 19 | Loss: 0.1689 | Accuracy: 6
	Batch_idx: 20 | Loss: 0.0947 | Accuracy: 15
	Batch_idx: 21 | Loss: 0.0717 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.0987 | Accuracy: 12
	Batch_idx: 23 | Loss: 0.0260 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0173 | Accuracy: 17
	Batch_idx: 25 | Loss: 0.0281 | Accuracy: 11
	Batch_idx: 26 | Loss: 0.0151 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0177 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0113 | Accuracy: 10
	Batch_idx: 29 | Loss: 0.0090 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1477 | Accuracy: 25
	Batch_idx: 31 | Loss: 0.0063 | Accuracy: 9
	Batch_idx: 32 | Loss: 0.0051 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0072 | Accuracy: 16
	Batch_idx: 34 | Loss: 0.2188 | Accuracy: 25
	Batch_idx: 35 | Loss: 0.1806 | Accuracy: 17
	Batch_idx: 36 | Loss: 0.1603 | Accuracy: 12
	Batch_idx: 37 | Loss: 0.1110 | Accuracy: 11
	Batch_idx: 38 | Loss: 0.1940 | Accuracy: 18
	Batch_idx: 39 | Loss: 0.0539 | Accuracy: 11
	Batch_idx: 40 | Loss: 0.0497 | Accuracy: 11
	Batch_idx: 41 | Loss: 0.0917 | Accuracy: 13
	Batch_idx: 42 | Loss: 0.0394 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0129 | Accuracy: 13
	Batch_idx: 44 | Loss: 0.0213 | Accuracy: 13
	Batch_idx: 45 | Loss: 0.0288 | Accuracy: 14
	Batch_idx: 46 | Loss: 0.0900 | Accuracy: 11
	Batch_idx: 47 | Loss: 0.0649 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0411 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0273 | Accuracy: 15
	Batch_idx: 50 | Loss: 0.0216 | Accuracy: 15
	Batch_idx: 51 | Loss: 0.0194 | Accuracy: 13
	Batch_idx: 52 | Loss: 0.0455 | Accuracy: 10
	Batch_idx: 53 | Loss: 0.0612 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.0495 | Accuracy: 13
	Batch_idx: 55 | Loss: 0.0674 | Accuracy: 13
	Batch_idx: 56 | Loss: 0.0886 | Accuracy: 13
	Batch_idx: 57 | Loss: 0.0454 | Accuracy: 7
	Batch_idx: 58 | Loss: 0.0292 | Accuracy: 8
	Batch_idx: 59 | Loss: 0.0535 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0677 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.0628 | Accuracy: 12
	Batch_idx: 62 | Loss: 0.1923 | Accuracy: 8
	Batch_idx: 63 | Loss: 0.1480 | Accuracy: 7
	Batch_idx: 64 | Loss: 0.1653 | Accuracy: 8
	Batch_idx: 65 | Loss: 0.0782 | Accuracy: 4
	Batch_idx: 66 | Loss: 0.0829 | Accuracy: 13
	Batch_idx: 67 | Loss: 0.0174 | Accuracy: 5
	Batch_idx: 68 | Loss: 0.1520 | Accuracy: 20
	Batch_idx: 69 | Loss: 0.0049 | Accuracy: 14
	Batch_idx: 70 | Loss: 0.0562 | Accuracy: 12
	Batch_idx: 71 | Loss: 0.0334 | Accuracy: 11
	Batch_idx: 72 | Loss: 0.0222 | Accuracy: 13
	Batch_idx: 73 | Loss: 0.0080 | Accuracy: 13
	Batch_idx: 74 | Loss: 0.0109 | Accuracy: 14
	Batch_idx: 75 | Loss: 0.0369 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.1060 | Accuracy: 14
	Batch_idx: 77 | Loss: 0.0895 | Accuracy: 16
	Batch_idx: 78 | Loss: 0.0880 | Accuracy: 14
	Batch_idx: 79 | Loss: 0.0535 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.0918 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0495 | Accuracy: 14
	Batch_idx: 82 | Loss: 0.0008 | Accuracy: 25
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 9.8863
  Class 2, accuracy: 6.1747
  Class 3, accuracy: 9.4737
  Class 4, accuracy: 12.6615
  Class 5, accuracy: 12.5000
  Class 6, accuracy: 34.7826
  Class 7, accuracy: 14.3603
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 13.7532
  Class 10, accuracy: 12.3218
  Class 11, accuracy: 7.5789
  Class 12, accuracy: 9.1463
  Class 13, accuracy: 14.1304
  Class 14, accuracy: 6.1489
  Class 15, accuracy: 16.0000
Testing Loss: 0.0837 | OA: 11.5431 | AA: 15.2154 | Time: 7.19
Epoch 91/150| Time: 1.64s| Loss: 0.0033
Epoch 92/150| Time: 1.64s| Loss: 0.0031
Epoch 93/150| Time: 1.63s| Loss: 0.0035
Epoch 94/150| Time: 1.71s| Loss: 0.0034
Epoch 95/150| Time: 1.62s| Loss: 0.0034
Epoch 96/150| Time: 1.63s| Loss: 0.0039
Epoch 97/150| Time: 1.64s| Loss: 0.0032
Epoch 98/150| Time: 1.68s| Loss: 0.0040
Epoch 99/150| Time: 1.63s| Loss: 0.0034
Epoch 100/150| Time: 1.64s| Loss: 0.0035
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet100.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet100.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3134 | Accuracy: 24
	Batch_idx: 1 | Loss: 0.0527 | Accuracy: 14
	Batch_idx: 2 | Loss: 0.1320 | Accuracy: 7
	Batch_idx: 3 | Loss: 0.1242 | Accuracy: 8
	Batch_idx: 4 | Loss: 0.1334 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1228 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1177 | Accuracy: 10
	Batch_idx: 7 | Loss: 0.1860 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1771 | Accuracy: 10
	Batch_idx: 9 | Loss: 0.2014 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.2465 | Accuracy: 8
	Batch_idx: 11 | Loss: 0.1695 | Accuracy: 9
	Batch_idx: 12 | Loss: 0.0674 | Accuracy: 2
	Batch_idx: 13 | Loss: 0.1300 | Accuracy: 4
	Batch_idx: 14 | Loss: 0.0348 | Accuracy: 9
	Batch_idx: 15 | Loss: 0.0308 | Accuracy: 3
	Batch_idx: 16 | Loss: 0.0715 | Accuracy: 6
	Batch_idx: 17 | Loss: 0.1502 | Accuracy: 11
	Batch_idx: 18 | Loss: 0.1286 | Accuracy: 14
	Batch_idx: 19 | Loss: 0.1728 | Accuracy: 4
	Batch_idx: 20 | Loss: 0.0976 | Accuracy: 16
	Batch_idx: 21 | Loss: 0.0722 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.1012 | Accuracy: 13
	Batch_idx: 23 | Loss: 0.0257 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0172 | Accuracy: 15
	Batch_idx: 25 | Loss: 0.0232 | Accuracy: 12
	Batch_idx: 26 | Loss: 0.0126 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0149 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0092 | Accuracy: 10
	Batch_idx: 29 | Loss: 0.0073 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1511 | Accuracy: 25
	Batch_idx: 31 | Loss: 0.0073 | Accuracy: 10
	Batch_idx: 32 | Loss: 0.0064 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0088 | Accuracy: 15
	Batch_idx: 34 | Loss: 0.2338 | Accuracy: 26
	Batch_idx: 35 | Loss: 0.1793 | Accuracy: 16
	Batch_idx: 36 | Loss: 0.1578 | Accuracy: 11
	Batch_idx: 37 | Loss: 0.1047 | Accuracy: 10
	Batch_idx: 38 | Loss: 0.1858 | Accuracy: 16
	Batch_idx: 39 | Loss: 0.0513 | Accuracy: 9
	Batch_idx: 40 | Loss: 0.0452 | Accuracy: 13
	Batch_idx: 41 | Loss: 0.0885 | Accuracy: 10
	Batch_idx: 42 | Loss: 0.0441 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0145 | Accuracy: 14
	Batch_idx: 44 | Loss: 0.0277 | Accuracy: 11
	Batch_idx: 45 | Loss: 0.0333 | Accuracy: 13
	Batch_idx: 46 | Loss: 0.0924 | Accuracy: 11
	Batch_idx: 47 | Loss: 0.0683 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0492 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0303 | Accuracy: 15
	Batch_idx: 50 | Loss: 0.0232 | Accuracy: 15
	Batch_idx: 51 | Loss: 0.0231 | Accuracy: 12
	Batch_idx: 52 | Loss: 0.0489 | Accuracy: 10
	Batch_idx: 53 | Loss: 0.0684 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.0574 | Accuracy: 13
	Batch_idx: 55 | Loss: 0.0748 | Accuracy: 13
	Batch_idx: 56 | Loss: 0.0933 | Accuracy: 13
	Batch_idx: 57 | Loss: 0.0500 | Accuracy: 7
	Batch_idx: 58 | Loss: 0.0328 | Accuracy: 8
	Batch_idx: 59 | Loss: 0.0617 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0787 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.0685 | Accuracy: 13
	Batch_idx: 62 | Loss: 0.2043 | Accuracy: 9
	Batch_idx: 63 | Loss: 0.1648 | Accuracy: 7
	Batch_idx: 64 | Loss: 0.1737 | Accuracy: 8
	Batch_idx: 65 | Loss: 0.0855 | Accuracy: 5
	Batch_idx: 66 | Loss: 0.0889 | Accuracy: 12
	Batch_idx: 67 | Loss: 0.0187 | Accuracy: 5
	Batch_idx: 68 | Loss: 0.1472 | Accuracy: 20
	Batch_idx: 69 | Loss: 0.0045 | Accuracy: 15
	Batch_idx: 70 | Loss: 0.0518 | Accuracy: 12
	Batch_idx: 71 | Loss: 0.0305 | Accuracy: 10
	Batch_idx: 72 | Loss: 0.0214 | Accuracy: 15
	Batch_idx: 73 | Loss: 0.0075 | Accuracy: 11
	Batch_idx: 74 | Loss: 0.0095 | Accuracy: 11
	Batch_idx: 75 | Loss: 0.0350 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.1004 | Accuracy: 15
	Batch_idx: 77 | Loss: 0.0822 | Accuracy: 15
	Batch_idx: 78 | Loss: 0.0943 | Accuracy: 13
	Batch_idx: 79 | Loss: 0.0659 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.1061 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0666 | Accuracy: 13
	Batch_idx: 82 | Loss: 0.0021 | Accuracy: 25
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 9.8863
  Class 2, accuracy: 6.7771
  Class 3, accuracy: 8.9474
  Class 4, accuracy: 12.6615
  Class 5, accuracy: 12.6712
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 14.6214
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 12.8535
  Class 10, accuracy: 12.1690
  Class 11, accuracy: 8.0000
  Class 12, accuracy: 9.7561
  Class 13, accuracy: 13.8340
  Class 14, accuracy: 5.5016
  Class 15, accuracy: 14.6667
Testing Loss: 0.0849 | OA: 11.4334 | AA: 14.8317 | Time: 7.21
Epoch 101/150| Time: 1.64s| Loss: 0.0034
Epoch 102/150| Time: 1.64s| Loss: 0.0038
Epoch 103/150| Time: 1.64s| Loss: 0.0036
Epoch 104/150| Time: 1.64s| Loss: 0.0036
Epoch 105/150| Time: 1.64s| Loss: 0.0039
Epoch 106/150| Time: 1.63s| Loss: 0.0036
Epoch 107/150| Time: 1.64s| Loss: 0.0033
Epoch 108/150| Time: 1.63s| Loss: 0.0051
Epoch 109/150| Time: 1.63s| Loss: 0.0031
Epoch 110/150| Time: 1.63s| Loss: 0.0037
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet110.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet110.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3117 | Accuracy: 25
	Batch_idx: 1 | Loss: 0.0486 | Accuracy: 13
	Batch_idx: 2 | Loss: 0.1379 | Accuracy: 7
	Batch_idx: 3 | Loss: 0.1218 | Accuracy: 7
	Batch_idx: 4 | Loss: 0.1287 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1186 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1165 | Accuracy: 9
	Batch_idx: 7 | Loss: 0.1867 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1758 | Accuracy: 10
	Batch_idx: 9 | Loss: 0.1997 | Accuracy: 10
	Batch_idx: 10 | Loss: 0.2459 | Accuracy: 7
	Batch_idx: 11 | Loss: 0.1753 | Accuracy: 9
	Batch_idx: 12 | Loss: 0.0695 | Accuracy: 2
	Batch_idx: 13 | Loss: 0.1355 | Accuracy: 3
	Batch_idx: 14 | Loss: 0.0381 | Accuracy: 4
	Batch_idx: 15 | Loss: 0.0328 | Accuracy: 4
	Batch_idx: 16 | Loss: 0.0694 | Accuracy: 6
	Batch_idx: 17 | Loss: 0.1549 | Accuracy: 10
	Batch_idx: 18 | Loss: 0.1149 | Accuracy: 13
	Batch_idx: 19 | Loss: 0.1518 | Accuracy: 4
	Batch_idx: 20 | Loss: 0.0897 | Accuracy: 15
	Batch_idx: 21 | Loss: 0.0787 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.1053 | Accuracy: 13
	Batch_idx: 23 | Loss: 0.0283 | Accuracy: 15
	Batch_idx: 24 | Loss: 0.0175 | Accuracy: 17
	Batch_idx: 25 | Loss: 0.0280 | Accuracy: 11
	Batch_idx: 26 | Loss: 0.0151 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0175 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0114 | Accuracy: 10
	Batch_idx: 29 | Loss: 0.0090 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1428 | Accuracy: 24
	Batch_idx: 31 | Loss: 0.0064 | Accuracy: 11
	Batch_idx: 32 | Loss: 0.0059 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0078 | Accuracy: 14
	Batch_idx: 34 | Loss: 0.2281 | Accuracy: 26
	Batch_idx: 35 | Loss: 0.2008 | Accuracy: 17
	Batch_idx: 36 | Loss: 0.1763 | Accuracy: 11
	Batch_idx: 37 | Loss: 0.1224 | Accuracy: 10
	Batch_idx: 38 | Loss: 0.2104 | Accuracy: 18
	Batch_idx: 39 | Loss: 0.0598 | Accuracy: 11
	Batch_idx: 40 | Loss: 0.0574 | Accuracy: 10
	Batch_idx: 41 | Loss: 0.0991 | Accuracy: 10
	Batch_idx: 42 | Loss: 0.0404 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0125 | Accuracy: 14
	Batch_idx: 44 | Loss: 0.0213 | Accuracy: 13
	Batch_idx: 45 | Loss: 0.0266 | Accuracy: 13
	Batch_idx: 46 | Loss: 0.0888 | Accuracy: 12
	Batch_idx: 47 | Loss: 0.0620 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0382 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0268 | Accuracy: 15
	Batch_idx: 50 | Loss: 0.0210 | Accuracy: 14
	Batch_idx: 51 | Loss: 0.0204 | Accuracy: 13
	Batch_idx: 52 | Loss: 0.0441 | Accuracy: 10
	Batch_idx: 53 | Loss: 0.0593 | Accuracy: 13
	Batch_idx: 54 | Loss: 0.0468 | Accuracy: 12
	Batch_idx: 55 | Loss: 0.0670 | Accuracy: 13
	Batch_idx: 56 | Loss: 0.0846 | Accuracy: 14
	Batch_idx: 57 | Loss: 0.0433 | Accuracy: 7
	Batch_idx: 58 | Loss: 0.0273 | Accuracy: 8
	Batch_idx: 59 | Loss: 0.0531 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0661 | Accuracy: 14
	Batch_idx: 61 | Loss: 0.0635 | Accuracy: 15
	Batch_idx: 62 | Loss: 0.1986 | Accuracy: 10
	Batch_idx: 63 | Loss: 0.1521 | Accuracy: 8
	Batch_idx: 64 | Loss: 0.1648 | Accuracy: 9
	Batch_idx: 65 | Loss: 0.0830 | Accuracy: 4
	Batch_idx: 66 | Loss: 0.0837 | Accuracy: 13
	Batch_idx: 67 | Loss: 0.0171 | Accuracy: 4
	Batch_idx: 68 | Loss: 0.1537 | Accuracy: 19
	Batch_idx: 69 | Loss: 0.0052 | Accuracy: 13
	Batch_idx: 70 | Loss: 0.0554 | Accuracy: 14
	Batch_idx: 71 | Loss: 0.0332 | Accuracy: 10
	Batch_idx: 72 | Loss: 0.0224 | Accuracy: 14
	Batch_idx: 73 | Loss: 0.0084 | Accuracy: 13
	Batch_idx: 74 | Loss: 0.0114 | Accuracy: 13
	Batch_idx: 75 | Loss: 0.0383 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.1064 | Accuracy: 15
	Batch_idx: 77 | Loss: 0.0906 | Accuracy: 15
	Batch_idx: 78 | Loss: 0.0869 | Accuracy: 14
	Batch_idx: 79 | Loss: 0.0532 | Accuracy: 3
	Batch_idx: 80 | Loss: 0.0911 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0481 | Accuracy: 13
	Batch_idx: 82 | Loss: 0.0010 | Accuracy: 0
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 9.5363
  Class 2, accuracy: 5.8735
  Class 3, accuracy: 8.4211
  Class 4, accuracy: 12.4031
  Class 5, accuracy: 12.6712
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 14.0992
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 13.2391
  Class 10, accuracy: 12.4745
  Class 11, accuracy: 8.8421
  Class 12, accuracy: 8.5366
  Class 13, accuracy: 14.1304
  Class 14, accuracy: 5.5016
  Class 15, accuracy: 13.3333
Testing Loss: 0.0837 | OA: 11.4213 | AA: 14.6265 | Time: 7.06
Epoch 111/150| Time: 1.67s| Loss: 0.0034
Epoch 112/150| Time: 1.63s| Loss: 0.0035
Epoch 113/150| Time: 1.63s| Loss: 0.0041
Epoch 114/150| Time: 1.64s| Loss: 0.0035
Epoch 115/150| Time: 1.63s| Loss: 0.0043
Epoch 116/150| Time: 1.63s| Loss: 0.0035
Epoch 117/150| Time: 1.63s| Loss: 0.0035
Epoch 118/150| Time: 1.71s| Loss: 0.0034
Epoch 119/150| Time: 1.63s| Loss: 0.0038
Epoch 120/150| Time: 1.64s| Loss: 0.0031
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet120.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet120.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3024 | Accuracy: 24
	Batch_idx: 1 | Loss: 0.0466 | Accuracy: 14
	Batch_idx: 2 | Loss: 0.1226 | Accuracy: 8
	Batch_idx: 3 | Loss: 0.1159 | Accuracy: 8
	Batch_idx: 4 | Loss: 0.1228 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1134 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1090 | Accuracy: 9
	Batch_idx: 7 | Loss: 0.1753 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1644 | Accuracy: 10
	Batch_idx: 9 | Loss: 0.1920 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.2378 | Accuracy: 7
	Batch_idx: 11 | Loss: 0.1599 | Accuracy: 10
	Batch_idx: 12 | Loss: 0.0669 | Accuracy: 3
	Batch_idx: 13 | Loss: 0.1273 | Accuracy: 4
	Batch_idx: 14 | Loss: 0.0353 | Accuracy: 7
	Batch_idx: 15 | Loss: 0.0304 | Accuracy: 4
	Batch_idx: 16 | Loss: 0.0651 | Accuracy: 6
	Batch_idx: 17 | Loss: 0.1456 | Accuracy: 10
	Batch_idx: 18 | Loss: 0.1026 | Accuracy: 13
	Batch_idx: 19 | Loss: 0.1305 | Accuracy: 4
	Batch_idx: 20 | Loss: 0.0873 | Accuracy: 15
	Batch_idx: 21 | Loss: 0.0768 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.1051 | Accuracy: 13
	Batch_idx: 23 | Loss: 0.0278 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0192 | Accuracy: 17
	Batch_idx: 25 | Loss: 0.0275 | Accuracy: 11
	Batch_idx: 26 | Loss: 0.0161 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0188 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0111 | Accuracy: 10
	Batch_idx: 29 | Loss: 0.0095 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1460 | Accuracy: 24
	Batch_idx: 31 | Loss: 0.0059 | Accuracy: 9
	Batch_idx: 32 | Loss: 0.0052 | Accuracy: 10
	Batch_idx: 33 | Loss: 0.0072 | Accuracy: 14
	Batch_idx: 34 | Loss: 0.2347 | Accuracy: 25
	Batch_idx: 35 | Loss: 0.1954 | Accuracy: 16
	Batch_idx: 36 | Loss: 0.1713 | Accuracy: 13
	Batch_idx: 37 | Loss: 0.1178 | Accuracy: 10
	Batch_idx: 38 | Loss: 0.2072 | Accuracy: 17
	Batch_idx: 39 | Loss: 0.0603 | Accuracy: 11
	Batch_idx: 40 | Loss: 0.0535 | Accuracy: 12
	Batch_idx: 41 | Loss: 0.1011 | Accuracy: 12
	Batch_idx: 42 | Loss: 0.0431 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0154 | Accuracy: 14
	Batch_idx: 44 | Loss: 0.0247 | Accuracy: 11
	Batch_idx: 45 | Loss: 0.0351 | Accuracy: 12
	Batch_idx: 46 | Loss: 0.0963 | Accuracy: 11
	Batch_idx: 47 | Loss: 0.0679 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0461 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0317 | Accuracy: 15
	Batch_idx: 50 | Loss: 0.0258 | Accuracy: 15
	Batch_idx: 51 | Loss: 0.0237 | Accuracy: 12
	Batch_idx: 52 | Loss: 0.0493 | Accuracy: 10
	Batch_idx: 53 | Loss: 0.0649 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.0558 | Accuracy: 13
	Batch_idx: 55 | Loss: 0.0730 | Accuracy: 14
	Batch_idx: 56 | Loss: 0.0930 | Accuracy: 13
	Batch_idx: 57 | Loss: 0.0507 | Accuracy: 8
	Batch_idx: 58 | Loss: 0.0330 | Accuracy: 7
	Batch_idx: 59 | Loss: 0.0627 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0823 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.0628 | Accuracy: 12
	Batch_idx: 62 | Loss: 0.1905 | Accuracy: 8
	Batch_idx: 63 | Loss: 0.1468 | Accuracy: 7
	Batch_idx: 64 | Loss: 0.1674 | Accuracy: 6
	Batch_idx: 65 | Loss: 0.0762 | Accuracy: 4
	Batch_idx: 66 | Loss: 0.0814 | Accuracy: 13
	Batch_idx: 67 | Loss: 0.0179 | Accuracy: 5
	Batch_idx: 68 | Loss: 0.1430 | Accuracy: 22
	Batch_idx: 69 | Loss: 0.0040 | Accuracy: 14
	Batch_idx: 70 | Loss: 0.0505 | Accuracy: 11
	Batch_idx: 71 | Loss: 0.0286 | Accuracy: 11
	Batch_idx: 72 | Loss: 0.0183 | Accuracy: 14
	Batch_idx: 73 | Loss: 0.0060 | Accuracy: 10
	Batch_idx: 74 | Loss: 0.0081 | Accuracy: 12
	Batch_idx: 75 | Loss: 0.0334 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.0972 | Accuracy: 14
	Batch_idx: 77 | Loss: 0.0783 | Accuracy: 16
	Batch_idx: 78 | Loss: 0.0910 | Accuracy: 14
	Batch_idx: 79 | Loss: 0.0660 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.1105 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0584 | Accuracy: 14
	Batch_idx: 82 | Loss: 0.0013 | Accuracy: 25
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 9.8863
  Class 2, accuracy: 6.6265
  Class 3, accuracy: 7.8947
  Class 4, accuracy: 13.1783
  Class 5, accuracy: 12.5000
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 14.3603
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 13.4961
  Class 10, accuracy: 12.1690
  Class 11, accuracy: 7.1579
  Class 12, accuracy: 9.7561
  Class 13, accuracy: 13.8340
  Class 14, accuracy: 5.8252
  Class 15, accuracy: 16.0000
Testing Loss: 0.0827 | OA: 11.4334 | AA: 14.8529 | Time: 7.24
Epoch 121/150| Time: 1.65s| Loss: 0.0038
Epoch 122/150| Time: 1.63s| Loss: 0.0047
Epoch 123/150| Time: 1.63s| Loss: 0.0049
Epoch 124/150| Time: 1.63s| Loss: 0.0037
Epoch 125/150| Time: 1.61s| Loss: 0.0032
Epoch 126/150| Time: 1.61s| Loss: 0.0036
Epoch 127/150| Time: 1.62s| Loss: 0.0046
Epoch 128/150| Time: 1.61s| Loss: 0.0047
Epoch 129/150| Time: 1.61s| Loss: 0.0037
Epoch 130/150| Time: 1.61s| Loss: 0.0034
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet130.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet130.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3154 | Accuracy: 24
	Batch_idx: 1 | Loss: 0.0599 | Accuracy: 13
	Batch_idx: 2 | Loss: 0.1402 | Accuracy: 8
	Batch_idx: 3 | Loss: 0.1335 | Accuracy: 8
	Batch_idx: 4 | Loss: 0.1413 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1325 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1308 | Accuracy: 11
	Batch_idx: 7 | Loss: 0.1969 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1842 | Accuracy: 12
	Batch_idx: 9 | Loss: 0.2108 | Accuracy: 11
	Batch_idx: 10 | Loss: 0.2605 | Accuracy: 8
	Batch_idx: 11 | Loss: 0.1806 | Accuracy: 11
	Batch_idx: 12 | Loss: 0.0553 | Accuracy: 3
	Batch_idx: 13 | Loss: 0.1176 | Accuracy: 4
	Batch_idx: 14 | Loss: 0.0300 | Accuracy: 4
	Batch_idx: 15 | Loss: 0.0259 | Accuracy: 4
	Batch_idx: 16 | Loss: 0.0560 | Accuracy: 6
	Batch_idx: 17 | Loss: 0.1358 | Accuracy: 10
	Batch_idx: 18 | Loss: 0.1233 | Accuracy: 12
	Batch_idx: 19 | Loss: 0.1720 | Accuracy: 4
	Batch_idx: 20 | Loss: 0.1005 | Accuracy: 14
	Batch_idx: 21 | Loss: 0.0747 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.1006 | Accuracy: 14
	Batch_idx: 23 | Loss: 0.0277 | Accuracy: 17
	Batch_idx: 24 | Loss: 0.0168 | Accuracy: 15
	Batch_idx: 25 | Loss: 0.0235 | Accuracy: 10
	Batch_idx: 26 | Loss: 0.0120 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0143 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0083 | Accuracy: 11
	Batch_idx: 29 | Loss: 0.0072 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1513 | Accuracy: 26
	Batch_idx: 31 | Loss: 0.0066 | Accuracy: 10
	Batch_idx: 32 | Loss: 0.0059 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0077 | Accuracy: 15
	Batch_idx: 34 | Loss: 0.2376 | Accuracy: 24
	Batch_idx: 35 | Loss: 0.1941 | Accuracy: 16
	Batch_idx: 36 | Loss: 0.1789 | Accuracy: 10
	Batch_idx: 37 | Loss: 0.1186 | Accuracy: 8
	Batch_idx: 38 | Loss: 0.2100 | Accuracy: 16
	Batch_idx: 39 | Loss: 0.0573 | Accuracy: 11
	Batch_idx: 40 | Loss: 0.0537 | Accuracy: 13
	Batch_idx: 41 | Loss: 0.1027 | Accuracy: 11
	Batch_idx: 42 | Loss: 0.0439 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0137 | Accuracy: 13
	Batch_idx: 44 | Loss: 0.0220 | Accuracy: 12
	Batch_idx: 45 | Loss: 0.0305 | Accuracy: 12
	Batch_idx: 46 | Loss: 0.0932 | Accuracy: 11
	Batch_idx: 47 | Loss: 0.0643 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0406 | Accuracy: 14
	Batch_idx: 49 | Loss: 0.0268 | Accuracy: 14
	Batch_idx: 50 | Loss: 0.0207 | Accuracy: 15
	Batch_idx: 51 | Loss: 0.0181 | Accuracy: 13
	Batch_idx: 52 | Loss: 0.0448 | Accuracy: 10
	Batch_idx: 53 | Loss: 0.0646 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.0504 | Accuracy: 13
	Batch_idx: 55 | Loss: 0.0694 | Accuracy: 14
	Batch_idx: 56 | Loss: 0.0872 | Accuracy: 12
	Batch_idx: 57 | Loss: 0.0491 | Accuracy: 8
	Batch_idx: 58 | Loss: 0.0315 | Accuracy: 8
	Batch_idx: 59 | Loss: 0.0588 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0705 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.0609 | Accuracy: 13
	Batch_idx: 62 | Loss: 0.2040 | Accuracy: 9
	Batch_idx: 63 | Loss: 0.1605 | Accuracy: 9
	Batch_idx: 64 | Loss: 0.1759 | Accuracy: 8
	Batch_idx: 65 | Loss: 0.0829 | Accuracy: 4
	Batch_idx: 66 | Loss: 0.0933 | Accuracy: 13
	Batch_idx: 67 | Loss: 0.0174 | Accuracy: 5
	Batch_idx: 68 | Loss: 0.1431 | Accuracy: 22
	Batch_idx: 69 | Loss: 0.0037 | Accuracy: 15
	Batch_idx: 70 | Loss: 0.0493 | Accuracy: 13
	Batch_idx: 71 | Loss: 0.0278 | Accuracy: 11
	Batch_idx: 72 | Loss: 0.0170 | Accuracy: 15
	Batch_idx: 73 | Loss: 0.0059 | Accuracy: 12
	Batch_idx: 74 | Loss: 0.0080 | Accuracy: 9
	Batch_idx: 75 | Loss: 0.0331 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.0963 | Accuracy: 16
	Batch_idx: 77 | Loss: 0.0791 | Accuracy: 15
	Batch_idx: 78 | Loss: 0.0886 | Accuracy: 15
	Batch_idx: 79 | Loss: 0.0655 | Accuracy: 2
	Batch_idx: 80 | Loss: 0.1115 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0608 | Accuracy: 14
	Batch_idx: 82 | Loss: 0.0014 | Accuracy: 25
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 10.3237
  Class 2, accuracy: 6.1747
  Class 3, accuracy: 6.8421
  Class 4, accuracy: 13.4367
  Class 5, accuracy: 12.3288
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 14.8825
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 12.5964
  Class 10, accuracy: 12.1690
  Class 11, accuracy: 8.6316
  Class 12, accuracy: 9.7561
  Class 13, accuracy: 14.2292
  Class 14, accuracy: 5.5016
  Class 15, accuracy: 16.0000
Testing Loss: 0.0853 | OA: 11.4944 | AA: 14.8646 | Time: 7.14
Epoch 131/150| Time: 1.62s| Loss: 0.0038
Epoch 132/150| Time: 1.61s| Loss: 0.0038
Epoch 133/150| Time: 1.61s| Loss: 0.0034
Epoch 134/150| Time: 1.62s| Loss: 0.0036
Epoch 135/150| Time: 1.62s| Loss: 0.0034
Epoch 136/150| Time: 1.61s| Loss: 0.0040
Epoch 137/150| Time: 1.62s| Loss: 0.0034
Epoch 138/150| Time: 1.62s| Loss: 0.0047
Epoch 139/150| Time: 1.61s| Loss: 0.0043
Epoch 140/150| Time: 1.61s| Loss: 0.0037
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet140.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet140.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3164 | Accuracy: 23
	Batch_idx: 1 | Loss: 0.0580 | Accuracy: 14
	Batch_idx: 2 | Loss: 0.1426 | Accuracy: 8
	Batch_idx: 3 | Loss: 0.1300 | Accuracy: 8
	Batch_idx: 4 | Loss: 0.1383 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1311 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1277 | Accuracy: 9
	Batch_idx: 7 | Loss: 0.1956 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1856 | Accuracy: 11
	Batch_idx: 9 | Loss: 0.2089 | Accuracy: 12
	Batch_idx: 10 | Loss: 0.2590 | Accuracy: 8
	Batch_idx: 11 | Loss: 0.1781 | Accuracy: 11
	Batch_idx: 12 | Loss: 0.0669 | Accuracy: 2
	Batch_idx: 13 | Loss: 0.1336 | Accuracy: 4
	Batch_idx: 14 | Loss: 0.0348 | Accuracy: 7
	Batch_idx: 15 | Loss: 0.0286 | Accuracy: 4
	Batch_idx: 16 | Loss: 0.0683 | Accuracy: 6
	Batch_idx: 17 | Loss: 0.1511 | Accuracy: 10
	Batch_idx: 18 | Loss: 0.1144 | Accuracy: 14
	Batch_idx: 19 | Loss: 0.1469 | Accuracy: 3
	Batch_idx: 20 | Loss: 0.0916 | Accuracy: 13
	Batch_idx: 21 | Loss: 0.0772 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.1022 | Accuracy: 14
	Batch_idx: 23 | Loss: 0.0282 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0164 | Accuracy: 16
	Batch_idx: 25 | Loss: 0.0241 | Accuracy: 10
	Batch_idx: 26 | Loss: 0.0127 | Accuracy: 14
	Batch_idx: 27 | Loss: 0.0160 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0090 | Accuracy: 10
	Batch_idx: 29 | Loss: 0.0075 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1455 | Accuracy: 24
	Batch_idx: 31 | Loss: 0.0071 | Accuracy: 10
	Batch_idx: 32 | Loss: 0.0061 | Accuracy: 8
	Batch_idx: 33 | Loss: 0.0083 | Accuracy: 13
	Batch_idx: 34 | Loss: 0.2263 | Accuracy: 25
	Batch_idx: 35 | Loss: 0.1864 | Accuracy: 17
	Batch_idx: 36 | Loss: 0.1598 | Accuracy: 11
	Batch_idx: 37 | Loss: 0.1133 | Accuracy: 10
	Batch_idx: 38 | Loss: 0.1971 | Accuracy: 18
	Batch_idx: 39 | Loss: 0.0550 | Accuracy: 10
	Batch_idx: 40 | Loss: 0.0516 | Accuracy: 12
	Batch_idx: 41 | Loss: 0.0916 | Accuracy: 12
	Batch_idx: 42 | Loss: 0.0400 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0136 | Accuracy: 14
	Batch_idx: 44 | Loss: 0.0226 | Accuracy: 11
	Batch_idx: 45 | Loss: 0.0308 | Accuracy: 13
	Batch_idx: 46 | Loss: 0.0933 | Accuracy: 11
	Batch_idx: 47 | Loss: 0.0639 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0458 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0277 | Accuracy: 15
	Batch_idx: 50 | Loss: 0.0218 | Accuracy: 15
	Batch_idx: 51 | Loss: 0.0194 | Accuracy: 12
	Batch_idx: 52 | Loss: 0.0443 | Accuracy: 10
	Batch_idx: 53 | Loss: 0.0575 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.0515 | Accuracy: 14
	Batch_idx: 55 | Loss: 0.0645 | Accuracy: 14
	Batch_idx: 56 | Loss: 0.0887 | Accuracy: 13
	Batch_idx: 57 | Loss: 0.0454 | Accuracy: 8
	Batch_idx: 58 | Loss: 0.0313 | Accuracy: 8
	Batch_idx: 59 | Loss: 0.0582 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0698 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.0588 | Accuracy: 12
	Batch_idx: 62 | Loss: 0.1921 | Accuracy: 8
	Batch_idx: 63 | Loss: 0.1488 | Accuracy: 8
	Batch_idx: 64 | Loss: 0.1616 | Accuracy: 6
	Batch_idx: 65 | Loss: 0.0781 | Accuracy: 5
	Batch_idx: 66 | Loss: 0.0815 | Accuracy: 11
	Batch_idx: 67 | Loss: 0.0159 | Accuracy: 5
	Batch_idx: 68 | Loss: 0.1509 | Accuracy: 19
	Batch_idx: 69 | Loss: 0.0049 | Accuracy: 13
	Batch_idx: 70 | Loss: 0.0554 | Accuracy: 12
	Batch_idx: 71 | Loss: 0.0321 | Accuracy: 10
	Batch_idx: 72 | Loss: 0.0224 | Accuracy: 14
	Batch_idx: 73 | Loss: 0.0080 | Accuracy: 13
	Batch_idx: 74 | Loss: 0.0108 | Accuracy: 12
	Batch_idx: 75 | Loss: 0.0382 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.1035 | Accuracy: 15
	Batch_idx: 77 | Loss: 0.0873 | Accuracy: 15
	Batch_idx: 78 | Loss: 0.0902 | Accuracy: 14
	Batch_idx: 79 | Loss: 0.0589 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.0980 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0528 | Accuracy: 13
	Batch_idx: 82 | Loss: 0.0011 | Accuracy: 25
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 10.1487
  Class 2, accuracy: 6.4759
  Class 3, accuracy: 7.8947
  Class 4, accuracy: 12.6615
  Class 5, accuracy: 12.3288
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 13.8381
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 13.3676
  Class 10, accuracy: 12.3218
  Class 11, accuracy: 7.1579
  Class 12, accuracy: 9.1463
  Class 13, accuracy: 13.8340
  Class 14, accuracy: 5.8252
  Class 15, accuracy: 14.6667
Testing Loss: 0.0840 | OA: 11.3969 | AA: 14.6643 | Time: 7.20
Epoch 141/150| Time: 1.62s| Loss: 0.0033
Epoch 142/150| Time: 1.63s| Loss: 0.0035
Epoch 143/150| Time: 1.62s| Loss: 0.0034
Epoch 144/150| Time: 1.62s| Loss: 0.0036
Epoch 145/150| Time: 1.62s| Loss: 0.0032
Epoch 146/150| Time: 1.62s| Loss: 0.0038
Epoch 147/150| Time: 1.62s| Loss: 0.0030
Epoch 148/150| Time: 1.62s| Loss: 0.0035
Epoch 149/150| Time: 1.62s| Loss: 0.0036
Epoch 150/150| Time: 1.62s| Loss: 0.0036
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet150.model model saved--<<
>>--/home/xueyiming/PytorchWorkspace/snapshots/patch_size11/Pyramidal_ResNet_2019-01-10_20-56-44/Pyramidal_ResNet150.model model loaded--<<
	Batch_idx: 0 | Loss: 0.3172 | Accuracy: 24
	Batch_idx: 1 | Loss: 0.0515 | Accuracy: 14
	Batch_idx: 2 | Loss: 0.1331 | Accuracy: 7
	Batch_idx: 3 | Loss: 0.1239 | Accuracy: 8
	Batch_idx: 4 | Loss: 0.1342 | Accuracy: 11
	Batch_idx: 5 | Loss: 0.1162 | Accuracy: 7
	Batch_idx: 6 | Loss: 0.1201 | Accuracy: 10
	Batch_idx: 7 | Loss: 0.1841 | Accuracy: 6
	Batch_idx: 8 | Loss: 0.1746 | Accuracy: 10
	Batch_idx: 9 | Loss: 0.2006 | Accuracy: 12
	Batch_idx: 10 | Loss: 0.2508 | Accuracy: 8
	Batch_idx: 11 | Loss: 0.1683 | Accuracy: 10
	Batch_idx: 12 | Loss: 0.0624 | Accuracy: 3
	Batch_idx: 13 | Loss: 0.1266 | Accuracy: 3
	Batch_idx: 14 | Loss: 0.0338 | Accuracy: 8
	Batch_idx: 15 | Loss: 0.0311 | Accuracy: 4
	Batch_idx: 16 | Loss: 0.0643 | Accuracy: 6
	Batch_idx: 17 | Loss: 0.1447 | Accuracy: 10
	Batch_idx: 18 | Loss: 0.1182 | Accuracy: 14
	Batch_idx: 19 | Loss: 0.1625 | Accuracy: 4
	Batch_idx: 20 | Loss: 0.0973 | Accuracy: 16
	Batch_idx: 21 | Loss: 0.0772 | Accuracy: 9
	Batch_idx: 22 | Loss: 0.1018 | Accuracy: 12
	Batch_idx: 23 | Loss: 0.0280 | Accuracy: 16
	Batch_idx: 24 | Loss: 0.0169 | Accuracy: 18
	Batch_idx: 25 | Loss: 0.0255 | Accuracy: 11
	Batch_idx: 26 | Loss: 0.0135 | Accuracy: 13
	Batch_idx: 27 | Loss: 0.0161 | Accuracy: 15
	Batch_idx: 28 | Loss: 0.0095 | Accuracy: 10
	Batch_idx: 29 | Loss: 0.0081 | Accuracy: 9
	Batch_idx: 30 | Loss: 0.1498 | Accuracy: 24
	Batch_idx: 31 | Loss: 0.0062 | Accuracy: 11
	Batch_idx: 32 | Loss: 0.0055 | Accuracy: 7
	Batch_idx: 33 | Loss: 0.0074 | Accuracy: 15
	Batch_idx: 34 | Loss: 0.2304 | Accuracy: 25
	Batch_idx: 35 | Loss: 0.1878 | Accuracy: 12
	Batch_idx: 36 | Loss: 0.1681 | Accuracy: 8
	Batch_idx: 37 | Loss: 0.1142 | Accuracy: 9
	Batch_idx: 38 | Loss: 0.1999 | Accuracy: 17
	Batch_idx: 39 | Loss: 0.0571 | Accuracy: 9
	Batch_idx: 40 | Loss: 0.0537 | Accuracy: 11
	Batch_idx: 41 | Loss: 0.0971 | Accuracy: 11
	Batch_idx: 42 | Loss: 0.0453 | Accuracy: 14
	Batch_idx: 43 | Loss: 0.0152 | Accuracy: 13
	Batch_idx: 44 | Loss: 0.0278 | Accuracy: 11
	Batch_idx: 45 | Loss: 0.0331 | Accuracy: 12
	Batch_idx: 46 | Loss: 0.0988 | Accuracy: 11
	Batch_idx: 47 | Loss: 0.0685 | Accuracy: 12
	Batch_idx: 48 | Loss: 0.0479 | Accuracy: 13
	Batch_idx: 49 | Loss: 0.0329 | Accuracy: 15
	Batch_idx: 50 | Loss: 0.0238 | Accuracy: 15
	Batch_idx: 51 | Loss: 0.0211 | Accuracy: 12
	Batch_idx: 52 | Loss: 0.0465 | Accuracy: 9
	Batch_idx: 53 | Loss: 0.0674 | Accuracy: 12
	Batch_idx: 54 | Loss: 0.0564 | Accuracy: 14
	Batch_idx: 55 | Loss: 0.0792 | Accuracy: 14
	Batch_idx: 56 | Loss: 0.0981 | Accuracy: 13
	Batch_idx: 57 | Loss: 0.0531 | Accuracy: 7
	Batch_idx: 58 | Loss: 0.0344 | Accuracy: 8
	Batch_idx: 59 | Loss: 0.0617 | Accuracy: 11
	Batch_idx: 60 | Loss: 0.0782 | Accuracy: 13
	Batch_idx: 61 | Loss: 0.0605 | Accuracy: 14
	Batch_idx: 62 | Loss: 0.1907 | Accuracy: 9
	Batch_idx: 63 | Loss: 0.1499 | Accuracy: 7
	Batch_idx: 64 | Loss: 0.1621 | Accuracy: 9
	Batch_idx: 65 | Loss: 0.0819 | Accuracy: 4
	Batch_idx: 66 | Loss: 0.0832 | Accuracy: 12
	Batch_idx: 67 | Loss: 0.0162 | Accuracy: 4
	Batch_idx: 68 | Loss: 0.1507 | Accuracy: 18
	Batch_idx: 69 | Loss: 0.0047 | Accuracy: 14
	Batch_idx: 70 | Loss: 0.0538 | Accuracy: 12
	Batch_idx: 71 | Loss: 0.0326 | Accuracy: 11
	Batch_idx: 72 | Loss: 0.0215 | Accuracy: 14
	Batch_idx: 73 | Loss: 0.0077 | Accuracy: 13
	Batch_idx: 74 | Loss: 0.0104 | Accuracy: 14
	Batch_idx: 75 | Loss: 0.0365 | Accuracy: 11
	Batch_idx: 76 | Loss: 0.1024 | Accuracy: 14
	Batch_idx: 77 | Loss: 0.0849 | Accuracy: 16
	Batch_idx: 78 | Loss: 0.0887 | Accuracy: 12
	Batch_idx: 79 | Loss: 0.0558 | Accuracy: 4
	Batch_idx: 80 | Loss: 0.0946 | Accuracy: 7
	Batch_idx: 81 | Loss: 0.0517 | Accuracy: 14
	Batch_idx: 82 | Loss: 0.0012 | Accuracy: 25
  Class 0, accuracy: 27.0270
  Class 1, accuracy: 10.0612
  Class 2, accuracy: 6.6265
  Class 3, accuracy: 8.9474
  Class 4, accuracy: 12.6615
  Class 5, accuracy: 12.6712
  Class 6, accuracy: 30.4348
  Class 7, accuracy: 14.3603
  Class 8, accuracy: 37.5000
  Class 9, accuracy: 11.6967
  Class 10, accuracy: 12.1181
  Class 11, accuracy: 8.2105
  Class 12, accuracy: 8.5366
  Class 13, accuracy: 14.0316
  Class 14, accuracy: 5.5016
  Class 15, accuracy: 16.0000
Testing Loss: 0.0844 | OA: 11.3359 | AA: 14.7741 | Time: 7.12
